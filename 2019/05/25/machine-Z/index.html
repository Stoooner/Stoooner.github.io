<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>机器学习对超新星高红移的分类 | Stoner的博客</title><meta name="description" content="在中科院紫金山天文台时做的一个报告分享.   1. ABSTRACT 分类算法：High-Z 回归算法：Machine-Z 样本：Our method relies exclusively on canonical data commonly available within the first few hours after the GRB trigger. Using a sample of"><meta name="keywords" content="天体物理学,超新星高红移,机器学习分类"><meta name="author" content="Stoner"><meta name="copyright" content="Stoner"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://yoursite.com/2019/05/25/machine-Z/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta property="og:type" content="article"><meta property="og:title" content="机器学习对超新星高红移的分类"><meta property="og:url" content="http://yoursite.com/2019/05/25/machine-Z/"><meta property="og:site_name" content="Stoner的博客"><meta property="og:description" content="在中科院紫金山天文台时做的一个报告分享.   1. ABSTRACT 分类算法：High-Z 回归算法：Machine-Z 样本：Our method relies exclusively on canonical data commonly available within the first few hours after the GRB trigger. Using a sample of"><meta property="og:image" content="http://qe0z9wdl5.bkt.clouddn.com/20200725231510.png"><meta property="article:published_time" content="2019-05-25T07:21:13.000Z"><meta property="article:modified_time" content="2020-07-25T15:16:45.686Z"><meta name="twitter:card" content="summary"><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'false'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="prev" title="Tensorboard以及Summary类总结" href="http://yoursite.com/2019/05/25/tensorboard-summary/"><link rel="next" title="PCA手动实现及推导" href="http://yoursite.com/2019/05/25/PCA/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: false,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: true,
  fancybox: false,
  Snackbar: {"bookmark":{"message_prev":"按","message_next":"键将本页加入书签"},"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: true,
  islazyload: true,
  isanchor: false    
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true
  }</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.1"><link rel="alternate" href="/atom.xml" title="Stoner的博客" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><canvas class="fireworks"></canvas><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="http://qe0z9wdl5.bkt.clouddn.com/20200726202347.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">49</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">64</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">17</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div></div></div></div><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content toc-div-class" style="display:none"></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(http://qe0z9wdl5.bkt.clouddn.com/20200725231510.png)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">Stoner的博客</a></span><span class="pull-right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">机器学习对超新星高红移的分类</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2019-05-25 15:21:13"><i class="far fa-calendar-alt fa-fw"></i> 发表于 2019-05-25</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2020-07-25 23:16:45"><i class="fas fa-history fa-fw"></i> 更新于 2020-07-25</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fas fa-inbox fa-fw post-meta__icon"></i><a class="post-meta__categories" href="/categories/%E5%A4%A9%E4%BD%93%E7%89%A9%E7%90%86%E5%AD%A6/">天体物理学</a></span></div><div class="meta-secondline"> </div><div class="meta-thirdline"><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta__icon"></i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><blockquote>
<p><strong>在中科院紫金山天文台时做的一个报告分享.</strong><br><a id="more"></a></p>
</blockquote>
<p><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795828055.png" alt="Alt text"></p>
<h2 id="1-ABSTRACT"><a href="#1-ABSTRACT" class="headerlink" title="1. ABSTRACT"></a>1. ABSTRACT</h2><ol>
<li>分类算法：<strong>High-Z</strong></li>
<li>回归算法：<strong>Machine-Z</strong></li>
<li>样本：<br><strong>Our method relies exclusively on canonical data commonly available within the first few hours after the GRB trigger. Using a sample of 284 bursts with measured redshifts.</strong></li>
<li>使用的机器学习算法：<strong>Random Forest</strong></li>
<li><strong>Validation Performance (machine-z): </strong><br><strong>the correlation coefficient between machine-z predictions and the true redshift is nearly 0.6</strong></li>
<li><strong>High-Z：</strong><blockquote>
<p><strong>20 % FPR(False Positive Rate假阳率)</strong>  ===&gt;  <strong>80 % Recall(召回率)</strong><br><strong>40 % FPR(False Positive Rate假阳率)</strong> ===&gt; <strong>100 % Recall(召回率)</strong></p>
</blockquote>
</li>
</ol>
<h2 id="2-INTRODUCTION"><a href="#2-INTRODUCTION" class="headerlink" title="2. INTRODUCTION"></a>2. INTRODUCTION</h2><ol>
<li>研究原因：<br>1.1 <strong>GRB的重要程度…</strong><br>1.2 <strong>由于其独特的特性, 高红移的GRB与类星体相比具有许多显着优势。(high-z GRBs have a number of significant advantages over quasars due to their unique characteristics. )</strong></li>
<li>目的：<br>2.1 <strong>这项工作的主要挑战是在光学发射逐步消失之前，可靠地识别适合于详细的光谱追踪的高红移爆发。基于爆发后有限的信息，必须在爆发后的头几个小时甚至几分钟内决定在大型望远镜上使用宝贵的观测时间。</strong><br><strong>(The main challenge in this work is to reliably identify high redshift bursts suitable for detailed spectroscopic follow-up before the optical emission fades away. </strong><br><strong>Decisions to use precious observing time on large telescopes must be made within the first hours or even minutes after the burst based on limited information.)</strong><br><strong>Previous attempts to screen high-z GRBs using promptly available high-energy data， while showing some promise, lacked the accuracy necessary to facilitate a reliable follow-up program. As a result, they were never widely adopted by observers</strong><br>2.2 <strong>主要困难在于从易于获得的高维数据中提取许多弱相关性并有效地组合它们包含的信息。 基于机器学习的现代方法非常适用于此目的。</strong><br><strong>The main difficulty lies in extracting numerous weak correlations from readily available high-dimensional data and efficiently combining the information they contain. A modern approach based on machine learning is ideal for this purpose.</strong></li>
</ol>
<h2 id="3-METHODOLOGY"><a href="#3-METHODOLOGY" class="headerlink" title="3. METHODOLOGY"></a>3. METHODOLOGY</h2><h3 id="3-1-GRB-Sample-and-Data-Features"><a href="#3-1-GRB-Sample-and-Data-Features" class="headerlink" title="3.1 GRB Sample and Data Features"></a>3.1 GRB Sample and Data Features</h3><blockquote>
<ol>
<li><strong>我们的样本由284个Swift GRB组成，带有光谱红移测量. 样本包括2005年至2014年底发现的GRB. 图1显示了样品中所有爆的红移分布。 最低红移值为0.033，最高值为8.26。 我们采用z = 4作为低红移和高红移的阈值。 根据该定义，284个GRB中的25个样本或大约9％是高红移. </strong><br><strong>(Our sample consists of 284 Swift GRBs with spectroscopic redshift measurements. The sample includes GRBs discovered between 2005 and the end of 2014. Fig. 1 shows the redshfit distribution of all bursts in the sample. The lowest redshift value is 0.033 and the highest is 8.26. We adopt z = 4 as the threshold between low-redshift and high-redshift bursts. Out of 284 GRBs in the sample 25 or ∼ 9% are high-redshift according to this definition.)</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795839753.png" alt="Alt text"></li>
</ol>
<p><a href="http://swift.gsfc.nasa.gov/archive/grb%20table/" target="_blank" rel="noopener">The measurements are taken from the Swift online catalog at https.</a></p>
<ol>
<li><strong>The Swift mission payload consists of three major instruments(Swift任务有效载荷包括三个主要仪器):</strong><br>2.1 <strong>the Burst Alert Telescope (BAT):</strong><br>2.1 <strong>the X-ray Telescope (XRT)</strong><br>2.2 <strong>the UV Optical Telescope (UVOT)</strong><blockquote>
<p><strong>BAT is a soft gamma-ray wide field instrument sensitive to photons in the energy range 15 keV to 350 keV and it is the GRB discovery instrument.</strong><br><strong>(BAT是一种对15 keV至350 keV能量范围内的光子敏感的软伽马射线宽场仪器，它是发现GRB的仪器). </strong><br><strong>Once BAT discovered a GRB and determined its sky position, the Swift satellite slews to the location of the burst so that the narrow field instruments XRT and UVOT can quickly start observing the afterglow. In order to provide a rapid machine-z redshift and high-z classification, we limited this study to readily available measurements from all three Swift instruments.</strong><br><strong>(一旦BAT发现GRB并确定其天空位置，Swift卫星就会转向爆发位置，这样窄场仪器XRT和UVOT可以快速开始观察余辉。 为了提供快速的机器-z红移和高z分类，我们将这项研究限制在所有三种Swift仪器的现成测量中). </strong></p>
</blockquote>
</li>
<li><strong>These measurements were adopted as numerical features for classification and regression(BAT，XRT和UVOT的测量结果作为回归与分类的样本特征)：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795846590.png" alt="Alt text"></li>
</ol>
</blockquote>
<h3 id="3-2-Machine-Learning-Algorithm"><a href="#3-2-Machine-Learning-Algorithm" class="headerlink" title="3.2 Machine Learning Algorithm"></a>3.2 Machine Learning Algorithm</h3><h4 id="3-2-1-Random-Forests"><a href="#3-2-1-Random-Forests" class="headerlink" title="3.2.1 Random Forests"></a>3.2.1 Random Forests</h4><blockquote>
<p><strong>Over the past few years the method found several interesting applications in observational astrophysics including selection of explosive transients in imaging data, classification of X-ray sources , and redshift prediction. RF has the ability to select useful features, relatively immune to data over-fitting, can handle nonlinear relationships, and provide probabilistic outputs.(在过去几年中，该方法在观测天体物理学中发现了几个有趣的应用，包括选择成像数据中的爆炸瞬态，X射线源的分类和红移预测. RF能够选择有用的特征，相对地不受数据过拟合影响，可以处理非线性关系，并提供概率输出).</strong> </p>
</blockquote>
<h4 id="3-3-2-Missing-Features-☆"><a href="#3-3-2-Missing-Features-☆" class="headerlink" title="3.3.2 Missing Features(☆)"></a>3.3.2 Missing Features(☆)</h4><blockquote>
<p><strong>Missing features are common in real world data and our GRB sample is no exception. A popular approach to handle missing input values is by imputation i.e. assigning values estimated from the distribution of all remaining instances(特征缺失在现实世界数据中很常见，我们的GRB样本也不例外。 处理缺失输入值的通用方法是通过估算，即分配的值来自剩余实例的分布估计).</strong><br><strong>In order to preserve all available information about the redshift we assigned all missing features to −1000. The effect on performance is negligible as long as the plug-in value is well outside the normal range for all features(为了保留有关红移的所有可用信息，我们给所有缺失的特征分配为 -1000。 只要插件值远远超出所有特征的正常范围，对性能的影响就可以忽略不计). </strong></p>
</blockquote>
<h4 id="3-3-3-Data-Imbalance-☆"><a href="#3-3-3-Data-Imbalance-☆" class="headerlink" title="3.3.3 Data Imbalance(☆)"></a>3.3.3 Data Imbalance(☆)</h4><blockquote>
<p><strong>The input catalog for our study is quite unbalanced with fewer than 10% of GRBs at z &gt; 4. A low fraction of high-redshift bursts in the training sample will typically result in a tendency to classify all bursts as low-redshift as the algorithm attempts to minimize the overall error rate. This imbalance will result in poor performance of the classifier on new data. One possible solution is to assign higher weights to high-z bursts during training. However, the price is often additional complexity and a tendency for overfitting.( 输入数据是非常不平衡的，在z &gt; 4时GRB的比例不到10％。训练样本中很小一部分的高红移通常会导致算法在试图最小化整体错误率的时候，将样本的类别更倾向于判别为低红移的类别。这种(数据的)不平衡将导致分类器在新数据上的性能不佳。 一种可能的解决方案是在训练期间为高红移的爆发样本分配更高的权重。 然而，代价往往是额外的复杂性和过度拟合的趋势). </strong></p>
<hr>
<ol>
<li><strong>数据不平衡带来的坏处：</strong><br><strong>从训练模型的角度来说，如果某类的样本数量很少，那么这个类别所提供的“信息”就太少。使用经验风险（模型在训练集上的平均损失）最小化作为模型的学习准则。设损失函数为0-1 loss（这是一种典型的均等代价的损失函数），那么优化目标就等价于错误率最小化（也就是accuracy最大化）。考虑极端情况：1000个训练样本中，正类样本999个，负类样本1个。训练过程中在某次迭代结束后，模型把所有的样本都分为正类，虽然分错了这个负类，但是所带来的损失实在微不足道，accuracy已经是99.9%，于是满足停机条件或者达到最大迭代次数之后自然没必要再优化下去，ok，到此为止，训练结束！但是这个模型没有学习到如何去判别出少数类.</strong></li>
<li><strong>不平衡数据下模型的评估指标.</strong></li>
<li><strong>不平衡数据处理方法.</strong></li>
</ol>
</blockquote>
<h2 id="4-HIGH-Z-CLASSIFICATION"><a href="#4-HIGH-Z-CLASSIFICATION" class="headerlink" title="4. HIGH-Z CLASSIFICATION"></a>4. HIGH-Z CLASSIFICATION</h2><h3 id="4-1-ROC-amp-AUC"><a href="#4-1-ROC-amp-AUC" class="headerlink" title="4.1 ROC &amp; AUC"></a>4.1 ROC &amp; AUC</h3><blockquote>
<ol>
<li><strong>ROC: Receiver Operating Characteristic Curve, 即受试者工作特征曲线,是反映真正率(TPR,把正例预测为正例的概率)和假正率(把负例错分为正例的概率)续变量的综合指标.</strong><br>1.1 <strong>ROC主要作用：</strong><br><strong>a. ROC曲线能很容易的查出任意阈值对学习器的泛化性能影响。</strong><br><strong>b. 有助于选择最佳的阈值。ROC曲线越靠近左上角，模型的查全率就越高。最靠近左上角的ROC曲线上的点是分类错误最少的最好阈值，其假正例和假负例总数最少。</strong><br><strong>c.可以对不同的学习器比较性能。将各个学习器的ROC曲线绘制到同一坐标中，直观地鉴别优劣，靠近左上角的ROC曲所代表的学习器准确性最高。</strong></li>
<li><strong>AUC: Area Under ROC Curve， AUC就是ROC曲线下的面积，衡量学习器优劣的一种性能指标.是衡量二分类模型优劣的一种评价指标,在样本不平衡的情况下，依然能够对分类器做出合理的评价, AUC对样本类别是否均衡并不敏感，这也是不均衡样本通常用AUC评价学习器性能的一个原因。</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795865411.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795870797.png" alt="Alt text"></li>
</ol>
<hr>
<p><strong>We compute this curve using randomized 10-fold cross validation (train on 90% of the sample and test on 10%).(我们使用10折交叉验证计算该曲线（对90％的样品进行训练，对10％进行测试)</strong></p>
<hr>
<p><strong>k-折交叉验证: k 折交叉验证通过对 k 个不同分组训练的结果进行平均来减少方差，因此模型的性能对数据的划分就不那么敏感。</strong></p>
<ol>
<li><strong>将全部样本划分为划分为k个大小相等的样本子集.</strong></li>
<li><strong>每一次挑选其中 1 份作为测试集，剩余 k-1 份作为训练集用于模型训练.</strong></li>
<li><strong>重复第二步 k 次，这样每个子集都有一次机会作为测试集，其余机会作为训练集.</strong><br>3.1 <strong>在每个训练集上训练后得到一个模型.</strong><br>3.2 <strong>用这个模型在相应的测试集上测试，计算并保存模型的评估指标.</strong></li>
<li><strong>计算 k 组测试结果的平均值作为模型精度的估计，并作为当前 k 折交叉验证下模型的性能指标.</strong></li>
<li><strong>5折交叉验证的例子：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795882024.png" alt="Alt text"></li>
</ol>
<hr>
<p><strong>机器学习中的数据划分:</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795888447.png" alt="Alt text"></p>
<hr>
<p><strong>数据维数过多与样本过少情况下的龙格现象:</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795901546.png" alt="Alt text"><br><strong>过拟合与欠拟合:</strong><br><strong>回归：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795908955.png" alt="Alt text"><br><strong>分类：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795915475.png" alt="Alt text"></p>
</blockquote>
<h3 id="4-2-Tuning-the-Classifier"><a href="#4-2-Tuning-the-Classifier" class="headerlink" title="4.2 Tuning the Classifier"></a>4.2 Tuning the Classifier</h3><blockquote>
<p><strong>We start with a pool of available features that initially contains all features in Table 1. We start with a pool of available features that initially contains all features in Table 1. The first most informative feature is selected to maximize classification performance (area under ROC curve) using only one feature at a time from the pool of N available features.(我们从表1包含的全部25个特征开始。选择第一个最具信息性的特征以最大化分类性能（ROC曲线下的面积），一次仅使用N个可用特征池中的一个特征。)</strong><br><strong>The next best feature is selected after looping over N − 1 features remaining in the pool and maximizing classification performance using two features.(在循环特征池中剩余的N-1个特征后选择下一个最佳特征，此时使用两个特征最大化分类性能)</strong><br><strong>The process continues until the pool of available features is empty. We use parameter values from Section 3.2, i.e. ntrees = 300 and nodesize = 12，The relative importance of all 25 classification features is shown in Figure 2. As more features are included in training, the area under the ROC curve increases rapidly with a maximum value of 0.89 around 8-th feature followed by a gradual decrease.(整个过程持续到特征池中所有可用特征为空为止, 所使用的参数是$n_{tree}$ = 300, node = 12. 所有25个分类特征的相对重要性如图2所示。随着训练中包含的更多特征，ROC曲线下面积迅速增加，最大值为0.89，大约为第8个特征，然后逐渐减小.)</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795924941.png" alt="Alt text"><br><strong>It is interesting to note that the 8 best features selected in this way include information from all three Swift instruments.  The absence of the total burst duration (BAT T90) on this list is somewhat surprising and may be attributed to a large intrinsic spread of burst durations that dominates the influence of time dilation on this time scale.(值得注意的是，以这种方式选择的8个最佳特征包括来自所有三个Swift仪器的信息。在该列表上没有总爆发持续时间（BAT T90）有点令人惊讶，并且可能归因于爆发持续时间的大的内在扩展，其主导了时间扩张对该时间尺度的影响。)</strong><br><strong>The ROC curve of the final high-z classifier trained using the 8 best features is shown on Fig. 3. The curve shows a steep rise and reaches 100% recall at about 40% false posive rate. We can reduce the false positive rate by half by changing the probability threshold and accepting 80% recall.(使用8个最佳特征训练的最终高z分类器的ROC曲线如图3所示。该曲线显示了陡峭的上升并且在约40％的假阳性率下达到100％的召回率(真正率)。 我们可以通过改变概率阈值和接受80％的召回率将假正率降低一半).</strong></p>
</blockquote>
<h3 id="4-3-Machine-Learned-Scoring"><a href="#4-3-Machine-Learned-Scoring" class="headerlink" title="4.3 Machine Learned Scoring"></a>4.3 Machine Learned Scoring</h3><h2 id="5-MACHINE-Z-REDSHIFT-ESTIMATOR"><a href="#5-MACHINE-Z-REDSHIFT-ESTIMATOR" class="headerlink" title="5. MACHINE-Z REDSHIFT ESTIMATOR"></a>5. MACHINE-Z REDSHIFT ESTIMATOR</h2><blockquote>
<p><strong>In this section,we adapt the methods from section 3 to solve a regression problem and develop an RF based redshift estimator that we call machine-z.(High-z用于分类样本是否高红移，machine-z基于RF用于预测样本实际的红移值)</strong></p>
</blockquote>
<h3 id="5-1-Tuning-the-Regressor"><a href="#5-1-Tuning-the-Regressor" class="headerlink" title="5.1 Tuning the Regressor"></a>5.1 Tuning the Regressor</h3><blockquote>
<ol>
<li><strong>Since the performance of a regressor is evaluated differently from a classifier, we performed an independent parameter search to approximately optimize input parameters of the RF regressor. For this purpose we used the “leave-one-out” cross-validation method that for N bursts consists of N runs with N − 1 instances used for training and one for testing.(由于回归与分类的评估方式不同，在此使用&lt;留一法&gt;进行交叉验证.)</strong><blockquote>
<p><strong>留一法交叉验证：假设样本数据有N个，将每1个样本单独作为测试集，其余N-1个样本作为训练集，依次对这N个样本进行遍历，得到N次验证，再将评估指标求平均得到最终的评估指标。留一法主要是用于样本量较小的情况时使用的交叉验证方法；在样本数目较多的情况下留一法的时间开销及其大. K折交叉验证在k=N的时候即为留一法.</strong></p>
</blockquote>
</li>
<li><strong>The quality of prediction is measured using the Pearson correlation coefficient between machine-z output and true redshift. Table 2 defines the search grid for approximate parameter optimization. In this case we found that a forrest of 100 fully developed trees (with as little as one burst per leaf node) and m = 5 random features per split provides the best results.The resulting correlation coefficient is 0.52.(machine-z回归器输出结果和真正的红移之间通过使用Pearson相关系数来衡量预测质量。表2定义了用于近似参数优化的搜索网格。 在这种情况下，我们发现100棵树木（每个叶节点只有一个爆）和每个分裂节点的随机特征数m=5的情况下的RF提供了最好的结果。得到的相关系数是0.52)</strong></li>
</ol>
</blockquote>
<h3 id="5-2-Regression-Feature-Importance"><a href="#5-2-Regression-Feature-Importance" class="headerlink" title="5.2 Regression Feature Importance"></a>5.2 Regression Feature Importance</h3><blockquote>
<p><strong>The area under the ROC curve is now replaced by the redshift correlation coefficient.(使用相关系数来取代ROC曲线)</strong><br><strong>The correlation coefficient starts from a sub-optimal value for the first feature, then increases, eventually flattens after the 11-th feature, and then slowly decreases beyond 16-th feature. We selected the first 11 features in this plot as input features for the machine-z estimator. Adding features beyond 11 does not improve predictions and increases the risk of overfitting or diluting the signal with noisy features.(相关系数从第一特征的次优值开始，然后增加，最终在第11个特征之后变平，然后在超过第16个特征后开始慢慢减小。 我们选择了该图中的前11个特征作为machine-z估计器的输入特征. 添加超过11个特征不会显著改善预测结果，并可能伴随过拟合的风险).</strong><br><strong>Relative importance of machine-z regression features. The Pearson correlation coefficient is shown as a function of the next best feature starting from the single best feature at the bottom of the plot. Features selected for the final machine-z estimation are shown in red.(机器z回归特征的相对重要性. Pearson从图的底部开始相关系数作为从单个最佳特征开始得到下一个最佳特征的函数。 为最终machine-z估计选择的特征以红色显示.)</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795939595.png" alt="Alt text"></p>
</blockquote>
<h3 id="5-3-Correction-for-Noise-and-Imbalance"><a href="#5-3-Correction-for-Noise-and-Imbalance" class="headerlink" title="5.3 Correction for Noise and Imbalance"></a>5.3 Correction for Noise and Imbalance</h3><blockquote>
<ol>
<li><strong>A comparison between machine-z predictions and true redshift for GRBs in the training set is presented in Fig. 6. While there is a good correlation between the predicted and the actual redshift, the range of the output values is squeezed relative to the input. This appears to be a consequence of the interaction between noisy features and the fact that high-redshift bursts are strongly underrepresented in training data (see Fig. 1). (图6显示了machine-z的预测与训练集中GRB的真正红移之间的比较. 虽然预测红移和实际红移之间存在良好的相关性，但输出值的范围相对于输入被挤压.这似乎是噪声特征之间相互作用的结果，而事实上高红移爆在训练数据集中的数目不足(underrepresented adj. 未被充分代表的，代表名额不足的))</strong><br>1.1 <img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795946324.png" alt="Alt text"></li>
</ol>
<p>1.2 <img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795972633.png" alt="Alt text"></p>
<ol>
<li><strong>When high-redshift bursts are given higher weights (e.g. by including multiple copies of the same burst in training data), the bias observed in Fig. 6 changes. (当高红移突发被赋予更高权重时（例如，通过在训练数据中包括相同突发的多个副本），图6中观察到的偏差改变). </strong><br><strong>The final corrected redshift predictions are computed using a straight line fit to data in Fig. 6 and taking into account the cross-validation uncertainty in machine-z output:(使用直线拟合图6中的数据并考虑机器-z输出中的交叉验证不确定性来计算最终校正的红移预测：)</strong> <img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558796045177.png" alt="Alt text"></li>
</ol>
<p><strong>The final corrected machine-z predictions as a function of the true redshift are shown in Fig. 7. The range of the output is now similar to that of the input and the correlation coefficient is the same as in Figure 6.(最终校正的machine-z预测作为真正红移的函数如图7所示。输出的范围现在与输入的范围相似，相关系数与图6中的相同.)</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558796051882.png" alt="Alt text"></p>
<hr>
<p><strong>图7中有一些有趣的地方: </strong></p>
<ol>
<li><strong>First, the lower right area of the plot is not populated. This means that in most cases machine-z does not fail to recognize a high-redshift burst.(首先图7右下角是没有东西的，说明在绝大多数情况下machine-z对高红移的爆的识别并未失败.)</strong></li>
<li><p><strong>Second, the density of bursts peaks roughly along the dashed line, so for a significant fraction of bursts the redshift estimate is close to the true value. This can be seen more clearly in Fig. 8 showing the distribution of the relative differences between machine-z estimates and actual redshifts. (其次，爆的密度大致沿着虚线峰值，因此对于大部分的爆来说，红移估计值接近真实值。 这在图8中可以更清楚地看出，显示了machine-Z估计值与实际红移之间的相对差异的分布)</strong><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558796059879.png" alt="Alt text"></p>
</li>
<li><p><strong>Third, the algorithm does occasionally predict a high redshift for a low-z burst as shown by the upper left portion of the plot. Even though following up these false positives will tend to waste some telescope time, machine-z will rarely miss the all important high-z bursts.(第三，该算法偶尔会预测低红移爆为高红移，如图的左上部分所示。 即使跟踪这些错误的预测会浪费一些望远镜时间，但算法很少会错过所有重要的高红移爆发。)</strong></p>
</li>
<li><strong>An inconvenient side effect of our simple correction for the redshift bias is that for a few GRBs the predicted redshift is negative. This is not a problem as long as the tool is used to select high-redshift GRBs, as the negative predictions only occurr at low redshift.(我们对红移偏差的简单校正的一个不方便的副作用是，对于少数GRB，预测的红移是负的。 不过由于负值的预测仅在低红移时发生，因此对于挑选高红移GRB的这个工具来说，这都不是问题).</strong></li>
</ol>
</blockquote>
<h2 id="6-DISCUSSION"><a href="#6-DISCUSSION" class="headerlink" title="6. DISCUSSION"></a>6. DISCUSSION</h2><h3 id="6-1-Comparison-with-Previous-Work"><a href="#6-1-Comparison-with-Previous-Work" class="headerlink" title="6.1 Comparison with Previous Work"></a>6.1 Comparison with Previous Work</h3><blockquote>
<ol>
<li><strong>Morgan et al. (2012) was the first to apply machine learned classification to screen high redshift GRBs using promptly available Swift data.</strong></li>
<li><strong>The ROC curve corresponding to our data set (red curve) has a slightly larger area than that for the Morgan et al. (2012) data (blue curve). Note that the red curve rises to 100% recall more rapidly than the blue curve.(对应于我们的数据集（红色曲线）的ROC曲线具有比Morgan等人稍大的面积。 （2012）数据（蓝色曲线）。 请注意，红色曲线比蓝色曲线更快地回升到100％).</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558796067704.png" alt="Alt text"></li>
</ol>
<ol>
<li><strong>Fig. 10 presents another performance comparison of the two data sets. </strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558796076146.png" alt="Alt text"></li>
</ol>
</blockquote>
<h3 id="6-2-Validation"><a href="#6-2-Validation" class="headerlink" title="6.2 Validation"></a>6.2 Validation</h3><blockquote>
<p><strong>The results for individual bursts in the test sample are shown in Table 3. (表3中显示了测试样品中单个爆的结果).</strong><br><strong>Two out of 22 bursts (GRB 151112A and GRB 151027B) qualify as high-redshift according to our classification in section 2.1 (z &gt; 4). Both algorithms flag them as having high redshift. (根据我们在2.1节（z&gt; 4）中的分类，22个爆发中的两个（GRB 151112A和GRB 151027B）符合高红移。 两种算法都将它们标记为具有高红移).</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558796083108.png" alt="Alt text"></p>
<p><strong>In addition to these two clear cut cases, our classifier identified 8 other bursts in the validation sample as high-z. However, out of those 8 bursts only one (GRB 151111A) has a machinez estimate z &gt; 4. (除了这两个明确的案例，我们的分类器还在验证样本中将8个其他的爆划分为高红移。然而，在这8个爆中，只有一个（GRB 151111A）具有machine-z &gt; 4)(间接说明在指示是否高红移这事儿上machine-z方法要强于high-z？).</strong><br><strong>These outcomes are consistent with our performance estimates and confirm the usefulness of our tools in prioritizing follow-up observations of candidate high-redshift GRBs.We can expect that the most robust results will be obtained if both high-z classifier and machine-z estimator predict high redshift. In this case we would have selected three candidate high-z bursts shown as gray rows in Table 3,two real ones and a single false positive. Note that the false positive (GRB 151111A) is a burst with an intermediate redshift z = 3.5(这些结果与我们的表现估计一致，确认了我们的工具在优先考虑候选高红移GRB的后续观测中的有效性。如果高z分类器和机器z估计器都预测到高红移，我们可以期望获得最稳健的结果。 在这种情况下，我们将选择三个候选高z突发，在表3中显示为灰色行，两个确实为高红移的爆和一个误报。 请注意，误报（GRB 151111A）是具有中间红移z = 3.5的爆)</strong></p>
</blockquote>
<h3 id="6-3-Extensions-to-Other-Data-Sources"><a href="#6-3-Extensions-to-Other-Data-Sources" class="headerlink" title="6.3 Extensions to Other Data Sources"></a>6.3 Extensions to Other Data Sources</h3><blockquote>
<p><strong>The present paper addresses redshift prediction for Swift GRBs. Transfering a trained classifier from one data set to another is very important, but typically challenging. Unfortunately, in most cases the performance is strongly degraded even if differences between data sources are purely incidental (e.g. slightly different energy ranges of flux measurements or different estimators of model parameters).(本文讨论了Swift GRB的红移预测。 将训练有素的分类器从一个数据集转移到另一个数据集非常重要，但通常具有挑战性。 不幸的是，在大多数情况下，即使数据源之间的差异纯粹是偶然的（例如，通量测量的能量范围略有不同或模型参数的不同估计），性能也会大大降低.)</strong><br><strong>If the new features are qualitatively similar to the old ones, one can shift and rescale the numbers to approximately match the distribution of each new and old feature. This requires only a modest amount of new data and may be a productive approach for future missions similar to Swift including Space-based multi-band astronomical Variable Objects Monitor (SVOM; Cordier et al. (2015)). In other cases we are forced to build new training sets and that can be time consuming.(如果新特征在质量上与旧特征相似，则可以移动和重新缩放数字以大致匹配每个新旧特征的分布。这仅需要适量的新数据，并且可能是应对以后类似于Swift的任务的有效方法，包括基于空间的多波段天文变量对象监视器（SVOM; Cordier等人（2015））在其他情况下，我们被迫建立新的训练集，这可能是耗时的).</strong><br><strong>Generic intermediate level features can be obtained for example from wavelet analysis that captures the intrinsic structure of the data and then apply a high level classfier such as RF (Ukwatta and Wozniak 2016).Those “abstract” features may prove more transferable from one data set to another and may eventually facilitate early redshift prediction for GRBs detected by future missions such as SVOM. (通用中间级特征可以例如从小波分析中获得，小波分析捕获数据的内在结构，然后应用高级分类器，例如RF。这些“抽象”特征可能证明可以从一个数据集转移到另一个数据集，并最终可能促进以后的任务（如SVOM）检测到的GRB的早期红移预测)</strong></p>
</blockquote>
<h2 id="7-SUMMARY"><a href="#7-SUMMARY" class="headerlink" title="7. SUMMARY"></a>7. SUMMARY</h2><blockquote>
<p><strong>The algorithm utilizes numerical and categorical features from all three instruments onboard the Swift satellite that are readily available within the first few hours after a GRB discovery. ( 该算法利用Swift卫星上所有三种仪器的数值和分类特征，这些特征在GRB发现后的最初几个小时内随时可用).</strong></p>
</blockquote>
<h2 id="附-Feature-Engineering-简要"><a href="#附-Feature-Engineering-简要" class="headerlink" title="附: Feature Engineering(简要)"></a>附: Feature Engineering(简要)</h2><blockquote>
<p><strong>在业界广泛流传一句话：</strong><br><strong>数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。那特征工程到底是什么呢？顾名思义，其本质是一项工程活动，主要通过一系列数据预处理的方式，使其最大限度地从原始数据中提取有用的特征以供算法和模型使用，从而提高模型的预测准确率</strong></p>
<hr>
<p><strong>完整的机器学习项目流程: </strong></p>
<ol>
<li><strong>数学抽象：指的是根据数据明确任务目标，是分类、还是回归，或者是聚类或者其他等等.</strong></li>
<li><strong>数据获取：数据决定了机器学习结果的上限，而算法只是尽可能逼近这个上限.</strong></li>
<li><strong>特征工程：特征选择好了，非常简单的算法也能得出良好、稳定的结果。这需要运用特征有效性分析的相关技术，如相关系数、卡方检验、平均互信息、条件熵、后验概率、逻辑回归权重等方法. (特征工程：数据清洗、特征处理等等)</strong></li>
<li><strong>模型训练与调优：开始利用算法训练模型，需对算法原理有深入理解，才能知道如何调节模型的超参数，使得结果变得更加优良 (超参数：是指在开始模型学习过程之前设置值的参数，而不是通过训练得到的参数数据)</strong></li>
<li><strong>模型诊断：训练后的模型需要进行调优，调优后的模型需要重新进行诊断(判断是否过拟合或者欠拟合以及误差分析等)，这是一个反复迭代不断逼近的过程，需要不断地尝试， 进而达到最优状态。</strong></li>
<li><strong>模型融合/集成：模型融合就是综合考虑不同模型的情况，并将它们的结果融合到一起，使结果获得提升. (Ensemble Learning—集成学习；Bagging ,Boosting, Stacking；GBDT，AdaBoost，Xgboost，RF…)</strong></li>
<li><strong>上线运行： 这一部分内容主要跟工程实现的相关性更大。工程上是结果导向，模型在线上运行的效果直接决定模型的成败。不单纯包括其准确程度、误差等情况，还包括其运行的速度(时间复杂度)、资源消耗程度（空间复杂度）、稳定性是否可接受.</strong></li>
</ol>
<hr>
<p><strong>数据缺失值处理方法(简要)：</strong></p>
<ol>
<li><strong>删除</strong>：<br>1.1 <strong>简单删除法：</strong><br><strong>此方法将存在缺失值的数据条目（对象，元组，记录）进行删除。这种方法简单易行，在对象有多个属性缺失值、被删除的含缺失值的对象与信息表中的数据量相比非常小的情况下是非常有效的。</strong><br>2.2 <strong>权重法</strong>：<br><strong>当缺失值的类型为非完全随机缺失的时候，可以通过对完整的数据加权来减小偏差。把数据不完全的个案标记后，将完整的数据个案赋予不同的权重，个案的权重可以通过logistic或probit回归求得。</strong></li>
<li><strong>填补</strong>：<br>2.1 <strong>人工填补（filling manually）</strong><br>2.2 <strong>特殊值填充（Treating Missing Attribute values as Special values）</strong><br>2.3 <strong>均值填充（Mean/Mode Completer）</strong><br>2.4 <strong>热卡填充（Hot deck imputation，或就近补齐）</strong><br>2.5 <strong>聚类填充(clustering imputation)</strong><br>2.6 <strong>使用所有可能的值填充（Assigning All Possible values of the Attribute）</strong><br>2.7 <strong>组合完整化方法（Combinatorial Completer）</strong><br>2.8 <strong>回归（Regression）</strong><br>2.9 <strong>极大似然估计（Max Likelihood ，ML）</strong><br>2.10 <strong>多重插补（Multiple Imputation，MI）</strong></li>
<li><strong>不处理：直接在包含空值的数据上进行数据挖掘。这类方法包括贝叶斯网络和人工神经网络等。</strong></li>
<li><a href="https://www.cnblogs.com/lantingg/p/8492631.html" target="_blank" rel="noopener">缺失值处理方法综述</a>；<a href="https://blog.csdn.net/ge341204/article/details/80720369?utm_source=blogxgwz2" target="_blank" rel="noopener">机器学习中数据缺失值处理方法</a></li>
</ol>
</blockquote>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Stoner</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://yoursite.com/2019/05/25/machine-Z/">http://yoursite.com/2019/05/25/machine-Z/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://yoursite.com" target="_blank">Stoner的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%A4%A9%E4%BD%93%E7%89%A9%E7%90%86%E5%AD%A6/">天体物理学</a><a class="post-meta__tags" href="/tags/%E8%B6%85%E6%96%B0%E6%98%9F%E9%AB%98%E7%BA%A2%E7%A7%BB/">超新星高红移</a><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%88%86%E7%B1%BB/">机器学习分类</a></div><div class="post_share"><div class="social-share" data-image="http://qe0z9wdl5.bkt.clouddn.com/20200726220919.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2019/05/25/tensorboard-summary/"><img class="prev-cover" data-src="http://qe0z9wdl5.bkt.clouddn.com/20200725231424.png" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Tensorboard以及Summary类总结</div></div></a></div><div class="next-post pull-right"><a href="/2019/05/25/PCA/"><img class="next-cover" data-src="http://qe0z9wdl5.bkt.clouddn.com/20200725231725.png" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">PCA手动实现及推导</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2019/05/25/XMM-NEWTON/" title="XMM-Newton软件安装"><img class="relatedPosts_cover" data-src="http://qe0z9wdl5.bkt.clouddn.com/20200725231322.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2019-05-25</div><div class="relatedPosts_title">XMM-Newton软件安装</div></div></a></div><div class="relatedPosts_item"><a href="/2019/05/25/xmm-newton-EPIC/" title="XMM-Newton EPIC数据处理过程"><img class="relatedPosts_cover" data-src="http://qe0z9wdl5.bkt.clouddn.com/20200725230911.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2019-05-25</div><div class="relatedPosts_title">XMM-Newton EPIC数据处理过程</div></div></a></div></div></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 By Stoner</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://jerryc.me/" target="_blank" rel="noopener">blog</a>!</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><button id="readmode" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font_plus" title="放大字体"><i class="fas fa-plus"></i></button><button id="font_minus" title="缩小字体"><i class="fas fa-minus"></i></button><button class="translate_chn_to_cht" id="translateLink" title="简繁转换">繁</button><button id="darkmode" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" title="设置"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="/js/third-party/fireworks.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script defer id="ribbon" src="/js/third-party/canvas-ribbon.js" size="150" alpha="0.6" zIndex="-1" mobile="true" data-click="true"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><script src="/js/search/local-search.js"></script><script>if (document.getElementsByClassName('mermaid').length) {
  loadScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js',function () {
    mermaid.initialize({
      theme: 'default',
  })
})
}</script><script>var endLoading = function () {
  document.body.style.overflow = 'auto';
  document.getElementById('loading-box').classList.add("loaded")
}
window.addEventListener('load',endLoading)</script></body></html>