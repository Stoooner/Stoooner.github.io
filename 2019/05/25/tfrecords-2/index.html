<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>创建自己的训练数据集--TFrecords实战 | Stoner的博客</title><meta name="description" content="Tfrecords理论介绍、使用方法以及相关博客链接.  1. 前言 &amp;#160; &amp;#160; &amp;#160;刚开始学习TensorFlow的时候都是跑官方的例子：比如我们熟知的：MNIST手写体数据集或者cifar-10&#x2F;100数据集，这些数据集都是官方以及整理好了的，直接使用就好。但是后面实际上不可能总是官方的数据集跑一跑就能学好TensorFlow的，所以一些项目需要处理自己的数据，整理自"><meta name="keywords" content="tfrecord"><meta name="author" content="Stoner"><meta name="copyright" content="Stoner"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://yoursite.com/2019/05/25/tfrecords-2/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta property="og:type" content="article"><meta property="og:title" content="创建自己的训练数据集--TFrecords实战"><meta property="og:url" content="http://yoursite.com/2019/05/25/tfrecords-2/"><meta property="og:site_name" content="Stoner的博客"><meta property="og:description" content="Tfrecords理论介绍、使用方法以及相关博客链接.  1. 前言 &amp;#160; &amp;#160; &amp;#160;刚开始学习TensorFlow的时候都是跑官方的例子：比如我们熟知的：MNIST手写体数据集或者cifar-10&#x2F;100数据集，这些数据集都是官方以及整理好了的，直接使用就好。但是后面实际上不可能总是官方的数据集跑一跑就能学好TensorFlow的，所以一些项目需要处理自己的数据，整理自"><meta property="og:image" content="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg"><meta property="article:published_time" content="2019-05-25T08:37:57.000Z"><meta property="article:modified_time" content="2019-06-21T04:28:54.000Z"><meta name="twitter:card" content="summary"><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'false'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="prev" title="WGAN一些需要注意的细节" href="http://yoursite.com/2019/05/25/WGAN-2/"><link rel="next" title="原始数据划分以及TFrecords实战" href="http://yoursite.com/2019/05/25/tfrecords-1/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: false,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: true,
  fancybox: false,
  Snackbar: {"bookmark":{"message_prev":"按","message_next":"键将本页加入书签"},"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: false,
  islazyload: true,
  isanchor: false    
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true
  }</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.1"><link rel="alternate" href="/atom.xml" title="Stoner的博客" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><canvas class="fireworks"></canvas><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">48</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">62</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">16</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content toc-div-class" style="display:none"></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">Stoner的博客</a></span><span class="pull-right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">创建自己的训练数据集--TFrecords实战</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2019-05-25 16:37:57"><i class="far fa-calendar-alt fa-fw"></i> 发表于 2019-05-25</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2019-06-21 12:28:54"><i class="fas fa-history fa-fw"></i> 更新于 2019-06-21</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fas fa-inbox fa-fw post-meta__icon"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="meta-secondline"> </div><div class="meta-thirdline"><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta__icon"></i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><blockquote>
<p><strong>Tfrecords理论介绍、使用方法以及相关博客链接.</strong><br><a id="more"></a></p>
</blockquote>
<h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a>1. 前言</h2><blockquote>
<p>&#160; &#160; &#160;刚开始学习<strong>TensorFlow</strong>的时候都是跑官方的例子：比如我们熟知的：<strong>MNIST</strong>手写体数据集或者<strong>cifar-10/100</strong>数据集，这些数据集都是官方以及整理好了的，直接使用就好。但是后面实际上不可能总是官方的数据集跑一跑就能学好<strong>TensorFlow</strong>的，所以一些项目需要处理自己的数据，整理自己的数据集。做过<strong>Kaggle</strong>竞赛的应该很熟悉<strong>.csv</strong>文件了，<strong>.csv</strong>文件非常方便,但是通常读取的时候,是一次性读取到内存里面的.要是内存小的话,就要想其他的办法了,那就变得很麻烦了. </p>
<p>&#160; &#160; &#160;或者有时候,从硬盘上面直接读取图片啊什么的,因为图片的文件格式,存放位置各种各样等等一些因素,要是想在训练阶段直接这么使用的话,就更加麻烦了.所以,对于数据进行统一的管理是很有必要的<strong>.TFRecord</strong>就是对于输入数据做统一管理的格式.加上一些多线程的处理方式,使得在训练期间对于数据管理把控的效率和舒适度都好于暴力的方法. </p>
<p>&#160; &#160; &#160;小的任务什么方法差别不大,但是对于大的任务,使用统一格式管理的好处就非常显著了.因此,TFRecord的使用方法很有必要熟悉. </p>
<p>&#160; &#160; &#160;自己通过查找很多资料，完成了一个简单的自己的图片通过<strong>TFRecord</strong>做成数据集以在<strong>TensorFlow</strong>运行的例子，现将其汇总，以便日后以往还能查找到。</p>
</blockquote>
<h2 id="2-TFrecord实战代码"><a href="#2-TFrecord实战代码" class="headerlink" title="2. TFrecord实战代码"></a>2. <strong>TFrecord</strong>实战代码</h2><blockquote>
<p>&#160; &#160; &#160;1. 自己的图片的<strong>TFrecords</strong><br>```</p>
<h1 id="coding-utf-8"><a href="#coding-utf-8" class="headerlink" title="__ coding:utf-8 __"></a>_<em>_ coding:utf-8 _</em>_</h1><p>‘’’<br>    做过kaggle竞赛的应该很熟悉.csv文件了,.csv文件非常方便,但是通常读取的时候,是一次性读取到内存里面的.<br>要是内存小的话,就要想其他的办法了,那就变得很麻烦了. 或者有时候,从硬盘上面直接读取图片啊什么的,因为图片的文件格式,<br>存放位置各种各样等等一些因素,要是想在训练阶段直接这么使用的话,就更加麻烦了.所以,对于数据进行统一的管理是很有必要的.<br>TFRecord就是对于输入数据做统一管理的格式.加上一些多线程的处理方式,<br>使得在训练期间对于数据管理把控的效率和舒适度都好于暴力的方法.<br>小的任务什么方法差别不大,但是对于大的任务,使用统一格式管理的好处就非常显著了.因此,TFRecord的使用方法很有必要熟悉.</p>
</blockquote>
<pre><code>本程序主要用于将自己的数据做成Tfrecords，以便tensorflow能够很好的进行划分batch和Tensor读取
</code></pre><p>对于数据量较小而言，可能一般选择直接将数据加载进内存，然后再分batch输入网络进行训练<br>如果数据量较大，这样的方法就不适用了，因为太耗内存，所以这时最好使用tensorflow提供的队列queue，<br>也就是从文件读取数据。对于一些特定的读取，比如csv文件格式，官网有相关的描述，<br>这里引入一种比较高效的读取方法（官网介绍的少），即使用tensorflow内定标准格式——TFRecords。</p>
<pre><code>TFRecords其实是一种二进制文件，虽然它不如其他格式好理解，但是它能更好的利用内存，更方便复制和移动，并且不需要单独的标签文件。
</code></pre><p>TFRecords文件包含了tf.train.Example 协议内存块(protocol buffer)(协议内存块包含了字段 Features)。<br>我们可以写一段代码获取你的数据， 将数据填入到Example协议内存块(protocol buffer)，将协议内存块序列化为一个字符串，<br>并且通过tf.python_io.TFRecordWriter 写入到TFRecords文件。</p>
<pre><code>从TFRecords文件中读取数据， 可以使用tf.TFRecordReader的tf.parse_single_example解析器。
</code></pre><p>这个操作可以将Example协议内存块(protocol buffer)解析为张量。<br>‘’’</p>
<h1 id="导入相关的包"><a href="#导入相关的包" class="headerlink" title="导入相关的包"></a>导入相关的包</h1><p>import os<br>import tensorflow as tf<br>from PIL import Image<br>import matplotlib.pyplot as plt<br>import time</p>
<p>EPOCH = 5</p>
<h1 id="设置batch-size的大小"><a href="#设置batch-size的大小" class="headerlink" title="设置batch_size的大小"></a>设置batch_size的大小</h1><p>BATCH_SIZE = 5</p>
<h1 id="设置出队后最小剩余量"><a href="#设置出队后最小剩余量" class="headerlink" title="设置出队后最小剩余量"></a>设置出队后最小剩余量</h1><p>min_after_dequeue = 10</p>
<h1 id="设置队列的容量"><a href="#设置队列的容量" class="headerlink" title="设置队列的容量"></a>设置队列的容量</h1><p>capacity = min_after_dequeue + 4 * BATCH_SIZE<br>OUTPUT_SIZE = 440</p>
<h1 id="OUTPUT-SIZE-630"><a href="#OUTPUT-SIZE-630" class="headerlink" title="OUTPUT_SIZE = 630"></a>OUTPUT_SIZE = 630</h1><h1 id="图片通道数为3，代表彩色"><a href="#图片通道数为3，代表彩色" class="headerlink" title="图片通道数为3，代表彩色"></a>图片通道数为3，代表彩色</h1><p>DEPTH = 3</p>
<h1 id="定义各个路径"><a href="#定义各个路径" class="headerlink" title="定义各个路径"></a>定义各个路径</h1><p>data_path = ‘data/‘<br>tfrecords_path = ‘tfrecords/‘</p>
<h1 id="需要生产的-tfrecords数目"><a href="#需要生产的-tfrecords数目" class="headerlink" title="需要生产的.tfrecords数目"></a>需要生产的.tfrecords数目</h1><p>tfrecords_num = 6</p>
<h1 id="用于获取项目所在绝对路径"><a href="#用于获取项目所在绝对路径" class="headerlink" title="用于获取项目所在绝对路径"></a>用于获取项目所在绝对路径</h1><h1 id="cwd-D-软件安装-pycharm-PyCharm-Community-Edition-2017-3-3-workplace-TFrecods-practicing"><a href="#cwd-D-软件安装-pycharm-PyCharm-Community-Edition-2017-3-3-workplace-TFrecods-practicing" class="headerlink" title="cwd = D:\软件安装\pycharm\PyCharm Community Edition 2017.3.3\workplace\TFrecods_practicing"></a>cwd = D:\软件安装\pycharm\PyCharm Community Edition 2017.3.3\workplace\TFrecods_practicing</h1><h1 id="这里可以获取cwd，也可以不用获取，反正我使用的是相对路径-relative-path-也一样能行"><a href="#这里可以获取cwd，也可以不用获取，反正我使用的是相对路径-relative-path-也一样能行" class="headerlink" title="这里可以获取cwd，也可以不用获取，反正我使用的是相对路径(relative path)也一样能行"></a>这里可以获取cwd，也可以不用获取，反正我使用的是相对路径(relative path)也一样能行</h1><p>cwd = os.getcwd()</p>
<h1 id="把传入的value转化为整数型的属性，int64-list对应着-tf-train-Example-的定义"><a href="#把传入的value转化为整数型的属性，int64-list对应着-tf-train-Example-的定义" class="headerlink" title="把传入的value转化为整数型的属性，int64_list对应着 tf.train.Example 的定义"></a>把传入的value转化为整数型的属性，int64_list对应着 tf.train.Example 的定义</h1><p>def _int64_feature(value):<br>    return tf.train.Feature(int64_list = tf.train.Int64List(value = [value]))</p>
<h1 id="把传入的value转化为字符串型的属性，bytes-list对应着-tf-train-Example-的定义"><a href="#把传入的value转化为字符串型的属性，bytes-list对应着-tf-train-Example-的定义" class="headerlink" title="把传入的value转化为字符串型的属性，bytes_list对应着 tf.train.Example 的定义"></a>把传入的value转化为字符串型的属性，bytes_list对应着 tf.train.Example 的定义</h1><p>def _byte_feature(value):<br>    return tf.train.Feature(bytes_list = tf.train.BytesList(value = [value]))</p>
<h1 id="生成TFRecords文件"><a href="#生成TFRecords文件" class="headerlink" title="生成TFRecords文件"></a>生成TFRecords文件</h1><p>def create_record(data_path,tfrecords_path,tfrecords_num):</p>
<pre><code>rows = 32
cols = 32
depth = DEPTH

#第一个for循环确定要将自己的数据划分为多少个.tfrecords文件
for i in range(tfrecords_num):
    # 先定义writer对象，writer负责将得到的记录写入TFRecords文件，此处有多个.tfrecords文件
    writer = tf.python_io.TFRecordWriter(tfrecords_path + str(i) + &quot;.tfrecords&quot;)
    #os.listdir() 方法用于返回指定的文件夹包含的文件或文件夹的名字的列表。这个列表以字母顺序。 它不包括 &#39;.&#39; 和&#39;..&#39; 即使它在文件夹中。
    #一张一张的写入TFRecords文件(这里有15张照片，准备划分为5个.tfrecords,每三张划分到一个.tfrecords文件)
    #当然，.tfrecords的数目和每次划分的数据的数目的乘积不一定满足总的数据的数目
    #img_name:[]
    for img_name in os.listdir(data_path)[i*BATCH_SIZE:(i+1)*BATCH_SIZE]:
        &#39;&#39;&#39;
        img_name:
            1.JPG
            10.JPG
            11.jpg
            12.JPG
            13.jpg
            14.jpg
            15.JPG
            2.JPG
            3.JPG
            4.JPG
            5.JPG
            6.JPG
            7.JPG
            8.JPG
            9.JPG
        &#39;&#39;&#39;
        # 打开图片
        img_path = data_path + img_name
        img = Image.open(img_path)

        #对图片做一些预处理操作
        img = img.resize((OUTPUT_SIZE, OUTPUT_SIZE))
        # 设置裁剪参数
        h, w = img.size[:2]
        j, k = (h - OUTPUT_SIZE) / 2, (w - OUTPUT_SIZE) / 2
        box = (j, k, j + OUTPUT_SIZE, k + OUTPUT_SIZE)
        # 裁剪图片
        img = img.crop(box=box)

        # 将图片转化为原生bytes
        img_raw = img.tobytes()
        #使用tf.train.Example来封装我们的数据
        example = tf.train.Example(features=tf.train.Features(feature={
            &#39;height&#39;: _int64_feature(rows),
            &#39;width&#39;: _int64_feature(cols),
            &#39;depth&#39;: _int64_feature(depth),
            &#39;img_raw&#39;: _byte_feature(img_raw),
            &#39;label&#39;: _int64_feature(i)
        }))
        #Example调用SerializeToString()方法将自己序列化并由
        #writer = tf.python_io.TFRecordWriter(&quot;train.tfrecords&quot;)对象保存，
        #最终是将所有的图片文件和label保存到同一个tfrecords文件中
        writer.write(example.SerializeToString())
writer.close()
</code></pre><p>‘’’<br>基本的，一个Example中包含Features，Features里包含Feature（这里没s）的字典。<br>最后，Feature里包含有一个 FloatList， 或者ByteList，或者Int64List</p>
<ul>
<li>tf.train.FloatList：列表每个元素为float。</li>
<li>tf.train.Int64List：列表每个元素为int64。</li>
<li>tf.train.BytesList：列表每个元素为string。<br>‘’’</li>
</ul>
<p>‘’’<br>读取数据则以上过程的逆，先获取序列化数据，再解析：<br>一旦生成了TFRecords文件，接下来就可以使用队列（queue）读取数据了<br>TF多线程机制：<br>‘’’<br>def read_and_decode(filename):</p>
<pre><code>#读取tfrecords文件名到队列中，使用tf.train.string_input_producer函数，该函数可以接收一个文件名列表，
#并自动返回一个对应的文件名队列filename_queue，之所以用队列是为了后续多线程考虑（队列和多线程经常搭配使用）
filename_queue = tf.train.string_input_producer(filename)
#实例化tf.TFRecordReader()类生成reader对象，接收filename_queue参数，并读取该队列中文件名对应的文件，
reader = tf.TFRecordReader()
#得到serialized_example(读到的就是.tfrecords序列化文件)
_, serialized_example = reader.read(filename_queue)
&#39;&#39;&#39;
tf.parse_single_example函数，该函数能从serialized_example中解析出一条数据,
这里tf.parse_single_example函数传入参数serialized_example和features，其中features是字典的形式，
指定每个key的解析方式，比如image_raw使用tf.FixedLenFeature方法解析，这种解析方式返回一个Tensor，
大多数解析方式也都是这种，另一种是tf.VarLenFeature方法，返回SparseTensor，用于处理稀疏数据，不再多提。
这里还要注意必须告诉解析函数以何种数据类型解析，这必须与生成TFRecords文件时指定的数据类型一致。
最后返回features是一个字典，里面存放了每一项的解析结果。
最后只要读出features中的数据即可。比如，features[&#39;label&#39;],features[&#39;pixels&#39;]。
但要注意的是，此时的image_raw依然是字符串类型的，需要进一步还原成像素数组，
用TF提供的函数tf.decode_raw来搞定：images = tf.decode_raw(features[&#39;image_raw&#39;],tf.uint8)。

&#39;&#39;&#39;
features = tf.parse_single_example(serialized_example,
                                   features={
                                       &#39;label&#39;: tf.FixedLenFeature([], tf.int64),
                                       #这里解析图片的类型与生成TFrecords文件是指定images的类型得一致
                                       #所以解析的时候使用string类型，但是images解析出来是string，还需要
                                       #将其进一步还原为像素数组(无符号8位---uint8类型)
                                       &#39;img_raw&#39; : tf.FixedLenFeature([], tf.string),
                                   })

imgs = tf.decode_raw(features[&#39;img_raw&#39;], tf.uint8)
imgs = tf.reshape(imgs, [OUTPUT_SIZE, OUTPUT_SIZE, 3])
#tf.cast(x, dtype, name=None) 对于传入的数据将其数据格式转换为dtype类型。
imgs = tf.cast(imgs, tf.float32) * (1. / 255)
labels = tf.cast(features[&#39;label&#39;], tf.int32)

&#39;&#39;&#39;
上面已经得到了images和labels,这是一条数据，训练一次需要一个batch的数据，
TF提供了tf.train.shuffle_batch函数，上述解析代码只要提供一次，
然后将labels和images作为tf.train.shuffle_batch函数的参数，
tf.train.shuffle_batch就能自动获取到一个batch的labels和images。
tf.train.shuffle_batch函数获取batch的过程需要生成一个队列（加入计算图中），
然后一个一个入队labels和images，然后出队组合batch.
batch_size就是batch的大小，capacity指的是队列的容量，比如capacity设为1，而batch_szie为3，
那么组成一个batch的过程中，出队的操作就会因为数据不足而频繁地被阻塞来等待入队加入数据，运行效率很低。
相反，如果capacity被设置的很大，比如设为1000，而batch_size设置为3，那么入队操作在空闲时就会频繁入队，
供过于求并非坏事，糟糕的是这样会占用很多内存资源，而且没有得到多少效率上的提升。
还有一点值得注意，当使用tf.train.shuffle_batch时，为了使得shuffle效果好一点，出队后队列剩余元素必须得足够多，
因为太少的话也没什么必要打乱了，因此tf.train.shuffle_batch函数要求提供min_after_dequeue参数来
保证出队后队内元素足够多，这样队列就会等队内元素足够多时才会出队。
显而易见，capacity必须大于min_after_dequeue。min_after_dequeue根据数据集大小和batch_size综合考虑，
而capacity则通常设置为capacity= min_after_dequeue + 3*batch_size，在效率和资源占用之间取得平衡。
&#39;&#39;&#39;

#制作打乱顺序的batch
img_batch, label_batch = tf.train.shuffle_batch([imgs, labels], batch_size=BATCH_SIZE,
                                                capacity=capacity,
                                                min_after_dequeue=min_after_dequeue)

return img_batch,label_batch
</code></pre><h1 id="TFRecords-collection-模型汇总"><a href="#TFRecords-collection-模型汇总" class="headerlink" title="TFRecords_collection(模型汇总)"></a>TFRecords_collection(模型汇总)</h1><p>def TFRecords_collection():</p>
<pre><code># 注意os.path.isfile只是判断传入的文件是否存在,而os.path.exists()则是判断文件或者文件夹是否存在
# 这里判断.tfrecords文件是否已经写入成功
if os.path.isfile(tfrecords_path + &#39;0.tfrecords&#39;):
    print(&#39;--------------.tfrecords文件已存在--------------&#39;)
else:
    start_time = time.time()
    print(&#39;--------------开始制作tfrecords--------------&#39;)
    # 制作tfrecords
    create_record(data_path, tfrecords_path, tfrecords_num)
    print(&#39;------------制作结束：耗时%.2f seconds-----------&#39; % (time.time() - start_time))

# os.path模块主要用于文件的属性获取,os.path.join(path1[, path2[, ...]])将多个路径组合后返回，
# 第一个绝对路径之前的参数将被忽略
filenames = [os.path.join(tfrecords_path, &#39;%d.tfrecords&#39; % ii) for ii in range(tfrecords_num)]
# 获取img_batch和label_batch
img_batch, label_batch = read_and_decode(filenames)
# 打印img_batch和label_batch的type,发现都是Tensor类型
&#39;&#39;&#39;
img_batch.type Tensor(&quot;shuffle_batch:0&quot;, shape=(5, 440, 440, 3), dtype=float32)
label_batch.type Tensor(&quot;shuffle_batch:1&quot;, shape=(5,), dtype=int32)
&#39;&#39;&#39;
print(&#39;img_batch.type&#39;, img_batch)
print(&#39;label_batch.type&#39;, label_batch)

# 初始化所有的op
init = tf.global_variables_initializer()

with tf.Session() as sess:
    sess.run(init)
    # 启用队列，tf.train.start_queue_runners函数，这个函数中传入参数sess,就可以做到多线程训练
    threads = tf.train.start_queue_runners(sess=sess)

    for i in range(EPOCH):
        plt.figure(figsize=(15, 15))
        value, label = sess.run([img_batch, label_batch])
        print(&#39;第%d次打印标签:&#39; % (i + 1), label)
        print(&#39;value.shape:&#39;, value.shape)
        print(&#39;value.type&#39;, type(value))
        for j in range(BATCH_SIZE):
            # 每个batch的照片数目：value.shape[0]
            plt.subplot(1, value.shape[0], (j + 1))
            plt.imshow(value[j:j + 1, :, :, :].reshape(OUTPUT_SIZE, OUTPUT_SIZE, 3))
        plt.show()
#需要注意的是，如果需要对图片裁切大小的OUTPUT_SIZE进行更改的话，一定要将tfrecords文件夹的.tfrecords文件
#全部删除，因为.tfrecoeds是上一次保存的，也就包含了上一次图片裁切大小的OUTPUT_SIZE的设定，
#所以，如果不删除，则会导致读取了上一次的.tfrecords文件，而导致图片.reshape失败，从而程序报错
#中间遇到一个错误就是这个，改了很久都没效果，所以要记住。
</code></pre><p>if <strong>name</strong> == ‘<strong>main</strong>‘:<br>    TFRecords_collection()</p>
<pre><code>
&gt;&amp;#160; &amp;#160; &amp;#160;2. Kaggle猫狗大战(Cats_vs_Dogs)训练集**TFrecords**
</code></pre><h1 id="coding-utf-8-1"><a href="#coding-utf-8-1" class="headerlink" title="-- coding: utf-8 --"></a>-<em>- coding: utf-8 -</em>-</h1><p>import os<br>import tensorflow as tf<br>from PIL import Image<br>import matplotlib.pyplot as plt<br>import numpy as np</p>
<p>data_path = ‘Cat_vs_Dog/‘<br>tfrecords_path = ‘Cat_vs_Dog_tfrecords/‘<br>filename = os.path.join(tfrecords_path,’train.tfrecords’)<br>BATCH_SIZE = 4</p>
<h1 id="预先定义自己的类-如果数据集类别比较多，可以批量读取，比如我的train文件夹下面有一百多个文件夹，"><a href="#预先定义自己的类-如果数据集类别比较多，可以批量读取，比如我的train文件夹下面有一百多个文件夹，" class="headerlink" title="预先定义自己的类(如果数据集类别比较多，可以批量读取，比如我的train文件夹下面有一百多个文件夹，"></a>预先定义自己的类(如果数据集类别比较多，可以批量读取，比如我的train文件夹下面有一百多个文件夹，</h1><h1 id="每个存放相应类别图片，我的classes就这样读出来的——classes-os-listdir-train-dir"><a href="#每个存放相应类别图片，我的classes就这样读出来的——classes-os-listdir-train-dir" class="headerlink" title="每个存放相应类别图片，我的classes就这样读出来的——classes = os.listdir(train_dir))"></a>每个存放相应类别图片，我的classes就这样读出来的——classes = os.listdir(train_dir))</h1><p>classes = {‘cats’, ‘dogs’}</p>
<p>def _int64_feature(value):<br>    return tf.train.Feature(int64_list = tf.train.Int64List(value = [value]))</p>
<p>def _bytes_feature(value):<br>    return tf.train.Feature(bytes_list = tf.train.BytesList(value = [value]))</p>
<p>def create_record(data_path,tfrecords_path):</p>
<pre><code># 输出成TFrecords文件
writer = tf.python_io.TFRecordWriter(tfrecords_path + &#39;train.tfrecords&#39;)
for index, name in enumerate(classes):
    class_path = data_path + name + &#39;/&#39;
    for img_name in os.listdir(class_path):
        img_path = class_path + img_name    #每个图片的地址
        img = Image.open(img_path)
        img = img.resize((208, 208))
        img_raw = img.tobytes()  #将图片转化为二进制格式
        example = tf.train.Example(features = tf.train.Features(feature = {
                                                            &quot;label&quot;: _int64_feature(index),
                                                            &quot;img_raw&quot;: _bytes_feature(img_raw),
                                                                           }))
        writer.write(example.SerializeToString())  #序列化为字符串
writer.close()
</code></pre><p>def read_and_decode(filename, batch_size): #读取.tfrecords文件</p>
<pre><code># 创建一个队列
filename_queue = tf.train.string_input_producer([filename])
reader = tf.TFRecordReader()
#返回文件名和文件
_, serialized_example = reader.read(filename_queue)
#features保存&#39;label&#39;和&#39;img_raw&#39;
features = tf.parse_single_example(serialized_example,
                                   features={
                                       &#39;label&#39;: tf.FixedLenFeature([], tf.int64),
                                       &#39;img_raw&#39; : tf.FixedLenFeature([], tf.string),
                                   })

img = tf.decode_raw(features[&#39;img_raw&#39;], tf.uint8)
img = tf.reshape(img, [208, 208, 3])  #reshape image to 512*80*3
</code></pre><h1 id="img-tf-cast-img-tf-float32-1-255-0-5-throw-img-tensor"><a href="#img-tf-cast-img-tf-float32-1-255-0-5-throw-img-tensor" class="headerlink" title="img = tf.cast(img, tf.float32) * (1. / 255) - 0.5 #throw img tensor"></a>img = tf.cast(img, tf.float32) * (1. / 255) - 0.5 #throw img tensor</h1><pre><code>label = tf.cast(features[&#39;label&#39;], tf.int32) #throw label tensor

img_batch, label_batch = tf.train.shuffle_batch([img, label],
                                                batch_size= batch_size,
                                                num_threads=64,
                                                capacity=2000,
                                                min_after_dequeue=1500,
                                                )
return img_batch, tf.reshape(label_batch,[batch_size])
</code></pre><p>if <strong>name</strong> == ‘<strong>main</strong>‘:<br>    create_record(data_path, tfrecords_path)<br>    image_batch, label_batch = read_and_decode(filename, BATCH_SIZE)<br>    print(‘image_batch.type:’,image_batch)<br>    print(‘label_batch.type:’, label_batch)</p>
<pre><code>with tf.Session()  as sess:
    i = 0
    # 启动多线程处理输入数据
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(coord=coord)

    try:
        while not coord.should_stop() and i&lt;1:
            # just plot one batch size
            image, label = sess.run([image_batch, label_batch])
            print(&#39;image.type:&#39;,type(image))
            print(&#39;image.shape:&#39;,image.shape)
            plt.figure(figsize=(10, 8))
            for j in np.arange(BATCH_SIZE):
                # print()
                plt.subplot(2, image.shape[0]/2, (j + 1))
                plt.title(&#39;label: %d&#39; % label[j],fontsize = 16)
                plt.imshow(image[j,:,:,:])
            plt.show()
            i+=1
    except tf.errors.OutOfRangeError:
        print(&#39;done!&#39;)
    finally:
        # When done, ask the threads to stop.
        coord.request_stop()
    #等待线程结束
    coord.join(threads)
</code></pre><p>‘’’<br>可以利用sklearn下的train_test_split()方法将数据分为三部分，训练集、开发集、验证集，例如：<br>train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.4, random_state=40)<br>‘’’<br>```</p>
<h2 id="3-参考链接以及相关附注"><a href="#3-参考链接以及相关附注" class="headerlink" title="3. 参考链接以及相关附注"></a>3. 参考链接以及相关附注</h2><p>&#160; &#160; &#160;1. 项目的图片如下：<br>&#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/tfrecords-2/b.png" alt><br>&#160; &#160; &#160;2. 参考链接：</p>
<blockquote>
<p>&#160; &#160; &#160;1. <a href="https://github.com/Blssel/TF-learing/blob/master/tfrecord/readme.md" target="_blank" rel="noopener">Github：TF-learing/tfrecord/readme.md</a><br>&#160; &#160; &#160;2. <a href="https://www.jianshu.com/p/ec456fbbcf45" target="_blank" rel="noopener">简书：TensorFlow高效读取数据 | Ycszen-物语</a><br>&#160; &#160; &#160;3. <a href="https://zhuanlan.zhihu.com/p/27238630" target="_blank" rel="noopener">十图详解tensorflow数据读取机制（附代码</a><br>&#160; &#160; &#160;4. <a href="https://blog.csdn.net/xierhacker/article/details/72357651" target="_blank" rel="noopener">TensorFlow学习（十一）：保存TFRecord文件</a><br>&#160; &#160; &#160;5. <a href="https://lguduy.github.io/2017/05/20/TensorFlow%E6%95%99%E7%A8%8B-%E5%A4%84%E7%90%86%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE/#%E5%89%8D%E8%A8%80" target="_blank" rel="noopener">TensorFlow教程：利用TensorFlow处理自己的数据</a><br>&#160; &#160; &#160;6. <a href="https://blog.csdn.net/shenxiaolu1984/article/details/52857437" target="_blank" rel="noopener">TensorFlow动手玩：数据导入2</a><br>&#160; &#160; &#160;7. <a href="https://blog.csdn.net/wiinter_fdd/article/details/72835939" target="_blank" rel="noopener">用Tensorflow处理自己的数据：制作自己的TFRecords数据集——Cats_vs_Dogs</a><br>&#160; &#160; &#160;8. <a href="https://blog.csdn.net/Best_Coder/article/details/70141075?locationNum=3&amp;fps=1" target="_blank" rel="noopener">Tensorflow 训练自己的数据集（一）（数据直接导入到内存）</a><br>&#160; &#160; &#160;9. <a href="https://www.cnblogs.com/wktwj/p/7227544.html" target="_blank" rel="noopener">tensorflow训练自己的数据集实现CNN图像分类1</a><br>&#160; &#160; &#160;10. <a href="https://blog.csdn.net/yimi_ac/article/details/79008555" target="_blank" rel="noopener">tensorflow实现逻辑回归，在kaggle《泰坦尼克》训练并测试准确率</a></p>
</blockquote>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Stoner</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://yoursite.com/2019/05/25/tfrecords-2/">http://yoursite.com/2019/05/25/tfrecords-2/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://yoursite.com" target="_blank">Stoner的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/tfrecord/">tfrecord</a></div><div class="post_share"><div class="social-share" data-image="http://qe0z9wdl5.bkt.clouddn.com/20200725214526.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2019/05/25/WGAN-2/"><img class="prev-cover" data-src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">WGAN一些需要注意的细节</div></div></a></div><div class="next-post pull-right"><a href="/2019/05/25/tfrecords-1/"><img class="next-cover" data-src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">原始数据划分以及TFrecords实战</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2019/05/25/tfrecords-1/" title="原始数据划分以及TFrecords实战"><img class="relatedPosts_cover" data-src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2019-05-25</div><div class="relatedPosts_title">原始数据划分以及TFrecords实战</div></div></a></div></div></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 By Stoner</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://jerryc.me/" target="_blank" rel="noopener">blog</a>!</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><button id="readmode" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font_plus" title="放大字体"><i class="fas fa-plus"></i></button><button id="font_minus" title="缩小字体"><i class="fas fa-minus"></i></button><button class="translate_chn_to_cht" id="translateLink" title="简繁转换">繁</button><button id="darkmode" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" title="设置"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="/js/third-party/fireworks.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script defer id="ribbon" src="/js/third-party/canvas-ribbon.js" size="150" alpha="0.6" zIndex="-1" mobile="true" data-click="true"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><script src="/js/search/local-search.js"></script><script>if (document.getElementsByClassName('mermaid').length) {
  loadScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js',function () {
    mermaid.initialize({
      theme: 'default',
  })
})
}</script><script>var endLoading = function () {
  document.body.style.overflow = 'auto';
  document.getElementById('loading-box').classList.add("loaded")
}
window.addEventListener('load',endLoading)</script></body></html>