<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>模组进行视频录制及HEVC视频编解码</title>
      <link href="/2020/07/29/%E6%A8%A1%E7%BB%84%E8%BF%9B%E8%A1%8C%E8%A7%86%E9%A2%91%E5%BD%95%E5%88%B6%E5%8F%8AHEVC%E8%A7%86%E9%A2%91%E7%BC%96%E8%A7%A3%E7%A0%81/"/>
      <url>/2020/07/29/%E6%A8%A1%E7%BB%84%E8%BF%9B%E8%A1%8C%E8%A7%86%E9%A2%91%E5%BD%95%E5%88%B6%E5%8F%8AHEVC%E8%A7%86%E9%A2%91%E7%BC%96%E8%A7%A3%E7%A0%81/</url>
      
        <content type="html"><![CDATA[<p><strong>内容说明</strong>：记录模组录制音视频以及HEVC视频编解码过程.<br><a id="more"></a></p><h2 id="1-视频录制"><a href="#1-视频录制" class="headerlink" title="1. 视频录制"></a>1. 视频录制</h2><ol><li>将模组与电脑进行连接；</li><li>模组进行视频录制有三种方式：<blockquote><p>2.1 网页端进行视频录制；<br>2.2 <strong>VLC</strong>进行视频录制；<br>2.3 <strong>ffmpeg</strong>进行录制；</p></blockquote></li><li>这里使用<strong>ffmpeg</strong>的方式进行录制。打开<strong>ffmpeg</strong>，其中该文件夹下的内容如下：<br><img src= "/img/loading.gif" data-src="http://qe0z9wdl5.bkt.clouddn.com/1595900974999.png" alt><br>其中红色框起来的四个<strong>.bat</strong>文件分别对应模组摄像头的四个<strong>Stream</strong>进行视频查看，也即打开摄像头查看外部景象，但是不会进行视频录制。这四个文件的代码基本一致，都是调用<strong>ffplay</strong>进行视频的查看播放，代码如下：    <pre><code>ffplay rtsp://169.254.28.10/stream0</code></pre>上述<strong>.bat</strong>内部就是这样一句话，其中<strong>ffplay</strong>代表调用的是<strong>ffplay.exe</strong>，接下来的<strong>rtsp://169.254.28.10/stream0</strong>代表的是格式为<strong>rtsp</strong>的<strong>ip</strong>为<strong>169.254.28.10</strong>的模组的第一个流<strong>stream0</strong>；通过运行上述这一代码，便可打开摄像头开到景象：<br><img src= "/img/loading.gif" data-src="http://qe0z9wdl5.bkt.clouddn.com/1595901416918.png" alt><br><img src= "/img/loading.gif" data-src="http://qe0z9wdl5.bkt.clouddn.com/1595901453964.png" alt><br>相应的，需要查看别的流是否正常的时候，就调用别的流的<strong>.bat</strong>文件即可；</li><li>要进行视频的录制，需要点击带<strong>dump</strong>的<strong>.bat</strong>文件，这种文件调用的则是<strong>ffmpeg.exe</strong>进行的视频录制：<br><img src= "/img/loading.gif" data-src="http://qe0z9wdl5.bkt.clouddn.com/1595901761058.png" alt><br><img src= "/img/loading.gif" data-src="http://qe0z9wdl5.bkt.clouddn.com/1595901781078.png" alt><br>对应的代码为：<pre><code>ffmpeg.exe  -i rtsp://169.254.28.10/stream0 -c copy -f h264 test_stream_1.h264</code></pre>其中，<strong>-i, -c, -f</strong>为对应的需要传入的参数。可以看到帧的数目以及录制的视频的文件大小都在不停的变动，当视频录制完毕之后便可关闭<strong>cmd</strong>页面，相应的，在<strong>ffmpeg</strong>文件夹下也就有了对应的录制好的视频：<br><img src= "/img/loading.gif" data-src="http://qe0z9wdl5.bkt.clouddn.com/1595901883955.png" alt><br>对于录制好的视频，需要查看其码流、码率等相关一些参数的时候，使用<strong>Elecard StreamEye Demo</strong>这一软件，直接将录制好的视频文件拖入该软件即可：<br><img src= "/img/loading.gif" data-src="http://qe0z9wdl5.bkt.clouddn.com/1595902095866.png" alt></li></ol><h2 id="2-HEVC视频编解码"><a href="#2-HEVC视频编解码" class="headerlink" title="2. HEVC视频编解码"></a>2. HEVC视频编解码</h2><h3 id="2-1-HEVC编解码器工程文件编译"><a href="#2-1-HEVC编解码器工程文件编译" class="headerlink" title="2.1 HEVC编解码器工程文件编译"></a>2.1 HEVC编解码器工程文件编译</h3><ol><li>首先，需要将<strong>Visual Studio2015</strong>打开，然后在主界面点击<strong>文件—打开—项目/解决方案(P)</strong>：<br><img src= "/img/loading.gif" data-src="http://qe0z9wdl5.bkt.clouddn.com/1596009063506.png" alt></li><li>找到<strong>HEVC</strong>编码器的工程文件<strong>HM-16.7</strong>，打开<strong>HM-16.7/build/HM_vc2013.sln</strong>文件；</li><li>在主界面右边的<strong>HM_vc2013</strong>项目这里右键点击<strong>生产解决方案(B)</strong>选项；</li><li>等待项目编译，项目编译完毕之后，在下面的控制台会看到：<br><img src= "/img/loading.gif" data-src="http://qe0z9wdl5.bkt.clouddn.com/1596009318020.png" alt></li></ol><h3 id="2-2-HEVC解码-编码"><a href="#2-2-HEVC解码-编码" class="headerlink" title="2.2 HEVC解码/编码"></a>2.2 HEVC解码/编码</h3><blockquote><p>使用<strong>HEVC</strong>编码器对视频进行编解码，相应的操作流程和命令行格式如下：</p></blockquote><ol><li>首先<strong>HM</strong>项目编译完毕之后，会在其<strong>\bin\vc2013\Win32\Debug </strong>文件夹下生产包括编解码器等可执行文件(<strong>exe</strong>)在内的多个文件，其中使用解码器就用<strong>TAppDecoder.exe</strong>，使用编码器就用<strong>TAppEncoder.exe</strong>：<br><img src= "/img/loading.gif" data-src="http://qe0z9wdl5.bkt.clouddn.com/1596009911404.png" alt></li><li>通过模组上的摄像头以及<strong>ffmpeg</strong>进行视频拍摄之后，得到相应的编码文件<strong>ksh_stream_1.h265</strong>，需要注意的是在<strong>mplayer_h264_dump_1.bat</strong>文件中，设定的格式是<strong>h264</strong>(<strong>ffmpeg</strong>暂不支持<strong>h265</strong>)，但是实际上，我们的<strong>Stream0</strong>设定的格式是<strong>h265</strong>的，所以这里<strong>ffmpeg</strong>设定的格式对其无影响；</li><li>对编码文件<strong>ksh_stream_1.h265</strong>进行解码，解码还原为<strong>YUV</strong>文件，相应的命令行格式如下：</li></ol><pre><code>TAppDecoder.exe -b \xx路径\xxname.h265 -o \xx路径\xxx.yuv</code></pre><p>其中<strong>-b</strong>后面接的是需要进行解码的编码码流，<strong>-o</strong>后面接的是解码后对应的解码文件；需要注意的是，<strong>POC 0-24</strong>代表的是<strong>GOP</strong>组中对应的<strong>I帧/P帧/B帧</strong>等图片；</p><ol><li>相应的，对编码了的码流能够进行编码，也就相应的可以对解码了的<strong>YUV</strong>文件进行编码，使用的是命令行格式如下：</li></ol><pre><code>TAppEncoder.exe -c xxxname.cfg -wdt 1280 -hgt 720 -fr 25 -f 500 -i xxxname.yuv -b xxxxname.h265</code></pre><p>其中，一些参数的解释如下：</p><blockquote><ul><li>-wdt 横向分辨率</li><li>-hgt 纵向分辨率</li><li>-fr 帧率</li><li>-f 编码帧数(对原解码YUV文件进行多少帧的编码)</li><li>-i 输入文件</li><li>-b 输出文件</li></ul></blockquote><p><img src= "/img/loading.gif" data-src="http://qe0z9wdl5.bkt.clouddn.com/1596012520636.png" alt><br><img src= "/img/loading.gif" data-src="http://qe0z9wdl5.bkt.clouddn.com/1596012577881.png" alt><br>其中，<strong>.cfg</strong>文件是编码时候需要选择的编码方式配置文件，这个配置文件可以在<strong>\HM-16.7\cfg\\</strong>文件夹下进行选择的。</p><h2 id="3-参考资料"><a href="#3-参考资料" class="headerlink" title="3. 参考资料"></a>3. 参考资料</h2><blockquote><ol><li><a href="https://tieba.baidu.com/p/2325281215?pid=32688262646&amp;see_lz=1&amp;red_tag=0406128317" target="_blank" rel="noopener">hm10编码教程；</a></li><li><a href="https://blog.csdn.net/weixin_30236595/article/details/94985105" target="_blank" rel="noopener">各种视频编码器的命令行格式；</a></li><li><a href="https://blog.csdn.net/wangcm04/article/details/25813237" target="_blank" rel="noopener">HM13.0 TAppDecoder参数设置；</a></li><li><a href="https://blog.csdn.net/u010485442/article/details/38308013" target="_blank" rel="noopener">HM学习心得2；</a></li><li><a href="https://blog.csdn.net/leixiaohua1020/article/details/49912113" target="_blank" rel="noopener">HEVC官方软件HM源代码简单分析-编码器TAppEncoder；</a></li><li><a href="https://space.bilibili.com/432184234/channel/detail?cid=129412" target="_blank" rel="noopener">音视频高手开发；</a></li><li><a href="https://space.bilibili.com/542307689/video?keyword=ffmpeg" target="_blank" rel="noopener">FFmpeg入门；</a></li><li><a href="https://space.bilibili.com/576287359/video?keyword=%E9%9F%B3%E8%A7%86%E9%A2%91" target="_blank" rel="noopener">音视频开发；</a></li></ol></blockquote>]]></content>
      
      
      <categories>
          
          <category> 视频编解码 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 硬件 </tag>
            
            <tag> 模组 </tag>
            
            <tag> codec </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>评分卡模型中的IV和WOE详解</title>
      <link href="/2020/07/27/IV-WOE/"/>
      <url>/2020/07/27/IV-WOE/</url>
      
        <content type="html"><![CDATA[<p><strong>内容说明</strong>：评分卡中各个特征的筛选和模型性能评估的指标.<br><a id="more"></a></p><h2 id="1-IV的用途"><a href="#1-IV的用途" class="headerlink" title="1. IV的用途"></a>1. IV的用途</h2><p><strong>IV</strong>的全称是<strong>Information Value</strong>，中文意思是信息价值，或者信息量。我们在用逻辑回归、决策树等模型方法构建分类模型时，经常需要对自变量(也就是我们说的特征，<strong>Features</strong>)进行筛选。比如我们有$200$个候选自变量，通常情况下，不会直接把$200$个变量直接放到模型中去进行拟合训练，而是会用一些方法，从这$200$个自变量中挑选一些出来，放进模型，形成入模变量列表。那么我们怎么去挑选入模变量呢？</p><p>挑选入模变量过程是个比较复杂的过程，需要考虑的因素很多，比如：</p><blockquote><ul><li><strong>变量的预测能力</strong>；</li><li><strong>变量之间的相关性</strong>；</li><li><strong>变量的简单性（容易生成和使用）</strong>；</li><li><strong>变量的强壮性（不容易被绕过）</strong>；</li><li><strong>变量在业务上的可解释性（被挑战时可以解释的通）等等</strong>。</li></ul></blockquote><p>但是，其中最主要和最直接的衡量标准是变量的预测能力。</p><p><strong>“变量的预测能力”</strong>这个说法很笼统，很主观，非量化，在筛选变量的时候我们总不能说：“我觉得这个变量预测能力很强，所以他要进入模型”吧？我们需要一些具体的量化指标来衡量每自变量的预测能力，并根据这些量化指标的大小，来确定哪些变量进入模型。<strong>IV</strong>就是这样一种指标，他可以用来衡量自变量的预测能力。类似的指标还有<strong>信息增益、基尼系数</strong>等等。</p><h2 id="2-对IV的直观理解"><a href="#2-对IV的直观理解" class="headerlink" title="2. 对IV的直观理解"></a>2. 对IV的直观理解</h2><p>从直观逻辑上大体可以这样理解<strong>“用IV去衡量变量预测能力”</strong>这件事情：我们假设在一个分类问题中，<strong>目标变量(也就是我们所说的标签)</strong>类别两类：$Y_1，Y_2$。</p><p>对于一个待预测的个体$A$(也就是一个样本)，要判断$A$属于类别$Y_1$还是$Y_2$，我们是需要一定的信息的，假设这个信息总量是$I$，而这些所需要的信息，就蕴含在所有的自变量$C_1，C_2，C_3，……，C_n$中。</p><p>那么，对于其中的一个变量$C_i$来说，其蕴含的信息越多，那么它对于判断$A$属于$Y_1$还是$Y_2$的贡献就越大，$C_i$的信息价值就越大，$C_i$的$IV$就越大，它就越应该进入到入模变量列表中。</p><h2 id="3-IV的计算"><a href="#3-IV的计算" class="headerlink" title="3. IV的计算"></a>3. IV的计算</h2><p>前面我们从感性角度和逻辑层面对<strong>IV</strong>进行了解释和描述，那么回到数学层面，对于一个待评估变量，他的<strong>IV</strong>值究竟如何计算呢？为了介绍<strong>IV</strong>的计算方法，我们首先需要认识和理解另一个概念——<strong>WOE</strong>，因为<strong>IV</strong>的计算是以<strong>WOE</strong>为基础的。</p><h3 id="3-1-WOE"><a href="#3-1-WOE" class="headerlink" title="3.1 WOE"></a>3.1 WOE</h3><p><strong>WOE</strong>的全称是<strong>“Weight of Evidence”</strong>，即证据权重。<strong>WOE</strong>是对原始自变量的一种编码形式。</p><p>要对一个变量进行<strong>WOE</strong>编码，需要首先把这个变量进行分组处理（也叫离散化、分箱等等，说的都是一个意思）。分组后，对于第<strong>i</strong>组，<strong>WOE</strong>的计算公式如下：</p><script type="math/tex; mode=display">WOE_i = \ln \frac{P_{y_i}}{P_{n_i}} = \ln \frac{\#y_i/\#y_T}{\#n_i/\#n_T}</script><p>其中:</p><blockquote><ul><li>$P_{y_i}$是这个组中响应客户(风险模型中，对应的是违约客户，总之，指的是模型中预测变量或者说标签取值为<strong>“是”</strong>或者取值为$1$的个体)占所有样本中所有响应客户比例;</li><li>$P_{n_i}$是这个组中未响应客户占样本中所有未响应客户的比例;</li><li>$\#y_i$是这个组中响应客户的数量，$\#n_i$是这个组中未响应客户的数量，$\#y_T$是样本中所有响应客户的数量，$\#n_T$是样本中所有未响应客户的数量。</li></ul></blockquote><p>从这个公式中我们可以体会到，<strong>WOE</strong>表示的实际上是<strong>“当前分组中响应客户占所有响应客户的比例”</strong>和<strong>“当前分组中没有响应的客户占所有没有响应的客户的比例”</strong>的差异。对这个公式做一个简单变换，可以得到：</p><script type="math/tex; mode=display">WOE_i = \ln \frac{P_{y_i}}{P_{n_i}} = \ln \frac{\#y_i/\#y_T}{\#n_i/\#n_T} = \ln \frac{\#y_i/\#n_i}{\#y_T/\#n_T}</script><p>变换以后我们可以看出，<strong>WOE</strong>也可以这么理解，<strong><em>他表示的是当前这个组中响应的客户和未响应客户的比值，和所有样本中这个比值的差异。</em></strong>这个差异是用这两个比值的比值，再取对数来表示的。</p><p><strong>WOE</strong>越大，这种差异越大，这个分组里的样本响应的可能性就越大，<strong>WOE</strong>越小，差异越小，这个分组里的样本响应的可能性就越小(其实，<strong>WOE</strong>的公式就是一个<strong>Odds</strong>的公式)。关于<strong>WOE</strong>编码所表示的意义，大家可以自己再好好体会一下。</p><h3 id="3-2-IV的计算公式"><a href="#3-2-IV的计算公式" class="headerlink" title="3.2 IV的计算公式"></a>3.2 IV的计算公式</h3><p>有了前面的介绍，我们可以正式给出<strong>IV</strong>的计算公式。对于一个分组后的变量，第<strong>i</strong>组的<strong>WOE</strong>前面已经介绍过，是这样计算的：</p><script type="math/tex; mode=display">WOE_i = \ln \frac{P_{y_i}}{P_{n_i}} = \ln \frac{\#y_i/\#y_T}{\#n_i/\#n_T} = \ln \frac{\#y_i/\#n_i}{\#y_T/\#n_T}</script><p>同样，对于分组<strong>i</strong>，也会有一个对应的<strong>IV</strong>值，计算公式如下：</p><script type="math/tex; mode=display">IV_i = (P_{y_i} - P_{n_i}) * WOE_i = (P_{y_i} - P_{n_i}) * \ln\frac{P_{y_i}}{P_{n_i}} \\ = (\#y_i/\#y_T - \#n_i/\#n_T) * \ln\frac{\#y_i/\#y_T}{\#n_i/\#n_T}</script><p>有了一个变量各分组的<strong>IV</strong>值，我们就可以计算整个变量的<strong>IV</strong>值，方法很简单，就是把各分组的<strong>IV</strong>相加：</p><script type="math/tex; mode=display">IV = \sum_i^{n}IV_i</script><p>其中$n$为变量分组个数(也就是这个特征被离散化之后的份数)。</p><h3 id="3-3-用实例介绍IV的计算和使用"><a href="#3-3-用实例介绍IV的计算和使用" class="headerlink" title="3.3 用实例介绍IV的计算和使用"></a>3.3 用实例介绍IV的计算和使用</h3><p>下面我们通过一个实例来讲解一下IV的使用方式。</p><h4 id="3-3-1-实例"><a href="#3-3-1-实例" class="headerlink" title="3.3.1 实例"></a>3.3.1 实例</h4><p>假设我们需要构建一个预测模型，这个模型是为了预测公司的客户集合中的每个客户对于我们的某项营销活动是否能够响应，或者说我们要预测的是客户对我们的这项营销活动响应的可能性有多大。假设我们已经从公司客户列表中随机抽取了<strong>100000</strong>个客户进行了营销活动测试，收集了这些客户的响应结果，作为我们的建模数据集，其中响应的客户有<strong>10000</strong>个。另外假设我们也已经提取到了这些客户的一些变量，作为我们模型的候选变量集，这些变量包括以下这些(实际情况中，我们拥有的变量可能比这些多得多，这里列出的变量(特征)仅是为了说明我们的问题)：</p><blockquote><ul><li><strong>最近一个月是否有购买</strong>；</li><li><strong>最近一次购买金额</strong>；</li><li><strong>最近一笔购买的商品类别</strong>；</li><li><strong>是否是公司VIP客户</strong>；</li></ul></blockquote><p>假设，我们已经对这些变量进行了离散化，统计的结果如下面几张表所示。</p><ul><li><strong>最近一个月是否有过购买：</strong><br><img src= "/img/loading.gif" data-src="http://qe0z9wdl5.bkt.clouddn.com/1583806730177.png" alt="图1. 最近一个月的购买情况"></li><li><strong>最近一次购买金额：</strong><br><img src= "/img/loading.gif" data-src="http://qe0z9wdl5.bkt.clouddn.com/1583806768409.png" alt="图2. 最近一次购买金额情况"></li><li><strong>最近一笔购买的商品类别：</strong><br><img src= "/img/loading.gif" data-src="http://qe0z9wdl5.bkt.clouddn.com/1583806789695.png" alt="图3. 最近一笔购买的商品类别情况"></li><li><strong>是否是公司VIP客户：</strong><br><img src= "/img/loading.gif" data-src="http://qe0z9wdl5.bkt.clouddn.com/1583806825151.png" alt="图4. 是否是公司的VIP客户"></li></ul><h4 id="3-3-2-计算WOE和IV"><a href="#3-3-2-计算WOE和IV" class="headerlink" title="3.3.2 计算WOE和IV"></a>3.3.2 计算WOE和IV</h4><p>我们以其中的一个变量<strong>“最近一次购买金额”</strong>变量为例：<br><img src= "/img/loading.gif" data-src="http://qe0z9wdl5.bkt.clouddn.com/1583806875756.png" alt><br><img src= "/img/loading.gif" data-src="http://qe0z9wdl5.bkt.clouddn.com/1583806886656.png" alt><br>我们把这个变量离散化为了$4$个分段：$&lt;100元，[100,200)，[200,500)，\geqslant500$元。首先，根据<strong>WOE</strong>计算公式，这四个分段的<strong>WOE</strong>分别为：<br><img src= "/img/loading.gif" data-src="http://qe0z9wdl5.bkt.clouddn.com/1583807164160.png" alt><br>插播一段，从上面的计算结果中我们可以看一下<strong>WOE</strong>的基本特点：</p><blockquote><ul><li>当前分组中，响应的比例越大，<strong>WOE</strong>值越大；</li><li>当前分组<strong>WOE</strong>的正负，由当前分组响应和未响应的比例，与样本整体响应和未响应的比例的大小关系决定，当前分组的比例小于样本整体比例时，<strong>WOE</strong>为负<strong>(对数函数的性质决定的)</strong>；相应的，当前分组的比例大于整体比例时，<strong>WOE</strong>为正；当前分组的比例和整体比例相等时，<strong>WOE</strong>为$0$;</li><li><strong>WOE</strong>的取值范围是全体实数。</li></ul></blockquote><p>我们进一步理解一下<strong>WOE</strong>，会发现，<strong>WOE</strong>其实描述了这个离散化的变量(特征)在当前的离散化分组下，对判断个体是否会响应（或者说属于哪个类）所起到影响方向和大小，当<strong>WOE</strong>为正时，变量当前取值对判断个体是否会响应起到的正向的影响，当<strong>WOE</strong>为负时，起到了负向影响。而<strong>WOE</strong>值的大小，则是这个影响的大小的体现。</p><p>好，回到正题，计算完<strong>WOE</strong>，我们分别计算四个分组的<strong>IV</strong>值：<br><img src= "/img/loading.gif" data-src="http://qe0z9wdl5.bkt.clouddn.com/1583808418826.png" alt><br>再插播一段，从上面IV的计算结果我们可以看出<strong>IV</strong>的以下特点：</p><blockquote><ul><li>对于变量的一个分组，这个分组的响应和未响应的比例与样本整体响应和未响应的比例相差越大，$IV$值越大，否则，$IV$值越小；</li><li>极端情况下，当前分组的响应和未响应的比例和样本整体的响应和未响应的比例相等时，$IV$值为$0$；</li><li>$IV$值的取值范围是$[0,+\infty)$，也就是说前面的权重$(P_{y_i} - P_{n_i})$的正负与后面的$WOE_i$的正负性是一致的，且当当前分组中只包含响应客户或者未响应客户时，$IV = +\infty$。</li></ul></blockquote><p>再次回到正题。最后，我们计算变量总<strong>IV</strong>值：<br><img src= "/img/loading.gif" data-src="http://qe0z9wdl5.bkt.clouddn.com/1583809291499.png" alt></p><h4 id="3-3-3-IV值的比较和变量预测能力的排序"><a href="#3-3-3-IV值的比较和变量预测能力的排序" class="headerlink" title="3.3.3 IV值的比较和变量预测能力的排序"></a>3.3.3 IV值的比较和变量预测能力的排序</h4><p>我们已经计算了四个变量中其中一个的<strong>WOE</strong>和<strong>IV</strong>值。另外三个的计算过程我们不再详细的说明，直接给出<strong>IV</strong>结果:</p><blockquote><ul><li>最近一个月是否有过购买：$IV = 0.250224725$；</li><li>最近一笔购买的商品类别：$IV = 0.615275563$；</li><li>是否是公司<strong>VIP</strong>客户：$IV = 1.56550367$。</li></ul></blockquote><p>前面我们已经计算过，最近一次购买金额的$IV$为$0.49270645$</p><p>这四个变量$IV$排序结果是这样的：</p><script type="math/tex; mode=display">是否是公司VIP客户 > 最近一笔购买的商品类别 > \\ 最近一次购买金额 > 最近一个月是否有过购买</script><p>我们发现<strong>“是否是公司VIP客户”</strong>这个特征是预测能力最高的变量，<strong>“最近一个月是否有过购买”</strong>这个特征是预测能力最低的变量。如果我们需要在这四个变量中去挑选变量，就可以根据<strong>IV</strong>从高到低去挑选了。在应用实践中，<strong>IV</strong>信息量大小与指标判别力有一个经验的规则：<br><img src= "/img/loading.gif" data-src="http://qe0z9wdl5.bkt.clouddn.com/1583809611915.png" alt></p><h2 id="4-关于IV和WOE的进一步思考"><a href="#4-关于IV和WOE的进一步思考" class="headerlink" title="4. 关于IV和WOE的进一步思考"></a>4. 关于IV和WOE的进一步思考</h2><h3 id="4-1-为什么用IV而不是直接用WOE"><a href="#4-1-为什么用IV而不是直接用WOE" class="headerlink" title="4.1 为什么用IV而不是直接用WOE"></a>4.1 为什么用IV而不是直接用WOE</h3><p>从上面的内容来看，变量各分组的<strong>WOE</strong>和<strong>IV</strong>都隐含着这个分组对目标变量的预测能力这样的意义。那我们为什么不直接用<strong>WOE</strong>相加或者绝对值相加作为衡量一个变量整体预测能力的指标呢？</p><p>并且，从计算公式来看，对于变量的一个分组，<strong>IV</strong>是<strong>WOE</strong>乘以这个分组响应占比和未响应占比的差。而一个变量的IV等于各分组<strong>IV</strong>的和。如果愿意，我们同样也能用<strong>WOE</strong>构造出一个这样的一个和出来，我们只需要把变量各个分组的<strong>WOE</strong>和取绝对值再相加，即（取绝对值是因为<strong>WOE</strong>可正可负，如果不取绝对值，则会把变量的区分度通过正负抵消的方式抵消掉）：</p><script type="math/tex; mode=display">WOE = \sum_i^n |WOE_i|, 其中，n为变量分组个数</script><p>那么我们为什么不直接用这个<strong>WOE</strong>绝对值的加和来衡量一个变量整体预测能力的好坏，而是要用<strong>WOE</strong>处理后的<strong>IV</strong>呢。</p><p>我们这里给出两个原因。<strong>IV</strong>和<strong>WOE</strong>的差别在于<strong>IV</strong>在<strong>WOE</strong>基础上乘以的那个权重系数$(P_{y_i} - P_{n_i})$，我们暂且用$P_{yn}$来代表这个值，也即$P_{yn} = (P_{y_i} - P_{n_i})$。</p><blockquote><ul><li>第一个原因，当我们衡量一个变量的预测能力时，我们所使用的指标值不应该是负数，否则，说一个变量的预测能力的指标是$-2.3$，听起来很别扭。从这个角度讲，乘以$P_{yn}$这个系数，保证了变量每个分组的结果都是非负数，你可以验证一下，当一个分组的<strong>WOE</strong>是正数时，$P_{yn}$也是正数，当一个分组的<strong>WOE</strong>是负数时，$P_{yn}$也是负数，而当一个分组的$WOE=0$时，$P_{yn}$也是$0$。当然，上面的原因不是最主要的，因为其实我们上面提到的$WOE = \sum_i^n |WOE_i|$这个指标也可以完全避免负数的出现；</li><li>更主要的原因，也就是第二个原因是，乘以$P_{yn}$后，体现出了变量当前分组中个体的数量占整体个体数量的比例，对变量预测能力的影响。</li></ul></blockquote><p>怎么理解第二个原因呢？我们还是举个例子。假设我们上面所说的营销响应模型中，还有一个变量$A$，其取值只有两个：$0,1$，数据如下：<br><img src= "/img/loading.gif" data-src="http://qe0z9wdl5.bkt.clouddn.com/1583811147102.png" alt><br>我们从上表可以看出，当变量$A$取值$1$时，其响应比例达到了$90\%$，非常的高，但是我们能否说变量$A$的预测能力非常强呢？不能。为什么呢？<strong>原因就在于，$A$取$1$时，响应比例虽然很高，但这个分组的客户数太少了，占的比例太低了。</strong>虽然，如果一个客户在$A$这个变量上取$1$，那他有$90\%$的响应可能性，但是一个客户变量$A$取$1$的可能性本身就非常的低。所以，对于样本整体来说，变量的预测能力并没有那么强。我们分别看一下变量各分组和整体的$WOE，IV$。<br><img src= "/img/loading.gif" data-src="http://qe0z9wdl5.bkt.clouddn.com/1583811340703.png" alt><br>从这个表我们可以看到，变量取$1$时，响应比达到$90\%$，对应的<strong>WOE</strong>很高，但对应的<strong>IV</strong>却很低，原因就在于<strong>IV</strong>在<strong>WOE</strong>的前面乘以了一个系数，而这个系数很好的考虑了这个分组中样本占整体样本的比例，比例越低，这个分组对变量整体预测能力的贡献越低。相反，如果直接用<strong>WOE</strong>的绝对值加和，会得到一个很高的指标，这是不合理的。</p><h3 id="4-2-IV的极端情况以及处理方式"><a href="#4-2-IV的极端情况以及处理方式" class="headerlink" title="4.2 IV的极端情况以及处理方式"></a>4.2 IV的极端情况以及处理方式</h3><p><strong>IV</strong>依赖<strong>WOE</strong>，并且<strong>IV</strong>是一个很好的衡量自变量对目标变量影响程度的指标。但是，使用过程中应该注意一个问题：变量的任何分组中，不应该出现响应数$=0$或非响应数$=0$的情况。</p><p>原因很简单，当变量一个分组中，响应数$=0$时，<br><img src= "/img/loading.gif" data-src="http://qe0z9wdl5.bkt.clouddn.com/1583811451181.png" alt><br>此时对应的$IV_i$为$-\infty$。<br>而当变量一个分组中，没有响应的数量$= 0$时，<br><img src= "/img/loading.gif" data-src="http://qe0z9wdl5.bkt.clouddn.com/1583811514031.png" alt><br>此时对应的$IV_i$为$+\infty$。</p><p>$IV_i$无论等于负无穷还是正无穷，都是没有意义的。<br>由上述问题我们可以看到，使用<strong>IV</strong>其实有一个缺点，就是不能自动处理变量的分组中出现响应比例为<strong>0</strong>或$100\%$的情况。那么，遇到响应比例为$0$或者$100\%$的情况，我们应该怎么做呢？建议如下：</p><blockquote><ul><li>如果可能，直接把这个分组做成一个规则，作为模型的前置条件或补充条件；</li><li>重新对变量进行离散化或分组，使每个分组的响应比例都不为$0$且不为$100\%$，尤其是当一个分组个体数很小时（比如小于$100$个），强烈建议这样做，因为本身把一个分组个体数弄得很小就不是太合理。</li><li>如果上面两种方法都无法使用，建议人工把该分组的响应数和非响应的数量进行一定的调整。如果响应数原本为$0$，可以人工调整响应数为$1$，如果非响应数原本为$0$，可以人工调整非响应数为$1$.</li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> 数据挖掘 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 评分卡 </tag>
            
            <tag> 评估指标 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode——674/830题解</title>
      <link href="/2020/07/26/leetcode-674-830/"/>
      <url>/2020/07/26/leetcode-674-830/</url>
      
        <content type="html"><![CDATA[<p><strong>内容说明</strong>：LeetCode的题目674和830的分析过程.<br><a id="more"></a></p><h2 id="1-题目描述"><a href="#1-题目描述" class="headerlink" title="1. 题目描述"></a>1. 题目描述</h2><blockquote><p><strong>674. 最长连续递增序列</strong><br><strong>题目：</strong>给定一个未经排序的整数数组，找到最长且连续的的递增序列，并返回该序列的长度。<br><strong>示例1：</strong><br>输入: [1,3,5,4,7]<br>输出: 3<br>解释: 最长连续递增序列是 [1,3,5], 长度为3。尽管 [1,3,5,7] 也是升序的子序列, 但它不是连续的，因为5和7在原数组里被4隔开。<br><strong>示例2：</strong><br>输入: [2,2,2,2,2]<br>输出: 1<br>解释: 最长连续递增序列是 [2], 长度为1。</p><hr><p><strong>830. 较大分组的位置</strong><br><strong>题目：</strong>在一个由小写字母构成的字符串 S 中，包含由一些连续的相同字符所构成的分组。例如，在字符串 S = “abbxxxxzyy” 中，就含有 “a”, “bb”, “xxxx”, “z” 和 “yy” 这样的一些分组。我们称所有包含大于或等于三个连续字符的分组为较大分组。找到每一个较大分组的起始和终止位置。最终结果按照字典顺序输出。<br><strong>示例 1：</strong><br>输入: “abbxxxxzzy”<br>输出: [[3,6]]<br>解释: “xxxx” 是一个起始于 3 且终止于 6 的较大分组。<br><strong>示例2：</strong><br>输入: “abc”<br>输出: []<br>解释: “a”,”b” 和 “c” 均不是符合要求的较大分组。<br><strong>示例3：</strong><br>输入: “abcdddeeeeaabbbcd”<br>输出: [[3,5],[6,9],[12,14]]</p></blockquote><h2 id="2-提交代码"><a href="#2-提交代码" class="headerlink" title="2. 提交代码"></a>2. 提交代码</h2><blockquote><p>题目<strong>674</strong>的代码：</p><pre><code>    class Solution:        def findLengthOfLCIS(self, nums):                result = index = 0                for i in range(len(nums)):                    if nums[i-1] &gt;= nums[i]:                        index = i                    result = max(result, i-index+1)                return result</code></pre><p>题目<strong>830</strong>的代码：</p><pre><code>    class Solution:        def largeGroupPositions(self, S: str):            # 哨兵法则            if not S:                return 0            S = S + &#39;0&#39;            result = index = 0            l = len(S)            count = []            for i in range(l):                if S[i-1] != S[i]:                    result = i - index                    if result &gt;= 3:                        count.append([index, i-1])                    index = i            return count</code></pre></blockquote><h2 id="3-题目分析"><a href="#3-题目分析" class="headerlink" title="3. 题目分析"></a>3. 题目分析</h2><p><strong>674_最长连续递增序列</strong>：<br>题解：对于题目来说，根据题意，在数组中有一段序列是连续增长且最长的，那么首先想到的就是使用双指针的方式，一个放在头部，一个放在尾部，让两个指针一前一后的进行前进，然后每次循环的时候都用尾指针减去头指针，看看现在的长度是否最大。在这个双指针的想法中，有几点想法是很重要的：</p><blockquote><ol><li>整个递增序列的前后出现了断层，也即：<strong>nums[i-1] &gt;= nums[i]</strong>，此时有序的序列断开，这个条件在循环中不断的判断递增序列是否到头了；</li><li>由于整个数组可能存在多个递增有序序列，因此需要判断出哪个递增序列最长，最笨的办法就是将有序序列的长度都保存下来，然后后续再开一个循环进行比较，但是这样明显就麻烦了，其实可以一个循环解决完有序序列判断和长度比较的工作，也即需要使用到一个变量来每次循环的时候比较一下当前这个变量保存的长度和新的有序序列的长度谁更长；</li></ol></blockquote><p>在实际操作过程中，其实可以不用费劲的去使用双指针，而是使用哨兵原则进行处理，也就是使用一个指针即可，因为在进行<strong>for</strong>循环的时候，每次循环的下标天然的就是另一个指针。因此利用那个新设定的指针<strong>index</strong>，最开始让新指针<strong>index</strong>指向数组第一个元素，当循环的<strong>i</strong>在不断的增加的时候，如果每次前后两个元素都满足<strong>nums[i-1] &lt; nums[i]</strong>，那么相应的<strong>index</strong>不动，此时随着<strong>i</strong>的移动，两个指标间的距离天然的就标识出了有序序列的长度，而当<strong>nums[i-1] &gt;= nums[i]</strong>时，预示着上一个有序序列结束了，此时哨兵<strong>index</strong>就立刻跟上<strong>i</strong>的脚步(<strong>index = i</strong>)，然后开启下一段有序序列的长度记录，顺便，上一段序列的长度与记录序列长度的变量<strong>result</strong>进行比较，得出大小，因此，整个题目最妙的就在于哨兵指标<strong>index</strong>的设立，使得指针变量的设立不必太多，一个就好；</p><hr><p><strong>830. 较大分组的位置</strong>：<br>这个题和上面的题同样的异曲同工，同样适用哨兵原则进行处理，不需要再设立两个指针才能指示长度了，因此更细的题解就不谈了；但是有一点需要注意的是，这两个题能够适用哨兵原则的关键点在于：</p><blockquote><ol><li>需要探寻整个数组中的某个序列：这个序列可能是递增的最长序列；可能是连续的最大序列；不管在进行循环的时候条件怎么不同，对于需要寻求的那个序列前后都是有明显的断层的，而且这个断层就是循环里那个关键的条件，能够用来判断是否符合题意的那个序列的条件的断层条件；</li><li>可以使用双指针进行相关的那个子序列的求解；<br>对于满足上面这两个条件的这一类题就可以使用<strong>哨兵原则</strong>进行求解了，这个就是这一类题的关键所在。</li></ol></blockquote>]]></content>
      
      
      <categories>
          
          <category> 题解 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
            <tag> LeetCode </tag>
            
            <tag> 数组 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数字视频编码技术原理</title>
      <link href="/2020/07/25/%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/"/>
      <url>/2020/07/25/%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p><strong>内容说明</strong>：关于《数字视频编码技术》相关书籍的知识点记录.<br><a id="more"></a></p><h2 id="1-第1章-概论"><a href="#1-第1章-概论" class="headerlink" title="1. 第1章 概论"></a>1. 第1章 概论</h2><h3 id="1-0-前言"><a href="#1-0-前言" class="headerlink" title="1.0 前言"></a>1.0 前言</h3><blockquote><ol><li>一帧图像：视频是按一定时间间隔获取的图像序列，序列中的一幅图像也被成为<strong>一帧图像</strong>；</li><li>数字化：为了处理、传输和存储方便，需要将图像在空间上的连续模拟量进行采样和量化，将其变为数字量的过程；</li><li>模拟视频信号在数字化过程中的过采样是导致数字视频中存在大量的数据冗余的根本原因。</li><li>在实际使用中，由于很难测定图像信号的频率，人们通常简单地将图像按照一个约定俗成的密度进行采样，例如每行$1920$个采样点，每幅图像$1080$行等。每个采样点得到的数据成为<strong>像素</strong>，一幅图像采样的行数和列数称为图像的<strong>分辨率</strong>。</li></ol></blockquote><h3 id="1-1-视觉感知"><a href="#1-1-视觉感知" class="headerlink" title="1.1 视觉感知"></a>1.1 视觉感知</h3><blockquote><ol><li>光源的能量使用<strong>光通量</strong>度量，<strong>光通量</strong>是<strong>每单位时间到达、离开或通过曲面的光能数量。</strong>光通量的单位是<strong>流明</strong>，记作：$lm$，指的是每瓦激发光源的辐射光能；</li><li>人的视觉系统<strong>human visual system(HVS)</strong>对光的感知具有融合处理能力，可以将三种基色视锥细胞的输出融合为<strong>亮度(Y)</strong>和<strong>色度/色饱和度(U、V)</strong>；</li></ol></blockquote><h3 id="1-2-数字视频"><a href="#1-2-数字视频" class="headerlink" title="1.2 数字视频"></a>1.2 数字视频</h3><blockquote><ol><li>一个数字视频系统包含采集（照相机、摄像机等）、处理（压缩、传输及解码等）和显示等几个重要模块。</li><li><strong>图像传感器（sensor）</strong>：<strong>电耦合器（CCD）</strong>和<strong>互补性氧化金属半导体（CMOS）</strong> ，其中<strong>CCD</strong>由高感光度的半导体材料构成，可以将光信号转化为电信号，所有感光单元产生的信号组合起来构成一副完整的数字图像，<strong>CCD</strong>的输出是模拟信号，连续的模拟信号通过模数转换器（A/D）转换成数字信号，<strong>CCD</strong>在扫描所有数据后将信号放大，而<strong>CMOS</strong>每扫描一个像素即刻对信号进行放大，因此用很少的能量消耗就可以进行快速扫描，<strong>CCD</strong>成像质量优于<strong>CMOS</strong>，但是成本更高；</li><li>二维视频图像的视觉质量受到单位面积采样点多少(解析度)的影响，对同样面积的视频场景，如果用高解析度的图像来表示会有更清晰的效果，相反低解析度的图像会导致模糊的效果；</li><li>通过在不同时间点上采样二维的视频场景图像，可以得到视频的多个时间采样点，数字视频序列就是由一段时间间隔内的空间采样点组成的；</li></ol></blockquote><h4 id="1-2-2-色彩空间"><a href="#1-2-2-色彩空间" class="headerlink" title="1.2.2 色彩空间"></a>1.2.2 色彩空间</h4><blockquote><ol><li>常用的色彩空间表示方法由<strong>RGB</strong>和<strong>YUV</strong>等。用<strong>RGB</strong>色彩空间表示视频图像时，一个像素需要用三个样值(即<strong>R</strong>、<strong>G</strong>、<strong>B</strong>三个色度值)表示，若每种色度成分用<strong>8 bit</strong>表示，那么彩色图像的一个像素需要<strong>24 bit</strong>表示；</li><li>人类的视觉系统对亮度的感知比对色度的感知更加敏感，因此将色彩空间分解为亮度(<strong>Y</strong>)和色度(<strong>U、V</strong>)两个基本成分，根据对<strong>Y、U、V</strong>三个分量的采样比率不同，数字视频图像可分为$4:2:0、4:2:2、4:4:4$；<br><img src= "/img/loading.gif" data-src="/2020/07/25/%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/1595405121362.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2020/07/25/%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/1595405109994.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2020/07/25/%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/1595405135108.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2020/07/25/%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/1595405149289.png" alt="Alt text"></li><li><img src= "/img/loading.gif" data-src="/2020/07/25/%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/1595405297957.png" alt="Alt text"></li></ol></blockquote><h4 id="1-2-3-视频格式"><a href="#1-2-3-视频格式" class="headerlink" title="1.2.3 视频格式"></a>1.2.3 视频格式</h4><blockquote><ol><li>一帧图像的像素点按行排列可以分为偶数行和奇数行，如果偶数行和奇数行的像素是在相同时间点采样得到的，则称该帧为<strong>逐行帧</strong>；如果偶数行和奇数行的像素在不同的时间点采样得到的，则该帧成为<strong>隔行帧</strong>，<strong>隔行帧</strong>中所有偶数行构成该图像的订场，所有奇数行构成该图像的低场；</li><li>视频在获取或者显示的时候，每秒钟按逐行扫描处理的图像数成为帧率，每秒钟按隔行扫描处理的图像数称为场率，例如每秒25帧或者50场等；</li></ol></blockquote><h3 id="1-3-视频数据冗余"><a href="#1-3-视频数据冗余" class="headerlink" title="1.3 视频数据冗余"></a>1.3 视频数据冗余</h3><blockquote><ol><li>从数字信号的统计特征方面，一般将这些数据冗余分成<strong>空间冗余、时间冗余和信息熵冗余</strong>三大类；<br><img src= "/img/loading.gif" data-src="/2020/07/25/%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/1595406584850.png" alt="Alt text"></li><li></li></ol></blockquote><h2 id="2-第2章-视频编码基础"><a href="#2-第2章-视频编码基础" class="headerlink" title="2. 第2章 视频编码基础"></a>2. 第2章 视频编码基础</h2><h3 id="2-2-香农编码定理"><a href="#2-2-香农编码定理" class="headerlink" title="2.2 香农编码定理"></a>2.2 香农编码定理</h3><ol><li><strong>离散无记忆(memoryless)信源：</strong>离散信源的一种类型. 若表示信源输出消息的随机变量序列是一个<strong>相互独立同分布的随机变量序列</strong>，在此情况下，信源先后发出的一个个符号是统计独立同分布的，即对任意正整数$N$，其$N$维联合概率分布满足：<script type="math/tex; mode=display">P(X_1, X2, ..., X_N) = \prod_{i=i}^N P(X_i)</script>换句话说，随机变量序列中的任意$N$维随机变量的联合概率分布可用随机变量中单个随机变量的概率分布的乘积来表示。这种信源称为<strong>离散无记忆信源</strong>。离散无记忆信源可用它输出的一个随机变量$X$来表示。离散无记忆信源是最简单的离散信源，可以用完备的离散型概率空间来描述，其主要特点是离散和无记忆。离散指的是信源可能输出的消息的种类是有限的或者是可数的。消息的样本空间R是一个离散集合。由于信源的每一次输出都是按照消息发生的概率输出R中的一种消息，因此信源输出的消息可以用离散随机变量X表示。无记忆是指不同的信源输出消息之间相互独立。（<a href="https://baike.baidu.com/item/%E7%A6%BB%E6%95%A3%E6%97%A0%E8%AE%B0%E5%BF%86%E4%BF%A1%E6%BA%90/19141006?fr=aladdin" target="_blank" rel="noopener">百度百科——离散无记忆信源</a>）</li></ol><hr><ol><li>目前主流的视频编码器采用的技术主要有<strong>预测、变换、量化、熵编码和环路滤波</strong>，这些技术在编码器中的基本次序关系如下图。主流的编码方法都是将图像划分成块进行编码，其中第二代标准都是划分成$16 \times 16$的宏块，第三代标准引入了更大块的划分，比如最大可到$64 \times 64$块的编码单元，以编码单元为单位进行编码。将每帧图像进行划分后，按照从上之下，从左至右的顺序对每个划分进行处理。<br><img src= "/img/loading.gif" data-src="/2020/07/25/%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/1595473825907.png" alt="Alt text"></li></ol><hr><ol><li><a href="https://zhuanlan.zhihu.com/p/75804693" target="_blank" rel="noopener">知乎专栏—码率是什么？比特率是干嘛的？帧速率是啥？分辨率又是什么？</a></li><li><a href="https://zhuanlan.zhihu.com/p/27037506" target="_blank" rel="noopener">知乎专栏—视频码率；</a></li><li><a href="https://www.zhihu.com/question/27460676/answer/36736875" target="_blank" rel="noopener">知乎—视频音频比特率（码率）与采样率有什么联系？</a></li><li><a href="http://tv.zol.com.cn/621/6216268.html" target="_blank" rel="noopener">网站视频不清晰?浅谈不可忽视的比特成本</a></li><li><a href="https://blog.csdn.net/tkp2014/article/details/51111303?locationNum=1&amp;fps=1" target="_blank" rel="noopener">什么是码率？</a></li><li><img src= "/img/loading.gif" data-src="/2020/07/25/%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/1595475863722.png" alt="Alt text"></li><li><img src= "/img/loading.gif" data-src="/2020/07/25/%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/1595475895327.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2020/07/25/%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/1595475907316.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2020/07/25/%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/1595475942755.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2020/07/25/%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/1595475950952.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2020/07/25/%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/1595475987968.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2020/07/25/%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/1595476029260.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2020/07/25/%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/1595476020931.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2020/07/25/%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/1595476043686.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2020/07/25/%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/1595476080072.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2020/07/25/%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/1595476091251.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2020/07/25/%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/1595476108553.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2020/07/25/%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/1595476117468.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2020/07/25/%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/1595478722039.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2020/07/25/%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/1595478748680.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2020/07/25/%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/1595478780251.png" alt="Alt text"><blockquote><ol><li><a href="https://www.jianshu.com/p/028196b8ca14" target="_blank" rel="noopener">码率，分辨率，帧率 …</a></li><li><a href="https://www.cnblogs.com/yongdaimi/p/10651537.html" target="_blank" rel="noopener">音视频编解码: 比特率 码率</a></li><li><a href="https://www.cnblogs.com/linuxAndMcu/p/12113242.html" target="_blank" rel="noopener">音视频基础知识—-音频编码格式（转）</a></li><li><a href="https://juejin.im/post/5cf07dfdf265da1b8466ca8c" target="_blank" rel="noopener">视频的基本参数及H264编解码相关概念</a></li><li><a href="https://www.codercto.com/a/87804.html" target="_blank" rel="noopener">ios平台实现视频H264硬编码及软编码(附完整demo)</a></li><li><a href="https://blog.csdn.net/weixin_34004750/article/details/91469605" target="_blank" rel="noopener">ios视频实现H264硬编码和软编码编译ffmpeg库及环境搭建(附完整demo)</a></li><li><a href="https://wenku.baidu.com/view/583082be590216fc700abb68a98271fe900eaf67.html" target="_blank" rel="noopener">离散无记忆的扩展信源.PPT</a></li><li><a href="https://wenku.baidu.com/view/4a2b33666ad97f192279168884868762caaebbf1.html" target="_blank" rel="noopener">二次扩展信源的熵2.PPT</a></li><li><a href="https://www.cnblogs.com/tid-think/p/10616789.html" target="_blank" rel="noopener">图像原始格式(YUV444 YUV422 YUV420)一探究竟</a></li><li><a href="https://blog.csdn.net/xjhhjx/article/details/80291465" target="_blank" rel="noopener">YUV图解 （YUV444, YUV422, YUV420, YV12, NV12, NV21）</a></li><li><a href="https://www.cnblogs.com/ziyi--caolu/p/8034367.html" target="_blank" rel="noopener">直播一：H.264编码基础知识详解</a></li><li><a href="https://www.cnblogs.com/imstudy/p/11887915.html" target="_blank" rel="noopener">零基础，史上最通俗视频编码技术入门（重要）</a></li><li><a href="http://www.52im.net/thread-228-1-1.html" target="_blank" rel="noopener">即时通讯音视频开发（一）：视频编解码之理论概述</a></li></ol></blockquote></li></ol>]]></content>
      
      
      <categories>
          
          <category> 视频编解码 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> codec </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>模组与电脑连接的整体步骤</title>
      <link href="/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/"/>
      <url>/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/</url>
      
        <content type="html"><![CDATA[<p><strong>内容说明</strong>：记录整个模组与电脑连接的相关步骤，便于记录和后续查看.<br><a id="more"></a></p><h2 id="1-模组样式及所需线材"><a href="#1-模组样式及所需线材" class="headerlink" title="1. 模组样式及所需线材"></a>1. 模组样式及所需线材</h2><p><strong>模组样式：</strong><br><img src= "/img/loading.gif" data-src="/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/1.1.jpg" alt="Alt text"><br><strong>所需线材：</strong><br><img src= "/img/loading.gif" data-src="/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/1.2.jpg" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/1.3.jpg" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/1.4.jpg" alt="Alt text"></p><h2 id="2-模组对应线材的连接方式"><a href="#2-模组对应线材的连接方式" class="headerlink" title="2. 模组对应线材的连接方式"></a>2. 模组对应线材的连接方式</h2><ol><li>首先将电源线与模组进行连接：、<br><img src= "/img/loading.gif" data-src="/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/2.1.jpg" alt="Alt text"></li><li>然后将网线的一段连接到模组对应的接口：<br><img src= "/img/loading.gif" data-src="/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/2.2.jpg" alt="Alt text"><br>相应的，网线的另一端连接到电脑的网线接口，使两个设备连接到同一个局域网中，方便进行连接，<strong>此时模组端的网线接口处闪现绿灯</strong>；<br><img src= "/img/loading.gif" data-src="/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/a.jpeg" alt="Alt text"></li><li>将一段有特殊细长方口、另一端则是<strong>USB</strong>接口的线分别连接模组和电脑对应接口:<br><img src= "/img/loading.gif" data-src="/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/b.jpeg" alt="Alt text"><br>当此线分别连接模组和电脑之后，在电脑端会自动出现相应的提示框提示连接到了相应的设备：<br><img src= "/img/loading.gif" data-src="/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/1.png" alt="Alt text"><br>相应的，在电脑的设备管理器中也能看到相应的设备，其中<strong>COM3</strong>是设备的名称；<br><img src= "/img/loading.gif" data-src="/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/2.png" alt="Alt text"></li></ol><ul><li>【备注】<strong>串行接口：</strong>简称串口，也称串行通信接口或串行通讯接口（通常指<strong>COM接口</strong>），是采用串行通信方式的扩展接口。串行接口 （<strong>Serial Interface</strong>）是指数据一位一位地顺序传送。其特点是通信线路简单，只要一对传输线就可以实现双向通信（可以直接利用电话线作为传输线），从而大大降低了成本，特别适用于远距离通信，但传送速度较慢。</li></ul><ol><li><p>点击提示框中的确定，然后打开<strong>XShell</strong>进行接下来的连接操作。在<strong>XShell</strong>中新建会话，设置相应的会话信息，点击<strong>SERIAL</strong>(串口设备)，填写会话名称，名称可随意设定，协议栏选择<strong>SERIAL</strong>：<br><img src= "/img/loading.gif" data-src="/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/3.png" alt="Alt text"></p></li><li><p>然后再次点击左边<strong>SERIAL</strong>，出现下图右边的情况，其中<strong>Port</strong>选择现在连接的模组设备的名称，也即<strong>COM3</strong>；<strong>Baud Rate</strong>设定为<strong>115200</strong>，然后剩下的选项不动，点击下方的连接按钮：<br><img src= "/img/loading.gif" data-src="/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/4.png" alt="Alt text"></p></li></ol><ol><li><p>连接成功的话可以看到下面几幅图的样子，其中模组内部其实是一个<strong>Linux</strong>系统，因此连接成功后会出现让你<strong>login</strong>的语句，其中登陆名为<strong>root</strong>，无登陆密码：<br><img src= "/img/loading.gif" data-src="/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/5.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/6.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/7.png" alt="Alt text"></p></li><li><p>登陆成功之后，按照<strong>《Goke 固件组 EVB基础操作中》</strong>的第10页PPT的两句命令进行执行：</p><pre><code> init.sh adidemo -a</code></pre></li><li>执行完毕之后查看电脑的<strong>ip地址</strong>与模组的<strong>ip地址</strong>：<br><img src= "/img/loading.gif" data-src="/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/9.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/8.png" alt="Alt text"><br>可以发现，两者的<strong>ip地址</strong>并不相同，可以通过：<pre><code> ifconfig eth0 169.254.28.10</code></pre>将两者<strong>ip地址</strong>统一到一起；</li></ol><ul><li>【备注】<strong>eth0代表的是第一块物理网卡，更多的解释请参照：<a href="https://blog.csdn.net/pzqingchong/article/details/75675618" target="_blank" rel="noopener">CSDN-eth0 eth0:1 eth0.1 的区别</a></strong></li></ul><ol><li><p>然后根据<strong>《Goke 固件组 EVB基础操作中》</strong>的第11页PPT中网络查看的内容，打开软件<strong>VLC</strong>，点击左上角的<strong>媒体——打开网络串流</strong>，然后在框中输入：</p><pre><code> rtsp://169.254.28.10/stream0</code></pre><p>其中169.254.28.10即是我们为模组设定的IP地址。<br><img src= "/img/loading.gif" data-src="/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/1595327517526.png" alt="Alt text"><br>点击播放按钮，就能看到模组的摄像头模块中拍摄到的实际画面了：<br><img src= "/img/loading.gif" data-src="/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/1595327636347.png" alt="Alt text"></p></li><li><p>最后关闭模组的时候直接拔出相应的插头即可。</p></li></ol><h2 id="3-注意事项"><a href="#3-注意事项" class="headerlink" title="3. 注意事项"></a>3. 注意事项</h2><ol><li>需要测试模组上的摄像头模块是否正常的时候需要在登陆模组的<strong>Linux系统</strong>之后，输入下面命令：<pre><code> init.sh adidemo -a</code></pre>进入到<strong>adi@goke#</strong>用户才能测试摄像头；<br><img src= "/img/loading.gif" data-src="/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/1595382610141.png" alt="Alt text"></li><li>进行<strong>XML配置</strong>的时候，首先需要退出<strong>adi@goke#</strong>用户到<strong>root</strong>目录下：<br><img src= "/img/loading.gif" data-src="/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/1595382673519.png" alt="Alt text"><br>然后进入<strong>/usr/local/bin</strong>目录中，使用<strong>vi video.xml</strong>进行<strong>xml</strong>文件的查看和修改：<br><img src= "/img/loading.gif" data-src="/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/1595382872449.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/1595382906306.png" alt="Alt text"><blockquote><p><strong>需要注意的是</strong>：<strong>Stream下的</strong>$<type>3</type>$中的<strong>3</strong>代表的是<strong>H.265</strong>，<strong>2</strong>代表的是<strong>JPEG</strong>，<strong>1</strong>代表的是<strong>H.264</strong>，<strong>0</strong>代表开关，需要注意的是<strong>Stream0/1/2/3</strong>这四个流可以同时都打开，相应的在<strong>VLC</strong>中展示的时候就可以出现多个窗口了；</p></blockquote></li></ol><h2 id="4-video-xml文件代码分析"><a href="#4-video-xml文件代码分析" class="headerlink" title="4. video.xml文件代码分析"></a>4. video.xml文件代码分析</h2><ol><li><p><strong>vin</strong>区域的代码：<br><img src= "/img/loading.gif" data-src="/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/1595385044147.png" alt="Alt text"><br>进入到<strong>video.xml</strong>文件中，<strong>vin</strong>包含的是摄像头固件的相应信息，其中：</p><p> <vi_width_a>1920</vi_width_a>代表摄像头的分辨率宽度为1920；<br> <vi_height_a>1080</vi_height_a>代表摄像头的分辨率高度为1080；<br> <vi_framerate_a>25</vi_framerate_a>代表摄像头的帧率FPS为25；<br>需要注意的是，上述的摄像头的参数是有上限和下限，不能过高或者过低，这是硬件的限制，如果设定的值过高或者过低，将造成摄像头无法正常工作，相应的，无法通过命令行进入到<strong>adi@goke#</strong>用户，也就无法拍摄到图像了。</p></li><li><p><strong>Stream</strong>区域的代码：<br><img src= "/img/loading.gif" data-src="/2020/07/21/1-%E6%A8%A1%E7%BB%84%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91/1595385764935.png" alt="Alt text"><br>模组仅有一个输入模块，也即摄像头，但是输出的流<strong>Stream</strong>却有多个，在上图中即可通过：</p><p> <StreamSetting num="4"><br>可以看出输出的流有<strong>4</strong>个。其中在<strong>Stream0</strong>中：</StreamSetting></p></li></ol><pre><code>&lt;type&gt;3&lt;/type&gt;代表图像的编码格式为3-H.265,2-JPEG,1-H.264,0-代表开关，需要注意的是Stream0/1/2/3这四个流可以同时都打开，相应的在VLC中展示的时候就可以出现多个窗口了;&lt;width&gt;1280&lt;/width&gt;代表输出流Stream0的图像分辨率宽度为1920；&lt;height&gt;720&lt;/height&gt;代表输出流Stream0的图像分辨率高度为1080；&lt;fps&gt;25&lt;/fps&gt;代表输出流Stream0的帧率FPS为25；</code></pre><blockquote><p><strong>注意：</strong>输出流的一些参数受限于摄像头的对应参数，比方说分辨率或者帧率，输出流的分辨率只能小于等于$1920\times1080$，因为这是摄像头的硬件极限，过大或者过小都会造成摄像头无法正常工作，相应的参数如帧率也是同样的道理。这里大概测试了一下<strong>Stream0</strong>在分辨率上的下限为$720\times480$，帧率的下限为$10 FPS$.</p></blockquote><h2 id="5-一些其他需要补充的知识点"><a href="#5-一些其他需要补充的知识点" class="headerlink" title="5. 一些其他需要补充的知识点"></a>5. 一些其他需要补充的知识点</h2><blockquote><ol><li><a href="https://blog.csdn.net/pc9319/article/details/79621352" target="_blank" rel="noopener">码率（Bitrate）、帧率（FPS）、分辨率和清晰度的联系与区别；</a></li><li><a href="https://blog.csdn.net/leixiaohua1020/article/details/18893769" target="_blank" rel="noopener">[总结]视音频编解码技术零基础学习方法；</a></li><li><a href="https://www.cnblogs.com/xkfz007/category/322714.html" target="_blank" rel="noopener">视频编解码学习总结博客；</a></li><li><a href="https://blog.csdn.net/qq_41603966/article/details/97525277" target="_blank" rel="noopener">串口（串行接口）相关概念；</a></li><li><a href="https://www.cnblogs.com/dalyday/p/11380252.html" target="_blank" rel="noopener">win10下安装FFmpeg步骤；</a></li><li><a href="https://www.diangon.com/m417981.html" target="_blank" rel="noopener">模拟信号为什么叫模拟信号？它到底模拟了啥？</a></li><li><a href="http://www.pomeas.cn/mobile/newsview/581.html" target="_blank" rel="noopener">什么是逐行和隔行扫描？它们有什么优缺点？</a></li><li><a href="https://blog.csdn.net/xiaojun111111/article/details/70255048" target="_blank" rel="noopener">逐行与隔行扫描的区别和原理；</a></li></ol></blockquote>]]></content>
      
      
      <categories>
          
          <category> 视频编解码 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 硬件 </tag>
            
            <tag> 模组 </tag>
            
            <tag> codec </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/07/20/hello-world/"/>
      <url>/2020/07/20/hello-world/</url>
      
        <content type="html"><![CDATA[<p><strong>内容说明：</strong>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><a id="more"></a><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="lang-bash">$ hexo new &quot;My New Post&quot;</code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="lang-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="lang-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="lang-bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>TensorFlow分布式与.pd文件相关网页</title>
      <link href="/2019/06/19/pb-website/"/>
      <url>/2019/06/19/pb-website/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>如题目所述.</strong><br><a id="more"></a></p></blockquote><h2 id="1-分布式"><a href="#1-分布式" class="headerlink" title="1. 分布式"></a>1. 分布式</h2><blockquote><ol><li><a href="https://blog.csdn.net/tiangcs/article/details/85952007" target="_blank" rel="noopener">TensorFlow分布式采坑记</a></li><li><a href="https://blog.csdn.net/luodongri/article/details/52596780" target="_blank" rel="noopener">白话tensorflow分布式部署和开发</a></li><li><a href="https://blog.csdn.net/xs11222211/article/details/82931120" target="_blank" rel="noopener">深度学习分布式训练实战（一）</a></li><li><a href="https://blog.csdn.net/xs11222211/article/details/82933764" target="_blank" rel="noopener">深度学习分布式训练实战（二）——TF</a></li><li><a href="https://blog.csdn.net/zwqjoy/article/details/89552866" target="_blank" rel="noopener">[深度学习] 一文理解分布式Tensorflow原理</a></li><li><a href="https://www.cnblogs.com/hellcat/p/9194115.html" target="_blank" rel="noopener">『TensorFlow』分布式训练_其三_多机分布式</a></li><li><a href="https://blog.csdn.net/u011026329/article/details/79190537" target="_blank" rel="noopener">TensorFlow 分布式（Distributed TensorFlow）</a></li><li><a href="https://www.jianshu.com/p/bf17ac9e6357" target="_blank" rel="noopener">TensorFlow分布式部署</a></li><li><a href="https://mc.ai/tensorflow%E4%B8%8A%E6%89%8B4-%E5%88%9D%E6%8E%A2%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/" target="_blank" rel="noopener">Tensorflow上手4: 初探分布式训练</a></li><li><a href="https://zhuanlan.zhihu.com/p/64604071" target="_blank" rel="noopener">你必须知道的六个深度炼丹好习惯</a></li><li><a href="https://blog.csdn.net/hjimce/article/details/61197190" target="_blank" rel="noopener">深度学习（五十五）tensorflow分布式训练</a>\</li><li><a href="https://www.jianshu.com/p/c189450a017d?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation" target="_blank" rel="noopener">学习笔记TF061:分布式TensorFlow，分布式原理、最佳实践</a></li><li><a href="http://xudongyang.coding.me/distributed-tensorflow/" target="_blank" rel="noopener">一文说清楚Tensorflow分布式训练必备知识</a></li></ol></blockquote><h2 id="2-pb文件"><a href="#2-pb文件" class="headerlink" title="2. pb文件"></a>2. pb文件</h2><blockquote><ol><li><a href="https://blog.csdn.net/CoderPai/article/details/68952258" target="_blank" rel="noopener">TensorFlow学习系列（三）：保存/恢复和混合多个模型</a></li><li><a href="https://blog.csdn.net/mogoweb/article/details/83064819" target="_blank" rel="noopener">如何合并两个TensorFlow模型</a></li><li><a href="https://www.jianshu.com/p/0f9f2bb962f4" target="_blank" rel="noopener">Tensorflow数据读取机制</a></li><li><a href="https://blog.csdn.net/qq26983255/article/details/85797707" target="_blank" rel="noopener">TensorFlow：将多个pb文件模型合并成一个</a></li><li><a href="https://blog.csdn.net/hustwayne/article/details/89482873" target="_blank" rel="noopener">Tensorflow： .Pb模型合并（子图合并成大图）</a></li><li><a href="https://www.huachao1001.cn/753d79ea5726181c01a2b3a983efd3cf.html" target="_blank" rel="noopener">从Tensorflow模型文件中解析并显示网络结构图（pb模型篇）</a></li></ol></blockquote>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TFServing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python代码加密</title>
      <link href="/2019/06/15/password-python/"/>
      <url>/2019/06/15/password-python/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>介绍如何以一种安全的方式加密python代码.</strong><br><a id="more"></a></p><p>我们以<strong>MNIST数据集预测手写体数字为例</strong>，实现代码加密。这里生成的是<strong>pyd</strong>文件，这个是开发<strong>cython</strong>生成的二进制脚本，可以直接当库导入，安全性来说，<strong>pyd</strong>是二进制文件，被反编译的难度相当高，其实<strong>pyd</strong>就是<strong>dll</strong>改个名字，只是必须实现特定的导出符号，按照约定的规则工作。不过即使是<strong>pyd</strong>，也不保证完全不泄漏。跟踪汇编代码就可以找到工作过程，只是这样会比反向源码成本大上超级多。<br>原始项目如下：<br><img src= "/img/loading.gif" data-src="/2019/06/15/password-python/1560607700111.png" alt="Alt text"><br>其中：</p><ul><li><strong>MNIST_data</strong>文件夹存放<strong>MNIST数据集</strong>;</li><li><strong>MNIST_model</strong>文件夹用于存放保存模型参数的文件;</li><li><strong>mnist_inference.py</strong>文件保存的是卷积网络的架构;</li><li><strong>mnist_train.py</strong>文件保存整个模型训练的代码.</li></ul></blockquote><hr><blockquote><p>整体过程如下：</p><ol><li>首先在在项目中创建<strong>setup.py</strong>文件，内部代码如下：<br>```<br>from distutils.core import setup<br>from Cython.Build import cythonize</li></ol><p>setup(name=’Hello World app’,  ext_modules=cythonize([‘mnist_train.py’, ‘mnist_inference.py’]))<br>```</p><ol><li>编译为 <strong>.c</strong>，再进一步编译为 <strong>.so</strong> 或 <strong>.pyd</strong>:<br><code>python setup.py build_ext --inplace</code></li><li>上一步完成之后会在项目中生成如下：<br><img src= "/img/loading.gif" data-src="/2019/06/15/password-python/1560608169867.png" alt="Alt text"><br>其中，<strong>build</strong>文件夹是生成过程使用到的临时文件。两个<strong>.c</strong>文件也是临时文件，可以打开看看传说中的<strong>D</strong>语言代码()。两个<strong>.pyd</strong>文件是我们所需的文件。</li><li>然后在项目中创建<strong>main.py</strong>文件，用于进入整个项目的入口：<br><img src= "/img/loading.gif" data-src="/2019/06/15/password-python/1560608401445.png" alt="Alt text"></li><li>最后对于临时文件，可以将其删除掉了(不删除也是没有问题的)：<br><img src= "/img/loading.gif" data-src="/2019/06/15/password-python/1560608494056.png" alt="Alt text"><br>最终仅留下一个可以看到源码的<strong>main.py</strong>文件，其他加密文件都是不可见的。</li><li>在运行的时候，不仅可以在<strong>IDE</strong>中直接运行，还可以在<strong>CMD</strong>下运行，只需要将需要的数据文件夹保留即可。</li></ol></blockquote>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python代码加密 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Inception Networks 相关网页</title>
      <link href="/2019/06/10/Inception-Network-pages2/"/>
      <url>/2019/06/10/Inception-Network-pages2/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>关于Inception Network架构详解的网页.</strong><br><a id="more"></a></p><ol><li><a href="https://blog.csdn.net/guyuealian/article/details/81560537" target="_blank" rel="noopener">使用自己的数据集训练GoogLenet InceptionNet V1 V2 V3模型（TensorFlow）</a></li><li><a href="https://blog.csdn.net/lujiandong1/article/details/53385092" target="_blank" rel="noopener">tensorflow将训练好的模型freeze,即将权重固化到图里面,并使用该模型进行预测</a></li><li><a href="https://blog.csdn.net/u013841196/article/details/80659132" target="_blank" rel="noopener">卷积神经网络的网络结构——Inception V3</a></li><li><a href="https://blog.csdn.net/loveliuzz/article/details/79135583" target="_blank" rel="noopener">深度学习卷积神经网络——经典网络GoogLeNet(Inception V3)网络的搭建与实现</a></li><li><a href="https://blog.csdn.net/sunbaigui/article/details/50807418" target="_blank" rel="noopener">深度学习之图像分类模型inception v2、inception v3解读</a></li><li><a href="https://blog.csdn.net/u010402786/article/details/52433324" target="_blank" rel="noopener">深入浅出——网络模型中Inception的作用与结构全解析</a></li><li><a href="https://blog.csdn.net/zziahgf/article/details/82801098" target="_blank" rel="noopener">网络结构之 Inception V3</a></li><li><a href="https://www.aiuai.cn/aifarm463.html" target="_blank" rel="noopener">网络结构之 Inception V3</a></li><li><a href="https://blog.csdn.net/stesha_chen/article/details/81259857" target="_blank" rel="noopener">GoogleLeNet(Inception-V1)论文及代码解析</a></li><li><a href="https://www.jianshu.com/p/57cccc799277" target="_blank" rel="noopener">经典分类CNN模型系列其三：Inception v1</a></li><li><a href="https://www.cnblogs.com/leebxo/p/10315490.html" target="_blank" rel="noopener">Inception Module-深度解析</a></li><li><a href="https://www.jianshu.com/p/544e2354b30a" target="_blank" rel="noopener">卷积神经网络工作原理研究 - Inception V3源代码</a></li><li><a href="https://blog.csdn.net/zzc15806/article/details/83447006" target="_blank" rel="noopener">【深度学习】GoogLeNet系列解读 —— Inception v1</a></li><li><a href="https://blog.csdn.net/q199502092010/article/details/80262348" target="_blank" rel="noopener">Inception-V1到Inception-V4</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzA3NDIyMjM1NA==&amp;mid=2649029565&amp;idx=1&amp;sn=330e398a4007b7b24fdf5203a5bf5d91&amp;chksm=871345c0b064ccd6dd7d954c90d63f1f3b883c7d487844cbe3424bec3c9abb66625f1837edbd#rd" target="_blank" rel="noopener">【模型解读】GoogLeNet中的inception结构，你看懂了吗</a></li><li><a href="https://php.ctolib.com/article/wiki/75208" target="_blank" rel="noopener">Simple TensorFlow Serving：通用和易于使用得部署机器学习模型</a></li><li><a href="https://www.infoq.cn/article/2016/02/TensorFlow-Serving" target="_blank" rel="noopener">谷歌发布 TensorFlow Serving 开源项目：更快的将深度学习模型产品商业化</a></li><li><a href="https://blog.csdn.net/l7H9JA4/article/details/82879112" target="_blank" rel="noopener">TensorFlow Serving入门</a></li><li><a href="https://zhuanlan.zhihu.com/p/45918984" target="_blank" rel="noopener">[L1]TensorFlow模型持久化~模型保存</a></li><li><a href="https://blog.csdn.net/lujiandong1/article/details/53385092" target="_blank" rel="noopener">tensorflow将训练好的模型freeze,即将权重固化到图里面,并使用该模型进行预测</a></li><li><a href="https://blog.csdn.net/u013841196/article/details/80673688" target="_blank" rel="noopener">卷积神经网络的网络结构——Inception V4</a></li><li><a href="https://blog.csdn.net/u014114990/article/details/52583912" target="_blank" rel="noopener">深入浅出——网络模型中Inceptionv1到 v4 的作用与结构全解析</a></li><li><a href="https://www.cnblogs.com/shouhuxianjian/p/7786760.html" target="_blank" rel="noopener">Feature Extractor[Inception v4]</a></li><li><a href="https://blog.csdn.net/u011021773/article/details/80791650" target="_blank" rel="noopener">极简解释inception V1 V2 V3 V4</a></li><li><a href="https://www.aiuai.cn/aifarm464.html" target="_blank" rel="noopener">网络结构之 Inception V4</a></li><li><a href="https://www.cnblogs.com/sdu20112013/p/10702173.html" target="_blank" rel="noopener">TensorRT是什么</a></li><li><a href="https://www.cnblogs.com/ranjiewen/p/8987195.html" target="_blank" rel="noopener">初见-TensorRT简介&lt;转&gt;</a></li><li><a href="https://zhuanlan.zhihu.com/p/35657027" target="_blank" rel="noopener">高性能深度学习支持引擎实战——TensorRT</a></li></ol></blockquote>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Inception Network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重要卷积神经网络结构分析</title>
      <link href="/2019/06/10/Import-CNN-Framework/"/>
      <url>/2019/06/10/Import-CNN-Framework/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>详细分析多个重要的卷积网络框架.</strong><br><a id="more"></a></p></blockquote><h2 id="1-Inception-v1-Networks"><a href="#1-Inception-v1-Networks" class="headerlink" title="1. Inception-v1 Networks"></a>1. Inception-v1 Networks</h2><h3 id="1-1-1x1卷积"><a href="#1-1-1x1卷积" class="headerlink" title="1.1 1x1卷积"></a>1.1 1x1卷积</h3><blockquote><p>$通过1 \times 1$卷积操作来压缩或者增加输入层的信道数目，从而改变(减少)计算量。<br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560128241604.png" alt="Alt text"></p></blockquote><h3 id="1-2-Inception-Module"><a href="#1-2-Inception-Module" class="headerlink" title="1.2 Inception Module"></a>1.2 Inception Module</h3><blockquote><p>在构建卷积层的时候，经常会需要决定过滤器的大小究竟是$1 \times 3$、$3 \times 3$还是$5 \times 5$，或者是否需要添加池化层，而<strong>Inception</strong>网络则帮助你自动的决定如何做出选择。虽然网络架构变得很复杂，但是网络表现却非常的好。<br>以下图为例：<br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560128537535.png" alt="Alt text"><br><strong>Inception</strong>模块用来代替人工去确定卷积层中的过滤类型或者是否需要创建卷积层或池化层，上图中输入层的维度为$28 \times 28 \times 192$，假设最上面使用$1 \times 1 \times 192 \times 64$卷积，那么输出为$1 \times 1 \times 64$；如果使用使用$3 \times 3 \times 192 \times 128$，那么输出为$28 \times 28 \times 128$(使用了<strong>SAME</strong>卷积)，然后我们把第二个计算出来的值堆叠到第一个值上面去；接着使用$5 \times 5$以及$MAX-POOLING$层等，以此将结果堆叠在一起。<br>依照上图可以得到：<strong>Inception</strong>模块输入为$28 \times 28 \times 192$，输出为$28 \times 28 \times 256$。<br><strong>Inception网络的基本思想是不需要人为的决定使用哪种过滤器或者是否使用池化，而是由网络自行确定这些参数，你可以为网络添加所有可能的尺寸的过滤器或者池化层，然后把这些输出连接起来，让网络自己学习它需要的参数、采用哪种过滤器组合。</strong><br>但是这里就有一个比较重要的问题了，那就是<strong>计算成本</strong>。<br>我们以上图中$5 \times 5$过滤器为例，计算一下它的计算成本是多少：<br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560129417723.png" alt="Alt text"><br>计算成本为：输出的大小代表要计算的数字个数，则这里要计算$28 \times 28 \times 32$个数字，对其中每个数字都需要执行$5 \times 5 \times 192$次乘法运算。所以乘法运算的总的次数为<strong>输出值个数 x 每个输出值需要计算的乘法运算次数 = </strong>$28 \times 28 \times 32 \times 5 \times 5 \times 192 = 1.2 亿$。<br>这是非常高的计算量了，而如果加入$1 \times 1$卷积，则可以将这个计算量缩减到原来的十分之一：<br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560130369650.png" alt="Alt text"><br>上图中使用$1 \times 1$卷积将输入压缩到$16$个信道，而中间这个被压缩的层有时候被称为<strong>bottleneck layer(瓶颈层)</strong>，第一层卷积的计算量为($1 \times 1$卷积)：$28 \times 28 \times 16 \times 1 \times 1 \times 192 \approx 240万$，第二层卷积的计算量为: $28 \times 28 \times 32 \times 5 \times 5 \times 16 \approx 1000万$，所以总的计算成本约为<strong>1240万</strong>，相当于上面<strong>1.2亿</strong>的十分之一。<br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560131172506.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560131415340.png" alt="Alt text"></p></blockquote><h3 id="1-3-Residual-Networks"><a href="#1-3-Residual-Networks" class="headerlink" title="1.3 Residual Networks"></a>1.3 Residual Networks</h3><blockquote><p><strong>Residual block(残差块)</strong>：<br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560132641217.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560132733434.png" alt="Alt text"><br>也就是说上面在深层的网络中加上的这个$a^{[l]}$，产生了一个<strong>残差块</strong>。<br>使用残差块可以训练非常深的神经网络，而<strong>ResNet</strong>就是很多的残差块堆叠在一起组成的一个深度神经网络。<br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560133115635.png" alt="Alt text"><br>上图中对于普通的网络来说(作图，没有残差块的网络)，凭着经验会发现随着网络层数的加深，训练错误会先减少，然后增多，但是理论上应该是随着网络层数的加深，应该训练的越来越好才对；但是对于<strong>ResNet</strong>则不同，即便网络再深(即使训练深度达到100层的网络也不例外)，训练的表现却都很不错，<strong>这种方式能够将中间的激活传递到更深的网络中去，有助于解决梯度消失和梯度爆炸问题。</strong><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560133853526.png" alt="Alt text"><br>在上图中，假设对于一个很深的网络后面再添加两层神经网络，并使用残差块结构（这里使用的激活函数为<strong>Relu</strong>），则：</p><script type="math/tex; mode=display">a^{[l+2]} = g(z^{[l+2]} + a^{[l]})</script><script type="math/tex; mode=display">= g(w^{[l+2]}·a^{[l+1]} + b^{[l+2]} + a^{[l]})</script><script type="math/tex; mode=display">如果此时w^{[l+2]}和b^{[l+2]}都为0</script><script type="math/tex; mode=display">= g(a^{[l]})</script><script type="math/tex; mode=display">= a^{[l]} = a^{[l+2]}</script><p><strong>结果表明，残差块学习这个恒等函数并不难，这就意味着即使给神经网络增加两层，它的效率也并不逊色与更简单的神经网络。想象一下，如果添加的这两层网络还学到了一些有用信息的话，那么它比学习恒等函数的表现将更好，那么这样的网络不仅仅保持了网络的效率，而且还提升了网络的效率。</strong><br><strong>另一个需要注意的点是</strong>，假设$z^{[l+2]}$和$a^{[l]}$是具有相同的维度的，所以在<strong>ResNet</strong>中使用了很多的<strong>SAME</strong>卷积，<br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560134986732.png" alt="Alt text"></p></blockquote><h2 id="2-Inception-v3-Network"><a href="#2-Inception-v3-Network" class="headerlink" title="2. Inception-v3 Network"></a>2. Inception-v3 Network</h2><p><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560147519168.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560148453948.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560148694586.png" alt="Alt text"></p><hr><p><strong>网络结构图中第一次出现的三个模块组：</strong><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560149370767.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560149488062.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560149503984.png" alt="Alt text"></p><hr><p><strong>网络结构图中第二次出现的五个模块组：</strong><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560149729631.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560150090714.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560150129838.png" alt="Alt text"><br><strong>这种既不改变空间分辨率，又不改变特征通道数的做法是为了把不同通道的特征给融合起来。</strong><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560150349813.png" alt="Alt text"></p><hr><p><strong>网络结构图中第三次出现的三个模块组：</strong><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560150514126.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560150688225.png" alt="Alt text"></p><h2 id="3-Inception-v4-Network"><a href="#3-Inception-v4-Network" class="headerlink" title="3. Inception-v4 Network"></a>3. Inception-v4 Network</h2><p><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560151352648.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560151643979.png" alt="Alt text"><br><strong>所谓特征融合其实就是将多个特征通道的值融合成一个数；而特征通道压缩指的是输出的特征通道的数目小于输入的特征通道的数目。</strong><br><strong>Branch1中的平均池化是对特征图做了一个空间模糊，而空间模糊则相当于对原来的特征图可能存在的一些噪音给去掉，而Branch2不使用对特征图进行空间模糊的平均池化是因为，空间模糊还有可能把真正有用的边缘信息或者物体的边缘轮廓也给去掉，因此下面采用折中的方式将两种方式都采用。</strong><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560153363346.png" alt="Alt text"></p><hr><p><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560153739082.png" alt="Alt text"><br><strong>需要注意的是将一个</strong>$n \times n$<strong>的卷积分解成</strong>$1 \times n$<strong>和</strong>$n \times 1$<strong>的卷积</strong> <strong>相当于增加了非线性映射的深度。</strong><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560154116572.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560154845267.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560155421987.png" alt="Alt text"></p><hr><p><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560155829143.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560156112315.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560156848895.png" alt="Alt text"></p><h2 id="4-Residual-Networks"><a href="#4-Residual-Networks" class="headerlink" title="4. Residual Networks"></a>4. Residual Networks</h2><p><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560156959897.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560157028430.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560157150706.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560157174268.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560157276393.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560157408304.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560157588198.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560157721323.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560157892573.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560158197277.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560158240945.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560158492223.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560158554251.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560158694678.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560158779559.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560158839431.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560159089731.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560159180492.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560159271653.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560159333154.png" alt="Alt text"></p><h2 id="5-Inception-ResNet-v1-v2"><a href="#5-Inception-ResNet-v1-v2" class="headerlink" title="5. Inception-ResNet-v1,v2"></a>5. Inception-ResNet-v1,v2</h2><p><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560159430770.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560159672226.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560159757091.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560159832467.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560159973808.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560160026383.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560160130969.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560160183813.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560160235461.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560160525435.png" alt="Alt text"></p><h2 id="6-SqueezeNet"><a href="#6-SqueezeNet" class="headerlink" title="6. SqueezeNet"></a>6. SqueezeNet</h2><p><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560160669640.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560160711543.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560160738129.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560160762977.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560160802319.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560160934523.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560161024034.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560161120186.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560161183724.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560161195229.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/Import-CNN-Framework/1560161258736.png" alt="Alt text"></p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 卷积网络框架 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习理论</title>
      <link href="/2019/06/10/DeepLearningTheory/"/>
      <url>/2019/06/10/DeepLearningTheory/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>记录深度学习理论课程相关内容.</strong><br><a id="more"></a></p></blockquote><h2 id="1-1-Can-shallow-network-fit-any-function"><a href="#1-1-Can-shallow-network-fit-any-function" class="headerlink" title="1.1 Can shallow network fit any function"></a>1.1 Can shallow network fit any function</h2><blockquote><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558080065257.png" alt="Alt text"></p><p>上图是说：给定一个<strong>network</strong>，以及相应的<strong>parameter(weights and biases)</strong>，那么这个<strong>network</strong>代表了一个<strong>function</strong>，而同样<strong>structure</strong>的<strong>network</strong>，在填入不同的<strong>parameter(weights and biases)</strong>的时候就对应不同的<strong>function</strong>。对于一个给定了的<strong>network</strong>的架构(<strong>structure</strong>)的时候，在给定各式各样的<strong>parameter</strong>的情况之下，其实就是在所有可能的<strong>function</strong>里面划定一个范围(<strong>network space</strong>)。</p><hr><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558080739654.png" alt="Alt text"></p><p>上图是说需要一个<strong>network</strong>去拟合图上的函数，在某一要求下，比方说要求<strong>network</strong>拟合函数达到某个精度的要求下，<strong>deep</strong>的<strong>network</strong>要比<strong>shallow</strong>的<strong>network</strong>的参数量少。</p><hr><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558080994943.png" alt="Alt text"></p><hr><p> <img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558081221451.png" alt="Alt text"></p><p> 上图是说如果一开始一个很<strong>shallow(small)</strong>的<strong>network</strong>不能覆盖到<strong>target function</strong>所在的<strong>function space</strong>，那么随着它的<strong>units</strong>的数目增长的越来越多，最终肯定是能<strong>fit</strong>到我们给定的<strong>target function</strong>的(后面讲到).</p><p> <img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558081479151.png" alt="Alt text"></p><hr><p> <img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558081540719.png" alt="Alt text"></p><p> <img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558082005754.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558082208813.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558082496627.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558082840572.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558083173657.png" alt="Alt text"><br>上图中<strong>l</strong>的两个绿色点直接连线的距离，而<strong>L</strong>是<strong>L-Lipschitz</strong>中的那个<strong>L</strong>。<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558084419662.png" alt="Alt text"></p><p>$error &lt; \Vert{f(x_1) - f(x_2)}\Vert \leq L\Vert{x_1 - x_2}\Vert &lt;l \times L \leq \xi    \Longrightarrow  l \leq \frac{\xi}{L}$<br>其中$ \Vert{f(x_1) - f(x_2)}\Vert \leq L\Vert{x_1 - x_2}\Vert$，且$\max_{0 \leq x \leq 1} \vert{f(x) - f^*(x)}\vert  \leq \xi$</p><p>因此，给定一个<strong>L-Lipschitz Function</strong>$f^<em>(x)$，需要找到一个<strong>piece-wise linear Function</strong>，让两者之间的<strong>error</strong>小于等于$\xi$，只需要做到在取线段的时候，相互之间的距离都取$\frac{\xi}{L}$就可以了，这样<strong>error</strong>就是小于等于$\xi$<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558086718838.png" alt="Alt text"><br>由此还可以得出，假设区间范围是$[0, 1]$之间，每个<strong>segment</strong>都是$\frac{\xi}{L}$，则<strong>segment</strong>的个数为$\frac{L}{\xi}$，也就是有$\frac{L}{\xi}$个<strong>piece-wise linear Function</strong><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558087000210.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558087049947.png" alt="Alt text"><br>因此，按照证明，只要做出上面那个<strong>piece-wise linear function</strong>，我们就能<strong>fit</strong>我们的<strong>target function</strong>(<strong>L-Lipschitz function</strong>)，让它们的<strong>error</strong>小于等于$\xi$，那么有没有办法通过只有一个<strong>hidden layer</strong>，且<strong>activation function</strong>都是<strong>relu</strong>的<strong>network</strong>制造出上图中绿线那样的<em>*piece-wise linear function</em></em>呢？答案是可以的。方法之一：</p><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558087441622.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558087711894.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558087994599.png" alt="Alt text"><br>上面两张图就是在解释使用两个<strong>relu</strong>可以组合成<strong>1</strong>个<strong>segment</strong>，而$\frac{L}{\xi}$个<strong>segment</strong>(<strong>piece-wise linear Function</strong>)，需要$\frac{2L}{\xi}$个<strong>relu neurons</strong>，就可以近似一个<strong>L-Lipschitz function</strong>，但是需要声明的是这个只是说可以做到，并没有说是效率最高的做法。这里有一个比较俗语的解释是上面成立的一个原因是因为，<strong>L</strong>越大，代表<strong>function</strong>的变化越快，则是一个越复杂的函数，那越复杂的函数就需要越多的神经元；相应的，$\xi$越小，则说明要求的精准度越高，则$\xi$越小在需要的神经元个数就越多。</p></blockquote><h2 id="1-2-Potential-of-Deep"><a href="#1-2-Potential-of-Deep" class="headerlink" title="1.2 Potential of Deep"></a>1.2 Potential of Deep</h2><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558097021232.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558097421561.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558097519589.png" alt="Alt text"></p><blockquote><p>类似逻辑电路一样(类比)，层数更多的逻辑电路需要的<strong>gate</strong>更少，而层数更多的神经网络在拟合同一个函数的时候，需要的神经元更少<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558097545982.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558097751934.png" alt="Alt text"><br>上图所说的是：在参数量相同的情况下，<strong>deep network</strong>产生的线性分段要比<strong>shallow network</strong>更多。<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558098139481.png" alt="Alt text"><br>上图中，<strong>relu</strong>是分段的，一部分的输出是<strong>0</strong>，还有一部分的输出和输入相同，对于采用<strong>relu</strong>作为激活函数的<strong>network</strong>，输出为<strong>0</strong>的那些可以拿掉，当做不存在一样，剩下的部分就好像是一个<strong>linear function</strong>，不过需要注意的是不能因此说<strong>relu</strong>是<strong>linear function</strong>，它是<strong>piece-wise linear function</strong>，当输入值达到某个阈值的时候<strong>relu</strong>就会从一种<strong>linear</strong>的输出状态到达另一种<strong>linear</strong>的输出状态。由于每个神经元在<strong>relu</strong>的左右下都有<strong>两种</strong>激活模式<strong>（ activation pattern）</strong>，因此如果有<strong>N</strong>个神经元，则有$2^N$种<strong>activation pattern</strong>，每一个<strong>activation pattern</strong>都制造了一个<strong>linear piece</strong>，所以总的也就是有$2^N$个<strong>linear pieces</strong>，但是需要注意的是这个是一个<strong>upper bound(最佳上限)</strong>，而这个上限可能永远都没有办法实现，有些<strong>pattern</strong>可能是永远也不会出现的，比方说：<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558099092748.png" alt="Alt text"></p></blockquote><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558099266392.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558099615364.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558099694294.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558099865914.png" alt="Alt text"></p><blockquote><p>从上面的图可以看出，当我们用<strong>deep structure</strong>的时候，每多加一层，线段的数目都变成<strong>double</strong><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558100023891.png" alt="Alt text"><br>在上面的图中，每个<strong>abs activation function</strong>都是由两个<strong>relu activation function</strong>组成，有前面所讲的，每次两个神经元(<strong>每个神经元的激活都是relu</strong>)组成一个线段，那么对于一个<strong>shallow network</strong>，如果需要产生<strong>100</strong>个线性分段，则需要<strong>200</strong>个神经元；但是如果使用的是<strong>deep network</strong>，每层有两个神经元，每次多加一层，线段的数目就会增加两倍，所以对于同样的<strong>100</strong>个线性分段，则只需要<strong>7</strong>层就可以实现了。因此需要产生比较多的线性片段的时候，使用<strong>deep</strong>是比较有效率的。深层的网络把之前的<strong>pattern</strong>重复的组合起来，有规律的重复出来。<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558101610973.png" alt="Alt text"><br>由上面的宽度为<strong>2</strong>，深度为<strong>N</strong>可以得出有$2^N$个线性分段的推论可以得出：宽度为$K$，深度为$H$的网络可以得出$K^H$个线性分段，以上就是<strong>network</strong>架构可以产生的线性分段的<strong>lower bound</strong>。<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558102008385.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558102213746.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558102275286.png" alt="Alt text"><br>上面两图是验证<strong>network</strong>的<strong>low layer</strong>的参数是比较重要的：左边的是在<strong>CIFAR 10</strong>上面做的实验，其中往不同层的参数上加上噪音，如果噪音加在最后一层的话，对结果几乎没有什么影响，但是一样的噪声加在第一层，整个结果就坏掉了。右边的是在<strong>MNIST</strong>数据集上的，然后分别对第一层进行训练，其他都是<strong>random</strong>的，以及分别往后，一直到只对最后一层进行训练，其他都是<strong>random</strong>的，最上面的紫色就是只训练第一层的结果，也就是只训练第一层，别的不管的情况下，结果都是很不错的，然后，只训练最后一层，结果就会坏掉。</p><hr></blockquote><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558103014973.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558103428049.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558103746080.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558103919220.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558104057330.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558104144772.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558104349911.png" alt="Alt text"></p><h2 id="1-3-Is-Deep-better-than-Shallow"><a href="#1-3-Is-Deep-better-than-Shallow" class="headerlink" title="1.3 Is Deep better than Shallow"></a>1.3 Is Deep better than Shallow</h2><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558104397074.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558104528234.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558104600075.png" alt="Alt text"><br>需要注意的是，上图中右边是实际<strong>relu</strong>达不到的一种状态，因为是不连续的，只是这里为了后面的证明，假设在梦幻状态下可以达到。</p><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558142786551.png" alt="Alt text"><br>现在假设在横轴上取两点$x_0$和$x_0 + l$，两点之间的间隔为$l$，然后我们假设要取一条直线$ax + b$取拟合这条红色的线($y = x^2$)，这条直线不需要它的头和尾在<strong>target function</strong>上面，那么这条直线在给定间距$l$的情况下能够拟合的多好呢？那么实际的也就是求解 $error^2 = \int_{x_0}^{x_0+l} (x^2 - (ax + b))^2 \, {\rm d}x \Longleftrightarrow \sqrt{\int_0^1 \vert f(x) - f^*(x) \vert ^2 \, {\rm d}x} \leq \xi$，然后找出一个$a$和$b$使得$error$最小，其最小结果为：<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558143543203.png" alt="Alt text"><br>其中的数学推导提醒：<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558143795151.png" alt="Alt text"><br>那么上面是对于一条直线进行拟合的过程，那么如果现在在区间$[0, 1]$之间有$n$条线段($\sum_{i=1}^{n} l_i = 1$)进行拟合，那如何分配这$n$条线段使得$error$的值最小：<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558144193000.png" alt="Alt text"><br>由于对于一条线段的时候$e^2 = \frac{l^5}{180}$，那么对于多个分段的线段来说，每个的$(e_i)^2 = \frac{(l_i)^5}{180}$，因此总的$error^2$为：</p><script type="math/tex; mode=display">E^2 = \sum_{i=1}^{n} (e_i)^2 = \sum_{i=1}^{n} \frac{(l_i)^5}{180}</script><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558144599224.png" alt="Alt text"><br>所以现在需要考虑的是如何分配 $l_1$ 到 $l_n$ 使得 $E^2$ 最小呢？正确的答案是间隔$l_i$平均分配(感觉有点像是最大熵模型)：<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558144869756.png" alt="Alt text"><br>由于采用间隔平均分配，因此：</p><script type="math/tex; mode=display">l_i = \frac{1}{n}</script><script type="math/tex; mode=display">E^2 = \sum_{i=1}^{n} \frac{(1/n)^5}{180} = \frac{1}{180}·\frac{1}{n^4}</script><p>平均分配的原因：<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558145611525.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558145771413.png" alt="Alt text"><br>因此，当$n$取上面的值的时候(也就是有上面那么多的<strong>linear pieces</strong>)才能让$Error \leq \xi$，而我们知道，每一个<strong>piece</strong>在<strong>shallow</strong>的状况下都需要一个<strong>neuron</strong>来制造，因此在<strong>shallow</strong>状况下我们仍然需要$O(\frac{1}{\sqrt \xi})$个<strong>neurons</strong>才能够去拟合$y = x^2$<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558146848316.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558146860041.png" alt="Alt text"><br>因此在给了<strong>shallow</strong>梦幻状态的情况之下，结果<strong>shallow</strong>的最佳状态依旧是$O(\frac{1}{\sqrt \xi})$，因此可以得出<strong>deep</strong>是比<strong>shallow</strong>好的(虽然没有去证实$O(\log_2(\frac{1}{\sqrt \xi})))$是否是<strong>deep</strong>最好的状态).<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558147073605.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558147082431.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558147223285.png" alt="Alt text"><br><strong>需要注意的是，上面说的是存在某一个function(文章中的应该？)，而不是说所有的function都不行。</strong></p><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558147459349.png" alt="Alt text"><br>上面这张图就是给出再上面的两张图中的某一个函数，这里给出的是一个球状的函数，球外面全是<strong>0</strong>，球里面全是<strong>1</strong>，结果是不管浅层的网络的宽度如何增加，损失依旧没有办法降下来，但是深层的网络，宽度只在<strong>100</strong>的时候就能降下来了。</p><p>但是需要主要的是不是所有的<strong>function</strong>都是<strong>deep</strong>比<strong>shallow</strong>的好(比方说<strong>linear</strong>)，因此下面的文章给出结论：<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558147593069.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558147845171.png" alt="Alt text"><br>因此结论是：比$x^2$还简单的(比如$y = x$)是不符合<strong>deep</strong>比<strong>shallow</strong>更好的，但是比$x^2$复杂的就是深得比浅的好，所以深度学习是有用的。</p><h2 id="2-1-When-Gradient-is-Zero"><a href="#2-1-When-Gradient-is-Zero" class="headerlink" title="2.1 When Gradient is Zero"></a>2.1 When Gradient is Zero</h2><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558148468485.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558148984222.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558149644026.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558162352495.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558162375183.png" alt="Alt text"></p><h3 id="2-1-1-Hessian-Matrix-When-Gradient-is-Zero"><a href="#2-1-1-Hessian-Matrix-When-Gradient-is-Zero" class="headerlink" title="2.1.1 Hessian Matrix: When Gradient is Zero"></a>2.1.1 Hessian Matrix: When Gradient is Zero</h3><blockquote><p><strong>Critical Point: </strong>驻点；<strong>stuck: </strong>卡住，无法移动；<strong>curvature: </strong>曲率；<strong>invertible：</strong>可逆的；<br><strong>dominant：</strong>主导<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558162442951.png" alt="Alt text"></p><p>需要注意的是训练到一定程度的时候，出现损失基本不再下降，梯度趋近到<strong>0</strong>的时候，不要随随便便就说走到了<strong>local minima/global minima</strong>，因为还有可能是<strong>saddle point(鞍点: 并非极值，但是梯度依旧为0)</strong><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558162665301.png" alt="Alt text"><br>那么要区分是上面哪一种的时候，就需要使用<strong>Hessian Matrix: </strong><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558163693705.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558163703389.png" alt="Alt text"></p></blockquote><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558165032965.png" alt="Alt text"></p><blockquote><p>对于上图的解释是: 假设$f(x)$实际是图中蓝色的曲线，如果现在排除掉包含$H$的那一项，只考虑前面的两项，则实际得到的结果是只能得到绿色的虚线。因此蓝色实线和绿色虚线的差异就是在于<strong>H</strong>所在的那一项。</p></blockquote><p>因此有了<strong>Hessian Matrix</strong>之后就可以定义新的<strong>Optimize</strong>的方法(也就是<strong>Newton’s method</strong>)。<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558166465037.png" alt="Alt text"><br>上图中，黑色是$f(x)$，前两项是绿色的实现，梯度无变化；而三项都考虑则变成红色的曲线，梯度则有了变化，我们期望通过某种方法找到红色曲线的最小值(梯度为<strong>0</strong>)的地方，方法就是对整个式子求一下导数为<strong>0</strong>的地方。</p><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558167309487.png" alt="Alt text"><br>上图中，相较于梯度下降仅能靠梯度指引方向的方式，牛顿法能够通过$H^{-1}$($H^{-1}$自动决定了<strong>learning_rate</strong>要有多大)一步直达最低点。</p><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558168321883.png" alt="Alt text"><br>上图中$f(\theta)$为黑色的曲线，而后面三项的组合为红色的曲线，以某个点$x_0$为初始点，当$\theta$和$\theta_0$非常接近的时候，红色的线才和黑色的线很贴近，那从初始点，初始的红线开始，牛顿法会一步走到初始红线的最低点，得到$x_1$，然后在$x_1$这个地方会重新计算$g$和$H$，然后得到新的第二条红线，然后牛顿法又是一步到第二条红色的二次曲线最低点，得到$x_2$，然后继续。。。所以相较于<strong>Gradient descent</strong>，牛顿法每次可以走一大步。当$f(x)$是二次函数的时候(<strong>quadratic function</strong>)，牛顿法直接一步到位。</p><p>但是为何有这么强方法，却不使用呢？因为牛顿法在深度学习中不好用，如下：</p><blockquote><ol><li>需要计算$H^{-1}$，因为在深度学习中参数的量动则就是几千万甚至上亿，由于<strong>H</strong>是$n \times n$的，所以要算它的$H^{-1}$基本是不可能的。</li><li>牛顿法是寻找梯度为<strong>0</strong>的点，但是梯度为<strong>0</strong>的点不一定是最值点，有可能是鞍点，因为在深度学习所定义出来的<strong>Loss function</strong>里，有很多<strong>gradient</strong>为<strong>0</strong>的点，不是<strong>local minima</strong>，而是<strong>saddle point</strong>.</li><li><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558168505545.png" alt="Alt text"></li></ol></blockquote><p>那么上面讲解<strong>Hessian Matrix</strong>的意义何在呢？<br>假设在用梯度下降的时候<strong>updata</strong>参数的时候，到了某一步，梯度很小的时候，这个时候$f(\theta)$的特性就会变成由<strong>Hessian</strong>主导，通过<strong>H</strong>告诉我们<strong>critical point</strong>到底属于那种情况.<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558168940567.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558169051514.png" alt="Alt text"></p><blockquote><p><strong>positive/negative definite: </strong>正定/负定<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558169310295.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558170532234.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558170569338.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558171129367.png" alt="Alt text"><br>上图是说，我们从$\theta_0$这个地方移动一个$H$的特征向量$v$，我们会增加特征值大小的值(假设特征值为正的时候).<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558171518613.png" alt="Alt text"><br>上图是说，使用<strong>Hessian</strong>的特征值和特征向量分析<strong>critical point</strong>的时候：<br>① 当$u$是$H$的特征向量的线性组合(这个随意的方向$u$一定是$H$的特征向量的线性组合，对称矩阵的性质)，且所有的特征值都是正的，那么往$u$的方向走过去的时候，$f(\theta)$会增加对应特征值大小的值，则现在的状态是对于<strong>local minima</strong>;<br>② 当$u$是$H$的特征向量的线性组合，且所有的特征值都是负的，那么往$u$的方向走过去的时候，$f(\theta)$会减小对应特征值大小的值，则现在的状态是对于<strong>local maxima</strong>;<br>③ 当$u$是$H$的特征向量的线性组合，且所有的特征值有正有负，那么往某些方向的时候，$f(\theta)$会增加，相反，$f(\theta)$会减少，则现在的状态是对于<strong>saddle point</strong>;</p></blockquote><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558172883403.png" alt="Alt text"></p><blockquote><p>上面的例子中如何计算<strong>Hessian Matrix</strong>的种类：<br>假设特征向量如下：<script type="math/tex">v = \begin{bmatrix} a & b \\  \end{bmatrix}</script><br>因此：</p><script type="math/tex; mode=display">v^\mathrm T H v</script><script type="math/tex; mode=display">= \begin{bmatrix} a & b \\  \end{bmatrix} ^\mathrm T· \begin{bmatrix} 2 & 0 \\ 0 & 6 \\  \end{bmatrix} · \begin{bmatrix} a & b \\  \end{bmatrix}</script><script type="math/tex; mode=display">= \begin{bmatrix} 2a & 6b \\  \end{bmatrix}·\begin{bmatrix} a  \\ b \\  \end{bmatrix}</script><script type="math/tex; mode=display">= 2a^2 + 6b^2 > 0</script><script type="math/tex; mode=display">\because (a,b \neq 0)</script><script type="math/tex; mode=display">\therefore H \implies Positive-definite</script><script type="math/tex; mode=display">\implies local-minima</script></blockquote><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558172939358.png" alt="Alt text"></p><hr><blockquote><p><strong>Degenerate: </strong>衰退，退化<br>退化矩阵(奇异矩阵)：奇异阵是行列式为0的方阵，是特征值（奇异值）含有0的方阵。<br><strong>Degenarate Hessian has at least one zero eigen value代表的意思是往相应的那个方向的特征向量走，不增也不减.</strong><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558183857197.png" alt="Alt text"><br>④因此当我们发现$H$有$zero vecror$的时候，我们没有办法判断在$zero eigen value$的方向是增加还是减少。当$Hessian$那项为<strong>0</strong>的时候，其他被抹去的项就起作用了。所以到$H$有特征值为<strong>0</strong>的时候，这个时候用<strong>Hessian</strong>判断是<strong>local minima、local maxima、saddle point</strong>就不适用了(无法判断了，都有可能，这个时候其中用去决定是哪一种的就是被抹去的更高次的项了)。<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558184814846.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558184921722.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558185042995.png" alt="Alt text"></p></blockquote><hr><blockquote><p>当你在训练的时候，<strong>loss</strong>不再下降了，上面的那些讨论都是假设是出于<strong>critical point(gradient为0的情况)</strong>，然后基于<strong>Hessian</strong>来讨论是出于<strong>local minima/local maxima/saddle point</strong>哪种；但是实际上还有可能<strong>training</strong>停下来了，并不代表你一定走到了<strong>critical point(gradient为0的情况)</strong>，因为这个时候你的<strong>gradient</strong>还有可能不为<strong>0</strong>。<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558185156166.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558185608066.png" alt="Alt text"><br>上面也是这样的情况，并非到了<strong>critical point</strong>的地方，分析可能是更加复杂的地方，<strong>gradient</strong>变小的区域里，可能逐渐靠近一个<strong>saddle point</strong>，增大则可能是逃出了这个<strong>saddle point</strong>，在变小则可能是靠近了另一个<strong>saddle point</strong>… …</p></blockquote><h2 id="2-2-Deep-Linear-Network"><a href="#2-2-Deep-Linear-Network" class="headerlink" title="2.2 Deep Linear Network"></a>2.2 Deep Linear Network</h2><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558185790834.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558186237347.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558186630036.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558187390194.png" alt="Alt text"></p><blockquote><p>上面计算出来在$w_1、w_2 = 0$的原点处是一个<strong>saddle point</strong>.而在$w_1·w_2 = 1$处则是<strong>critical point</strong>(在上面的热力图中可以看出，而且是<strong>global minima</strong>)。<br><strong>利用Hessian 计算critical point的性质.</strong><br><strong>hessian 有0的特征值的时候是，那个方向是分析是哪种情况是不好分析的，除非以某些具体数据去算算看。</strong><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558188314135.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558188466702.png" alt="Alt text"></p></blockquote><hr><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558189160490.png" alt="Alt text"></p><blockquote><p>对于上面的深度线性网络，可以证明，只要满足一些非常宽松的条件，这个线性网络不管叠加多少层，它的所有局部极小值都是全局最小值。比方说一些文章给出的宽松条件是<strong>Hidden layer size &gt;= input dim, output dim</strong>, 比如输入和输出的维度是5维，那么中间每一个隐层的输出维度都要大于或者等于5维即可。<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558189596902.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558189619568.png" alt="Alt text"></p></blockquote><h2 id="2-3-Does-Deep-Network-have-Local-Minima"><a href="#2-3-Does-Deep-Network-have-Local-Minima" class="headerlink" title="2.3 Does Deep Network have Local Minima"></a>2.3 Does Deep Network have Local Minima</h2><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558189862012.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558190399092.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558190572757.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558190855626.png" alt="Alt text"><br><strong>上图说明初始化很重要，否则容易陷入盲点，造成训练落入local_minima,最后崩坏。</strong></p><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558191303644.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558191457103.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558191502066.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558191556193.png" alt="Alt text"><br><strong>这一节就是说Deep Non-linear Network</strong>是存在<strong>local minima</strong>的，上面那些文献就是在设计各种实验去找出什么情况下容易遇到<strong>local minima</strong>，可能以后会有新的理论告诉我们应该如何设计网络(如何初始化，什么样的结构，什么样的数据…)，使用什么样的条件，就能有效的避开<strong>local minial</strong>，从而找到<strong>global minima</strong></p><h2 id="2-4-Geometry-of-Loss-Surface-Conjecture"><a href="#2-4-Geometry-of-Loss-Surface-Conjecture" class="headerlink" title="2.4 Geometry of Loss Surface(Conjecture)"></a>2.4 Geometry of Loss Surface(Conjecture)</h2><blockquote><ol><li><strong>Geometry: </strong>n.    几何(学); 几何形状; 几何图形; 几何结构;</li><li><strong>Conjecture: </strong>n.    猜测; 推测; 揣测; 臆测; v.    猜测; 推测;</li><li><strong>Empirical: </strong>adj.    以实验(或经验)为依据的; 经验主义的;</li></ol></blockquote><p>现在在<strong>Deep Learning</strong>的领域有这么一个推论：几乎所有的<strong>local minimum</strong>它的<strong>loss</strong>，跟<strong>global optinum</strong>都是差不多的，因此如果卡在了<strong>local minimum</strong>也不要惊慌，因它跟<strong>global minimum</strong>的<strong>loss</strong>是差不多的。<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558230298561.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558230627503.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558230781646.png" alt="Alt text"></p><blockquote><p>上图是基于再上面一张图的假设(假设特征值一半为正，一半为负，至于为什么？不管，文章这么假设的)说明我们的网络越大，遇见<strong>saddle point</strong>的可能性越大。</p></blockquote><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558230976183.png" alt="Alt text"></p><blockquote><p>现在假设几率不再是$\frac{1}{2}$, 而是跟现在的<strong>loss</strong>有关了，现在假设几率为$p$(上图中的<strong>error</strong>指的就是<strong>loss</strong>).<br>需要注意的是：<strong>Larger error，larger p</strong>是一个假设($p$是负的<strong>eigenvalue</strong>出现的几率，而<strong>负的eigenvalue</strong>代表<strong>loss</strong>有一条路往下降)。其实这个假设也是蛮合理的，想想看，刚开始的时候，在<strong>loss</strong>还比较高的地方，应该会有很多条路让你往<strong>loss</strong>更低的地方走，当<strong>loss</strong>很大的时候是比较有可能出现<strong>negative eigenvalue</strong>，后面训练到后来，<strong>loss</strong>很低时候，出现<strong>negative eigenvalue</strong>的几率$p$就变得很小了。因此上图的图中<strong>loss</strong>随着大小的不同，走到<strong>critical point</strong>，对应的<strong>eigenvalue</strong>的<strong>分布</strong>的变化。<br>从上图还能看出：在<strong>loss</strong>比较大的时候，<strong>eigenvalue</strong>为正的概率和为负的概率基本一半；<strong>loss</strong>比较小的时候，<strong>eigenvalue</strong>基本为正；因此<strong>saddle point</strong>比较容易出现在<strong>loss</strong>比较大的时候，而<strong>local minimum</strong>比较容易出现在<strong>loss</strong>比较低的地方(因为此时<strong>eigenvalue</strong>基本都是为正的)。<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558232413671.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558232523313.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558232630425.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558232645925.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558232744765.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558232952444.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558232970689.png" alt="Alt text"></p></blockquote><h2 id="2-5-Geometry-of-Loss-Surface-Empirical"><a href="#2-5-Geometry-of-Loss-Surface-Empirical" class="headerlink" title="2.5 Geometry of Loss Surface(Empirical)"></a>2.5 Geometry of Loss Surface(Empirical)</h2><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558233086374.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558233094775.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558233469124.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558233650824.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558233775339.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558234122697.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558234269079.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558234347827.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558234639087.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558234762963.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558234803475.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558234907367.png" alt="Alt text"><br><strong>不同初始化，造就的模型不同。</strong><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558235070770.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558235215231.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558235350683.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558235486657.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558235587901.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558235644335.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558235807379.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558235877541.png" alt="Alt text"></p><h2 id="3-1-Generalization-Capability-of-Deep-Learning"><a href="#3-1-Generalization-Capability-of-Deep-Learning" class="headerlink" title="3.1 Generalization Capability of Deep Learning"></a>3.1 Generalization Capability of Deep Learning</h2><blockquote><p>需要注意的是，不管你的数据的分布是什么样子的，都会有$1-\delta$概率($\delta$是你自己定的一个值)出现下面的式子：</p><script type="math/tex; mode=display">E_{test} \leq E_{train} + \Omega(R, M, \delta)</script><p>因此有：</p><script type="math/tex; mode=display">E_{train} \leq E_{test} \leq E_{train} + \Omega(R, M, \delta)</script><p>其中$\Omega(R, M, \delta)$与$\delta$有关，至于这一项是什么后面再说。<br>因此$\delta$越小，上面式子发生的概率越大，则中间的$E_{test}$所在的区间就得越大(这样才有很大概率出现在这个区间之内)，因此相应的$\Omega(R, M, \delta)$也就越大。<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558270653247.png" alt="Alt text"></p><hr><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558270867907.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558270971276.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558271086884.png" alt="Alt text"><br><strong>capacity of model</strong>的含义是对于错误标注的数据进行拟合，达到百分百正确时使用的数据的量就是模型的$VC dimension$。<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558271290720.png" alt="Alt text"></p><hr><p><strong>Overparameterized: </strong>过参数化，参数过多；<br>一个比较反直觉的结论：在深度学习中，如果训练集的错误率很小了，而测试集的错误率比较高的情况下，如果这个时候再增加模型中的参数量，测试集的结果反而会变好。<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558271774929.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558272967476.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558273007272.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558273269484.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558273613610.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558273738169.png" alt="Alt text"><br>上面的都是在验证模型大的情况下，泛化反而会相比较之前的较差结果要好一些。至于原因暂时还没有定论结果。</p><hr><p>下面这个实验是说：神经网络是自带正则化的。<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558273984950.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558274308341.png" alt="Alt text"></p></blockquote><h2 id="3-2-Indicator-of-Generalization"><a href="#3-2-Indicator-of-Generalization" class="headerlink" title="3.2 Indicator of Generalization"></a>3.2 Indicator of Generalization</h2><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558274443913.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558274626635.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558274741946.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558275064641.png" alt="Alt text"></p><blockquote><p>上图中左图最下面的虚线正确率先增加后减少，说明模型在初期是先从$20 %$的真实标注数据中学习到了有用的东西的，而后遇到<strong>80 %</strong>错误标注的时候的正确率开始下降。<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558275402082.png" alt="Alt text"></p><hr><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558275431578.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558275669761.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558275998776.png" alt="Alt text"><br>其实$x$的<strong>sensitivity</strong>还是很直觉的，也就是说现在输入的数据如果有一个小量的变化的话，那对我的输出到底是有多大的变化。<strong>sensitivity</strong>和泛化之间的关系就是如果某个网络对某一份数据非常的<strong>sensitive</strong>，那么意味着这个<strong>Network</strong>不够<strong>roboost</strong>。<br>而<strong>Regularization</strong>也可以看做是<strong>minimize sensitivity</strong>，因此正则化的时候<strong>weight</strong>越接近0越好，其实就是让<strong>output</strong>越平滑，<strong>output</strong>越平滑其实就是<strong>sensitivity</strong>越小，因为<strong>input</strong>有变化的时候，<strong>output</strong>变化是比较小的。<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558276492716.png" alt="Alt text"><br>那么对于一个没有标签的测试集，就可以通过计算<strong>sensitivity</strong>的值去判断<strong>test</strong>的表现结果如何。<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558276779000.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558276927319.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558277096050.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558277114755.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558277165544.png" alt="Alt text"></p></blockquote><hr><p>下面是说不同锋利程度的<strong>local minimum</strong>与泛化程度的关系(的一种可能猜想)：<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558277403045.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558277607275.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558277786862.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558277908659.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558278039524.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558278075345.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558278095267.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558356388010.png" alt="Alt text"></p><h2 id="4-1-1-Batch-Normalization"><a href="#4-1-1-Batch-Normalization" class="headerlink" title="4.1.1  Batch_Normalization"></a>4.1.1  Batch_Normalization</h2><p><strong>Batch_Norm:</strong></p><script type="math/tex; mode=display">\mu = \frac{1}{m} \sum_{i} z^{(i)}</script><script type="math/tex; mode=display">{\sigma}^2 = \frac{1}{m} (z^{(i)} - \mu)^2</script><script type="math/tex; mode=display">z_{norm}^{(i)} = \frac{z^{(i)} - \mu}{\sqrt{\sigma^2 + \epsilon}}</script><script type="math/tex; mode=display">\tilde{z}^{(i)} = \gamma·z_{norm}^{(i)} + \beta</script><p>其中 $\epsilon$ 是为了保证数值稳定. $\gamma$ 和 $\beta$ 是可以跟随<strong>backpropagation</strong>进行学习更新的参数，类似神经网络的中的权重$\omega$, 更新公式如下：</p><script type="math/tex; mode=display">\omega^{[l]} := {\omega}^{[l]} - \alpha·d{\omega}^{[l]}</script><script type="math/tex; mode=display">\gamma^{[l]} := {\gamma}^{[l]} - \alpha·d{\gamma}^{[l]}</script><script type="math/tex; mode=display">\beta^{[l]} := {\beta}^{[l]} - \alpha·d{\beta}^{[l]}</script><p>其中$\gamma$以及$\beta$也是可以再反向传播的时候进行<strong>training</strong>的参数，需要注意的是：当 $\gamma = \sqrt{\sigma^2 + \epsilon}$ 以及 $\beta = \mu$ 的时候，相当于是恢复到了<strong>batch_norm</strong>之前的状态.</p><blockquote><hr><p><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558356602000.png" alt="Alt text"><br><strong>Feature Scaling:</strong><br>下面这个图中，假设$x_1$是$1,2,…$，$x_2$是$100,200,….$，假设$x_1,x_2$是一样重要的<strong>feature</strong>，对结果的影响力是一样的，这意味着$w_1$的<strong>scale</strong>会比较大，然后把$w_1,w_2$与$loss$的关系拿出来作图，就会发现在$w_1$这个方向的变化的斜率是比较小的，相应的<strong>gradient</strong>是比较小的。<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558357052634.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558358133270.png" alt="Alt text"><br>对于深度学习，在<strong>training</strong>的过程中每一层的参数都是不断的变化，则每一层的<strong>output</strong>都会在变化，相应的每一层的<strong>mean</strong>和<strong>variance</strong>也就在不断的变化。<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558358847474.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558358946692.png" alt="Alt text"><br><strong>Batch_Norm中的Batch不能太小了，不然算均值和方差会不准。</strong><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558359272868.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558359358028.png" alt="Alt text"><br>需要注意的是<strong>Batch_Norm</strong>在做<strong>backpropogation</strong>的时候是需要通过$\mu, \sigma$的，不能把它们两个当成是常量给排除掉，因为往上返回的时候$\mu, \sigma$是会改动的，所以不能当成常量。<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558359744159.png" alt="Alt text"><br>$\gamma$和$\beta$不同于$\mu$和$\sigma$的，他俩是独立于数据的，他俩是<strong>network</strong>自己的学习得到的。<br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558360603736.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558360856175.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/10/DeepLearningTheory/1558360899077.png" alt="Alt text"></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 理论推导 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>迁移学习中预训练模型的保存文件</title>
      <link href="/2019/06/06/model-pd/"/>
      <url>/2019/06/06/model-pd/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>分析不同的预训练模型的保存文件的特性.</strong><br><a id="more"></a></p></blockquote><h2 id="1-pb文件"><a href="#1-pb文件" class="headerlink" title="1. pb文件"></a>1. pb文件</h2><blockquote><p>在使用<strong>迁移学习</strong>代码的时候发现，对于存在着不同的模型保存文件，例如： <strong>.npy文件、.npz文件、.mat文件、.ckpt文件以及.pb文件</strong>。其中我在使用<strong>VGG16</strong>的是使用的模型保存文件是<strong>.npy文件</strong>，在使用<strong>Inception-v3</strong>的时候使用的是<strong>.pb文件</strong>。</p><p>对于<strong>.npy文件、.npz文件、.mat文件</strong>而言，这些文件仅仅保存着网络的权重，因此要想使用就得在自己模型的代码中重建网络，根据网络结构一步步搭建，将相应的权重赋予其中的$w、b$，然后再需要修改的层那里对新的变量进行初始化。需要明确的是：<strong>tf.Optimizer</strong>只优化<strong>tf.GraphKeys.TRAINABLE_VARIABLES</strong>中的变量，也就是说在进行<strong>Backpropagation</strong>参数更新的，只会回传梯度到<strong>Variable</strong>(变量)上去，常量是被固定住了，不会被更新的，因此在迁移学习中对于很多预训练了的框架，想要在迁移的时候对部分参数进行固定以避免训练的话，可以通过使用<strong>tf.constant</strong>或者<strong>python</strong>变量的形式来规避常量被训练。</p><p>除了以上的几个模型保存格式之外，通常我们使用<strong>TensorFlow</strong>时保存模型都使用 <strong>ckpt</strong> 格式的模型文件(<code>tf.train.Saver()</code>)，但是这种方式有几个缺点：</p><blockquote><ol><li>首先这种模型文件是依赖 <strong>TensorFlow</strong> 的，只能在其框架下使用；</li><li>其次，在恢复模型之前还需要再定义一遍网络结构，然后才能把变量的值恢复到网络中。</li></ol></blockquote><p>也就是说：通过<strong>tf.saver</strong>保存形成的<strong>ckpt</strong>文件其变量数据和图是分开的。我们知道<strong>TensorFlow</strong>是先画图，然后通过<strong>placeholde</strong>往图里面喂数据。这种解耦形式存在的方法对以后的迁移学习以及对程序进行微小的改动提供了极大的便利性。但是对于一些模型来说，如果训练好了之后不会再发生改变的话，那么<strong>ckpt</strong>的方式就没有必要了。一方面，<strong>ckpt</strong>文件储存的数据都是变量，既然我们不再改动，就应当让其变成常量，直接<strong>“烧”</strong>到图里面(也就是是将模型参数固化到图文件中)。另一方面，谷歌推荐的保存模型的方式是保存模型为<strong>pb</strong>文件，<strong>它具有语言独立性，可独立运行，封闭的序列化格式，任何语言都可以解析它，它允许其他语言和深度学习框架读取、继续训练和迁移 TensorFlow 的模型</strong>。它的主要使用场景是<strong>实现创建模型与使用模型的解耦， 使得前向推导 inference的代码统一</strong>。另外的好处是保存为<strong>pb</strong>文件时候，模型的变量都会变成固定的，导致模型的大小会大大减小，适合在手机端运行。对于线上的模型，我们一般是通过<strong>C++</strong>或者<strong>C</strong>语言编写的程序进行调用。所以一般模型最终形式都是应该写成<strong>pb</strong>文件的形式。</p></blockquote><h2 id="2-相关网页链接"><a href="#2-相关网页链接" class="headerlink" title="2. 相关网页链接"></a>2. 相关网页链接</h2><blockquote><ol><li><a href="https://blog.csdn.net/wc781708249/article/details/78043099?locationNum=10&amp;fps=1" target="_blank" rel="noopener">Tensorflow-pb保存与导入</a></li><li><a href="https://blog.csdn.net/guvcolie/article/details/77478973" target="_blank" rel="noopener">将tensorflow网络模型（图+权值）保存为.pb文件，并从.pb文件中还原网络模型</a></li><li><a href="https://zhuanlan.zhihu.com/p/31417693" target="_blank" rel="noopener">知乎——tensorflow保存和恢复模型的两种方法介绍</a></li><li><a href="https://cloud.tencent.com/developer/article/1357573" target="_blank" rel="noopener">Tensorflow MobileNet移植到Android</a></li><li><a href="https://juejin.im/entry/5be3b34c6fb9a049fc030303" target="_blank" rel="noopener">从Tensorflow模型文件中解析并显示网络结构图（pb模型篇）</a></li><li><a href="https://zhuanlan.zhihu.com/p/64099452" target="_blank" rel="noopener">知乎——[深度学习] TensorFlow中模型的freeze_graph</a></li><li><a href="https://blog.csdn.net/zyc121561/article/details/82222417" target="_blank" rel="noopener">基于Inception-v3的CNN迁移学习框架训练实例</a></li><li><a href="https://epleone.github.io/2018/03/19/tensorflow-guide/" target="_blank" rel="noopener">TensorFlow 学习心得</a></li><li><a href="https://blog.csdn.net/wc781708249/article/details/78043099?locationNum=10&amp;fps=1" target="_blank" rel="noopener">Tensorflow-pb保存与导入</a></li><li><a href="http://www.yanglajiao.com/article/qq_36356761/79505153" target="_blank" rel="noopener">TensorFlow 预训练模型导入</a></li></ol></blockquote>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 迁移学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>近期迁移学习相关网页</title>
      <link href="/2019/06/05/transfer-learning-Web-page/"/>
      <url>/2019/06/05/transfer-learning-Web-page/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>近期有关迁移学习的一些重要的网页.</strong><br><a id="more"></a></p><ol><li><a href="https://blog.csdn.net/qq_33431368/article/details/79344848" target="_blank" rel="noopener">【TensorFlow实战笔记】 迁移学习实战—卷积神经网络CNN-Inception-v3模型(非常重要)</a></li><li><a href="https://blog.csdn.net/White_Idiot/article/details/78816850" target="_blank" rel="noopener">【TensorFlow】迁移学习（使用Inception-v3）(非常重要)</a></li><li><a href="https://blog.csdn.net/gaoyueace/article/details/79724359" target="_blank" rel="noopener">使用TensorFlow-Slim实现Inception模块</a></li><li><a href="https://www.jianshu.com/p/54a96089fdac" target="_blank" rel="noopener">TensorFlow将checkpoint文件转成.pd文件</a></li><li><a href="https://blog.csdn.net/oYouHuo/article/details/81111833" target="_blank" rel="noopener">TensorFlow保存训练模型为pd文件并恢复(重要)</a></li><li><a href="https://blog.csdn.net/qq26983255/article/details/82846614" target="_blank" rel="noopener">TensorFlow：将ckpt文件固化成pb文件(非常重要)</a></li><li><a href="https://blog.csdn.net/guyuealian/article/details/82218092" target="_blank" rel="noopener">tensorflow实现将ckpt转pb文件(非常重要)</a></li><li><a href="https://blog.csdn.net/yjl9122/article/details/78341689" target="_blank" rel="noopener">tensorflow—使用freeze_graph.py将ckpt转为pb文件(重要)</a></li><li><a href="https://blog.csdn.net/mao_xiao_feng/article/details/73409975" target="_blank" rel="noopener">【Tensorflow】辅助工具篇——tensorflow slim(TF-Slim)介绍(重要)</a></li><li><a href="https://tensorlayercn.readthedocs.io/zh/latest/" target="_blank" rel="noopener">TensorLayer 中文文档</a></li><li><a href="https://www.cnblogs.com/zengfanlin/p/8970868.html" target="_blank" rel="noopener">用tensorlayer导入Slim模型迁移学习</a></li><li><a href="https://niuyuanyuanna.github.io/2018/12/06/tensorflow/4.1%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AF%86%E5%88%AB%E8%8A%B1/#inceptipn-v3%E6%A8%A1%E5%9E%8B" target="_blank" rel="noopener">Inception-V3迁移学习(重要)</a></li><li><a href="http://czx.im/2018/04/18/Tensorflow6/" target="_blank" rel="noopener">使用 Google Inception V3模型进行迁移学习之——牛津大学花朵分类(重要)</a></li><li><a href="https://blog.csdn.net/u013709270/article/details/78778538" target="_blank" rel="noopener">应用TF-Slim快速实现迁移学习</a></li><li><a href="https://blog.csdn.net/chaipp0607/article/details/74139895" target="_blank" rel="noopener">TensorFlow-Slim图像分类库(重要)</a></li><li><a href="https://blog.csdn.net/Mr_health/article/details/81285119" target="_blank" rel="noopener">tensorflow利用slim进行迁移学习(重要)</a></li><li><a href="https://blog.csdn.net/weixin_42001089/article/details/81055745" target="_blank" rel="noopener">tensorflow-Inception迁移学习(非常重要)</a></li><li><a href="https://blog.csdn.net/qq_38343111/article/details/82256878" target="_blank" rel="noopener">Tensorflow Inception-v3模型迁移学习(重要)</a></li><li><a href="https://www.cnblogs.com/hellcat/p/6909269.html" target="_blank" rel="noopener">『TensorFlow』迁移学习</a></li><li><a href="https://blog.csdn.net/u014061630/article/details/80557028" target="_blank" rel="noopener">Tensorflow之pb文件分析(重要)</a></li><li><a href="https://blog.csdn.net/qq_36653505/article/details/86526310" target="_blank" rel="noopener">查看TensorFlow的pb模型文件的ops和tensor并使用TensorBoard可视化(重要)</a></li><li><a href="https://blog.csdn.net/fu6543210/article/details/80343345" target="_blank" rel="noopener">tensorflow保存数据为.ｐｂ格式和加载ｐｂ文件</a></li><li><a href="https://zhuanlan.zhihu.com/p/32887066" target="_blank" rel="noopener">知乎——TensorFlow 保存模型为 PB 文件(重要)</a></li><li><a href="https://www.zhihu.com/question/49637656/answer/142035602" target="_blank" rel="noopener">知乎——tensorflow如何从pb or pbtxt中训练一个model？(非常重要)</a></li><li><a href="https://zhuanlan.zhihu.com/p/47649285" target="_blank" rel="noopener">知乎——TensorFlow应用.pb文件保存和加载模型方法及相关注意事项</a></li><li><a href="https://www.zhihu.com/question/58287577?sort=created" target="_blank" rel="noopener">知乎——tensorflow训练好的模型怎么调用？</a></li><li><a href="http://czx.im/2018/04/18/Tensorflow6/" target="_blank" rel="noopener">Tensorflow学习笔记6(Transfer Learning迁移学习）(重要)</a></li><li><a href="https://www.jianshu.com/p/613c3b08faea" target="_blank" rel="noopener">TensorFlow学习笔记：Retrain Inception_v3（一）(重要)</a></li><li><a href="https://www.jianshu.com/p/4e5b3e652639" target="_blank" rel="noopener">Inception-v2/v3结构解析（原创）(重要)</a></li><li><a href="http://wenda.chinahadoop.cn/question/5890" target="_blank" rel="noopener">Inception V3要避免bottleneck，而ResNet使用了bottleneck，这该如何理解？</a></li><li><a href="https://blog.csdn.net/zziahgf/article/details/82801098" target="_blank" rel="noopener">网络结构之 Inception V3(重要)</a></li><li><a href="https://tensorflow.juejin.im/tutorials/image_retraining.html" target="_blank" rel="noopener">重新训练 Inception 最后一层并识别新的分类(非常重要)</a></li></ol></blockquote>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 迁移学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VGG16迁移学习分析</title>
      <link href="/2019/06/04/transfer-learning/"/>
      <url>/2019/06/04/transfer-learning/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>整理使用VGG16框架进行迁移学习的方法步骤.</strong><br><a id="more"></a></p></blockquote><h2 id="1-迁移学习简介"><a href="#1-迁移学习简介" class="headerlink" title="1. 迁移学习简介"></a>1. 迁移学习简介</h2><blockquote><p>深度学习中最强大的理念之一就是有时候神经网络可以从一个任务中学习到知识，并将这些知识应用到另一个独立的任务中。比如现在你训练好了一个神经网络能够识别像猫这样的对象，然后使用这些学习到的知识去帮助你更好的阅读<strong>X射线扫描图</strong>，这就是所谓的<strong>迁移学习</strong>。</p></blockquote><h2 id="2-VGG-Network介绍"><a href="#2-VGG-Network介绍" class="headerlink" title="2. VGG Network介绍"></a>2. VGG Network介绍</h2><blockquote><p><strong>「VGG Network」</strong>，牛津大学<strong>VGG</strong>实验室设计的架构，将<strong>AlexNet</strong>的$8$层提高到了$19$层，真正让深度这个词得以充分体现。从<strong>VGG</strong>开始，人们不再使用太大的卷积核，取而代之的是若干个小卷积核的组合。比如， $3$个步长为$1$的$3 \times 3$卷积核，可以拥有同$1$个$7 \times 7$的卷积核一样的感受野，但是，它可以使整个网络变得更深，并且更具有非线性。同时，还能够进一步减少训练的参数量。</p></blockquote><p>下图是各个著名网络的对比相关信息以及<strong>「VGG Network」</strong>的信息：<br><img src= "/img/loading.gif" data-src="/2019/06/04/transfer-learning/1559623117786.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/04/transfer-learning/1559623163942.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/06/04/transfer-learning/1559623226922.png" alt="Alt text"></p><h2 id="3-迁移学习实际操作步骤"><a href="#3-迁移学习实际操作步骤" class="headerlink" title="3. 迁移学习实际操作步骤"></a>3. 迁移学习实际操作步骤</h2><p>首先，整个操作过程借鉴一下文章：</p><blockquote><ol><li><a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/5-16-transfer-learning/" target="_blank" rel="noopener">迁移学习 Transfer Learning</a></li><li><a href="https://www.cnblogs.com/zengfanlin/p/8886701.html" target="_blank" rel="noopener">用tensorflow迁移学习猫狗分类</a></li></ol></blockquote><p>其中这里的得到的<strong>VGG pre-trained model</strong>是使用<a href="https://github.com/machrisaa/tensorflow-vgg" target="_blank" rel="noopener">machrisaa/tensorflow-vgg</a>改写的<strong>VGG16的代码</strong>以及在他的<strong>GitHub</strong>下提供的训练好了的<strong>model parameters</strong>，也就是<strong>VGG16 NPY</strong>文件，如果下载不了的话，可以通过一下网页以百度云的方式下载：<a href="https://www.jianshu.com/p/c9d06e794393" target="_blank" rel="noopener">简书——vgg16.npy 和vgg19.npy</a>。</p><p>权重文件下载完毕之后，建立相应的项目，在项目下建立一个文件夹来存放<strong>VGG16.npy</strong>文件：<img src= "/img/loading.gif" data-src="/2019/06/04/transfer-learning/1559624035247.png" alt="Alt text"></p><p>数据文件在上面的网页<a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/5-16-transfer-learning/" target="_blank" rel="noopener">迁移学习 Transfer Learning</a>中可以找到下载，<strong>VGG16</strong>是针对<strong>ImageNet</strong>的$1000$个类别的众多图片做<strong>分类</strong>任务进行训练的，在本次的迁移学习任务中，我们利用了图片分类的网络，在最后迁移到利用$CNN$做回归的任务中去，对于前面的卷积层(<strong>CNN Layers</strong>)依旧保留，而后面的<strong>Fully Connected Layers</strong>，对其进行修改，将用于分类$1000$个<strong>softmax</strong>层删掉，在网上下载那$1000$个分类数据中的猫和老虎的图片, 然后伪造一些猫和老虎长度的数据。最后做到让迁移后的网络分辨出猫和老虎的长度 (<strong>regressor</strong>)的<strong>回归任务</strong>。</p><p>而项目目录下的<strong>transfer_learning.py</strong>文件就是迁移学习的具体代码，我们这里对几个重要的点一一作出分析。</p><h3 id="3-1-固定卷积层-训练全连接"><a href="#3-1-固定卷积层-训练全连接" class="headerlink" title="3.1 固定卷积层 + 训练全连接"></a>3.1 固定卷积层 + 训练全连接</h3><blockquote><p><strong>首先，对于迁移学习需要注意几点</strong>：</p><ol><li>如果你的数据集很小，你可能只需要<strong>重新训练最后一层的权重</strong>，并<strong>保持前面的参数不动</strong>，经验规则就是如果你的新的数据集比较小，那么就只训练输出层的最后一两层，而数据很多的时候，也许你可以重新训练神经网络中所有的参数；</li><li>如果放射科的数据足够多，那么你可以重新训练神经网络剩下的所有层；</li><li>当你新的数据足够多的时候，你重新训练神经网络中所有的参数的时候，那么在图像识别数据进行的初期训练阶段被称之为<strong>预训练(pre-training)</strong>，因为你使用图像识别数据去训练的时候，是以数据量多的那个任务预训练好的参数初始化神经网络的权重，然后如果你以后更新所有权重然后在另一个数据量少的任务上进行训练，这个过程被称之为<strong>微调(fine-tuning)</strong>。</li></ol></blockquote><p>在这个将$1000$个类别进行分类的任务迁移到动物体长预测的回归任务中，回归任务的数据量不是很多，因此，我们在这里将最后一层修改为回归神经元，在训练的时候只训练最后一层的参数。</p><p>那么迁移学习实际在代码中对应着什么意思呢？通过分析代码我发现，整体是这样的：</p><blockquote><ol><li>首先对于下图中用红色矩形框出的代码：<img src= "/img/loading.gif" data-src="/2019/06/04/transfer-learning/1559625253556.png" alt="Alt text"><br>红色框的代码是一个非常重要的点，需要明确的是，<strong>self.data_dict</strong>用于存放<strong>VGG16</strong>预训练过后得到的参数，它是一个字典类型，存放着一共有16个键值对。<strong>data_dict</strong>的<strong>keys</strong>就是对应的每一层的名字(从<strong>conv1</strong>一直到<strong>fc8</strong>)，相应的，<strong>value</strong>则是一个巨型列表(每个元素又是一个<strong>numpy</strong>数组)，每一个<strong>key</strong>对应的<strong>value</strong>都包含两个元素(包含那一层的<strong>weights</strong>和<strong>bias</strong>)，因此迁移就体现在前面整个卷积层的参数是采取固定不动的状态，从<strong>VGG16</strong>文件中读取的，不参与训练；而后面如果将全连接层进行修改，则可训练参数是后面的全连接层。<strong>需要注意的是，最后在训练完毕之后，需要进行预测的时候，不单单需要将预训练的VGG16的参数读取出来，还需要将后面修改了的，进行训练了的全连接层(依你具体改了的层而定)的参数一起导入才能够进行预测。(反正改了什么层去训练，预测的时候就要相应的导入什么层的训练参数)</strong>。</li><li>将<strong>VGG16</strong>预训练的参数导出存放在一个字典里之后，该如何将其分发到每一层呢？具体如下：<blockquote><p>2.1. 首先需要根据前面图片中<strong>VGG16</strong>的框架结构，在代码中将其框架结构复现出来(这里暂时不算池化层，对框架中的全连接层将其改为一层全联机层用于回归，卷积层不改变)；<br>2.2. 复现前面卷积层的框架之后，定义下面的封装好的卷积层和池化层代码：<br><img src= "/img/loading.gif" data-src="/2019/06/04/transfer-learning/1559626059290.png" alt="Alt text"><br>2.3. 在复现框架的过程中，对于权重(<strong>Weights</strong>)和偏置(<strong>bias</strong>)，使用下面方法获取预训练完毕的结果：<img src= "/img/loading.gif" data-src="/2019/06/04/transfer-learning/1559626162296.png" alt="Alt text">，也就是说，从前面保存参数的字典中按照每一层对应的层名，以字典方式获取预训练完毕的参数结果。<br>2.4. 而最后几层的全连接层，由于需要修改以进行迁移，因此对于修改了的层就不需要导入预训练好了的参数值了，而是以相应的初始化方式进行初始化，然后训练修改了的那几层的参数，<strong>由此可得，在迁移学习中根据数据量的大小，对想要的层进行修改之后，未修改的层的参数就带入预训练好了的参数，而修改了的层的参数就按照某种方式进行初始化，然后仅仅训练想要的那几层好了。</strong></p></blockquote></li><li>最后训练完毕之后，准备进行预测的时候，前面卷积层的参数依旧是按照上面的方式从存放所有预训练参数的字典中获取，而修改了的进行训练了的层则需要从训练完毕的参数文件中进行读取，这样才能进行预测：<br><img src= "/img/loading.gif" data-src="/2019/06/04/transfer-learning/1559626588927.png" alt="Alt text"></li></ol></blockquote><h3 id="3-2-VGG16各层参数的shape以及数目"><a href="#3-2-VGG16各层参数的shape以及数目" class="headerlink" title="3.2 VGG16各层参数的shape以及数目"></a>3.2 VGG16各层参数的shape以及数目</h3><pre><code>————————————————————————————————————————————————————————————Layer                   Output Shape               Param #============================================================conv1_1_weights         (3, 3, 3, 64)              1728conv1_1_bias            (64,)                      64————————————————————————————————————————————————————————————conv1_2_weights         (3, 3, 64, 64)             36864conv1_2_bias            (64,)                      64————————————————————————————————————————————————————————————conv2_1_weights         (3, 3, 64, 128)            73728conv2_1_bias            (128,)                     128————————————————————————————————————————————————————————————conv2_2_weights         (3, 3, 128, 128)           147456conv2_2_bias            (128,)                     128————————————————————————————————————————————————————————————conv3_1_weights         (3, 3, 128, 256)           294912conv3_1_bias            (256,)                     256————————————————————————————————————————————————————————————conv3_2_weights         (3, 3, 256, 256)           589824conv3_2_bias            (256,)                     256————————————————————————————————————————————————————————————conv3_3_weights         (3, 3, 256, 256)           589824conv3_3_bias            (256,)                     256————————————————————————————————————————————————————————————conv4_1_weights         (3, 3, 256, 512)           1179648conv4_1_bias            (512,)                     512————————————————————————————————————————————————————————————conv4_2_weights         (3, 3, 512, 512)           2359296conv4_2_bias            (512,)                     512————————————————————————————————————————————————————————————conv4_3_weights         (3, 3, 512, 512)           2359296conv4_3_bias            (512,)                     512————————————————————————————————————————————————————————————conv5_1_weights         (3, 3, 512, 512)           2359296conv5_1_bias            (512,)                     512————————————————————————————————————————————————————————————conv5_2_weights         (3, 3, 512, 512)           2359296conv5_2_bias            (512,)                     512————————————————————————————————————————————————————————————conv5_3_weights         (3, 3, 512, 512)           2359296conv5_3_bias            (512,)                     512————————————————————————————————————————————————————————————fc6_weights             (25088, 4096)              102760448fc6_bias                (4096,)                    4096————————————————————————————————————————————————————————————fc7_weights             (4096, 4096)               16777216fc7_bias                (4096,)                    4096————————————————————————————————————————————————————————————fc8_weights             (4096, 1000)               4096000fc8_bias                (1000,)                    1000————————————————————————————————————————————————————————————============================================================Total params: 138357544</code></pre><p>由此可见，<strong>vgg16.npy</strong>文件很大不是没有原因的。</p><h2 id="4-如何固定住参数"><a href="#4-如何固定住参数" class="headerlink" title="4. 如何固定住参数"></a>4. 如何固定住参数</h2><blockquote><p>首先需要明确一点的是，<strong>tf.Optimizer</strong>只优化<strong>tf.GraphKeys.TRAINABLE_VARIABLES</strong>中的变量，也就是说在进行<strong>Backpropagation</strong>参数更新的，只会回传梯度到<strong>Variable(变量)</strong>上去，常量是被固定住了，不会被更新的(<a href="https://blog.csdn.net/touch_dream/article/details/78446863" target="_blank" rel="noopener">tf常用集合及其获取方式</a>)。<br>因此在<strong>迁移学习</strong>中对于很多预训练了的框架，想要在迁移的时候对部分参数进行固定以避免训练的话，可以通过使用<strong>tf.constant</strong>或者<strong>python</strong>变量的形式来规避常量被训练。例如：<a href="https://blog.csdn.net/xys430381_1/article/details/88885580" target="_blank" rel="noopener">tensorflow —-迁移学习中如何只更新部分参数</a>，在这篇博客里详细讨论了如何固定部分参数，只训练另一部分参数的方法技巧。</p><hr><p>这里再附上一些相关的参考博客：</p><ol><li><a href="https://blog.csdn.net/grllery/article/details/80380332" target="_blank" rel="noopener">迁移学习之—tensorflow选择性加载权重</a></li><li><a href="https://blog.csdn.net/u014381600/article/details/71511794" target="_blank" rel="noopener">迁移学习技巧以及如何更好的finetune 模型(重点)</a></li><li><a href="https://www.jianshu.com/p/07426ba049b6" target="_blank" rel="noopener">简书——迁移学习总结</a></li><li><a href="https://blog.csdn.net/LoseInVain/article/details/78935157" target="_blank" rel="noopener">利用numpy数组保存TensorFlow模型的参数</a></li><li><a href="https://blog.csdn.net/qq_40108803/article/details/83627532" target="_blank" rel="noopener">读取VGG16网络生成的.npy文件的参数</a></li><li><a href="https://blog.csdn.net/qq_40614981/article/details/81001971" target="_blank" rel="noopener">模型保存文件.npy</a></li><li><a href="https://codeday.me/bug/20190401/856668.html" target="_blank" rel="noopener">python – Tensorflow：tf.get_collection不返回范围中的变量</a></li><li><a href="https://blog.csdn.net/shwan_ma/article/details/78879620" target="_blank" rel="noopener">[tensorflow]打印Tensorflow graph中的所有需要训练的变量—tf.trainable_variables()</a></li><li><a href="http://www.voidcn.com/article/p-mepbcmhk-bgt.html" target="_blank" rel="noopener">tensorflow常用函数及概念</a></li></ol></blockquote><p>在本代码中，由于卷积层是直接使用的<strong>VGG16</strong>的模型框架，注入的参数也是直接使用的是<strong>.npy</strong>文件导出的数据进行初始化的，而不是使用的<strong>TensorFlow</strong>中<strong>Varibale的方式初始化的</strong>。因此在之后训练的时候只会更新后改了的全连接层的参数(修改了的全连接层的参数通过<strong>Varibale的方式初始化的</strong>)，而前面的都是<strong>常量(constant)</strong>。这一点可以通过<code>tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))</code>的方式看出：<br><img src= "/img/loading.gif" data-src="/2019/06/04/transfer-learning/1559675934438.png" alt="Alt text"><br>打印出来的结果如下：</p><pre><code>[ &lt; tf.Variable &#39;fc6/kernel:0&#39; shape = (25088, 256) dtype = float32_ref &gt;,  &lt; tf.Variable &#39;fc6/bias:0&#39; shape = (256,) dtype = float32_ref &gt;,  &lt; tf.Variable &#39;out/kernel:0&#39; shape = (256, 1) dtype = float32_ref &gt;,  &lt; tf.Variable &#39;out/bias:0&#39; shape = (1,) dtype = float32_ref &gt;]</code></pre><p>可以看出<strong>Variable</strong>变量只有后面修改了的全连接层的参数，前面的卷积层的参数都是常量，不参与到参数更新，因此也就被固定住了，不参与到训练过程中。</p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 卷积神经网络 </tag>
            
            <tag> 迁移学习 </tag>
            
            <tag> VGG16 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>预测代码中遇到的问题</title>
      <link href="/2019/05/30/tensorflow-save-and-restore/"/>
      <url>/2019/05/30/tensorflow-save-and-restore/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>记录预测代码模块化过程中遇到的问题.</strong><br><a id="more"></a></p></blockquote><h2 id="1-TensorFlow模型的保存和提取"><a href="#1-TensorFlow模型的保存和提取" class="headerlink" title="1. TensorFlow模型的保存和提取"></a>1. TensorFlow模型的保存和提取</h2><h3 id="1-1-模型保存"><a href="#1-1-模型保存" class="headerlink" title="1.1 模型保存"></a>1.1 模型保存</h3><blockquote><pre><code>saver = tf.train.Saver(max_to_keep=num, var_list=var_list)saver.save(sess, model_save_path, global_step=i)</code></pre><p>需要注意的是<strong>max_to_keep</strong>用于指定需要保存的模型个数，<strong>var_list</strong>指定要保存和恢复的变量，如果<code>saver=tf.train.Saver()</code>里面不传入参数，默认保存全部变量。在模型运行运行结束后会生成<strong>4</strong>个文件，分别是：</p><ol><li><strong>checkpoint</strong>文件保存了一个目录下所有的模型文件列表，这个文件是<code>tf.train.Saver</code>类自动生成且自动维护的，它是一个二进制文件，包含了weights, biases, gradients和其他variables的值。但是0.11版本后的都修改了，用.data和.index保存值，用checkpoint记录最新的记录。；</li><li><strong>meta</strong>文件保存了<strong>TensorFlow</strong>计算图的结构，可以理解为神经网络的网络结构，<strong>TensorFlow</strong>通过元图（<strong>MetaGraph</strong>）来记录计算图中节点的信息以及运行计算图中节点所需要的元数据，它一个协议缓冲，保存<strong>tensorflow</strong>中完整的<strong>graph</strong>、<strong>variables</strong>、<strong>operation</strong>、<strong>collection</strong>。；</li><li><strong>data-00000-of-00001</strong>文件保存了<strong>TensorFlow</strong>程序中每一个变量的取值，这个文件是通过<strong>SSTable</strong>格式存储的，可以大致理解为就是一个（<strong>key，value</strong>）列表；</li><li><strong>index</strong>是对应模型的索引文件；</li><li>如果想设置每多长时间保存一次，可以设置<code>saver = tf.train.Saver(keep_checkpoint_every_n_hours=2)</code>，这个是每<strong>2</strong>个小时保存一次；</li><li>如果不想保存所有变量，可以在创建<strong>saver</strong>实例时，指定保存的变量，可以以<strong>list</strong>或者<strong>dict</strong>的类型保存，如下：<pre><code>w1 = tf.Variable(tf.random_normal(shape=[2]), name=&#39;w1&#39;)w2 = tf.Variable(tf.random_normal(shape=[5]), name=&#39;w2&#39;)saver = tf.train.Saver([w1,w2])</code></pre><h3 id="1-2-模型提取"><a href="#1-2-模型提取" class="headerlink" title="1.2 模型提取"></a>1.2 模型提取</h3></li></ol></blockquote><pre><code>&#39;&#39;&#39;在一个新的python脚本文件中&#39;&#39;&#39;import tensorflow as tf&#39;&#39;&#39;导入其他库&#39;&#39;&#39;pass&#39;&#39;&#39;其他数据准备工作&#39;&#39;&#39;&#39;&#39;&#39;这里不需要重新搭建模型&#39;&#39;&#39;&#39;&#39;&#39;提取模型，首先提取计算图，这一步相当于搭建模型&#39;&#39;&#39;saver = tf.train.import_meta_graph(&quot;model/mnist.ann-10000.meta&quot;)with tf.Session() as sess:    &#39;&#39;&#39;提取保存好的模型参数&#39;&#39;&#39;    &#39;&#39;&#39;这里注意模型参数文件名要丢弃后缀.data-00000-of-00001&#39;&#39;&#39;    saver.restore(sess, &quot;model/mnist.ann-10000&quot;)    &#39;&#39;&#39;通过张量名获取张量&#39;&#39;&#39;    &#39;&#39;&#39;这里按张量名获取了我保存的一个模型的三个张量，并换上新的名字&#39;&#39;&#39;    new_x = tf.get_default_graph().get_tensor_by_name(&quot;x:0&quot;)    new_y = tf.get_default_graph().get_tensor_by_name(&quot;y:0&quot;)    new_y_ = tf.get_default_graph().get_tensor_by_name(&quot;y_:0&quot;)    &#39;&#39;&#39;现在可以进行计算了&#39;&#39;&#39;    y_1 = sess.run(new_y_, feed_dict={new_x: new_x_data, new_y: new_y_data})print(y_1)</code></pre><h3 id="1-3-从断点处继续训练模型"><a href="#1-3-从断点处继续训练模型" class="headerlink" title="1.3 从断点处继续训练模型"></a>1.3 从断点处继续训练模型</h3><pre><code>with tf.Session() as sess:sess.run(tf.global_variables_initializer())saver = tf.train.Saver()ckpt = tf.train.get_checkpoint_state(os.path.dirname(&#39;checkpoints_path&#39;))# 如果checkpoint存在则加载断点之前的训练模型if ckpt and ckpt.model_checkpoint_path:    saver.restore(sess, ckpt.model_checkpoint_path)</code></pre><h3 id="1-4-模型结构是否需要重新定义"><a href="#1-4-模型结构是否需要重新定义" class="headerlink" title="1.4 模型结构是否需要重新定义"></a>1.4 模型结构是否需要重新定义</h3><blockquote><p>当我们将模型的预测部分与训练部分进行分裂，各自模块化之后，如果想要进行预测的时候，有两种方式：</p><ol><li><strong>重新定义网络结构: </strong> <pre><code>saver.restore(sess,&quot;save/model.ckpt&quot;)</code></pre>这种方法不方便的在于，在使用模型进行预测的时候，必须把模型的网络结构重新定义一遍，然后载入对应名字的变量的值。但是很多时候我们都更希望能够读取一个文件然后就直接使用模型，而不是还要把模型的网络结构(<strong>Inference</strong>)重新定义一遍。所以就需要使用另一种方法。</li><li><strong>不需重新定义网络结构的方法: </strong><pre><code>def load_model(): with tf.Session() as sess:     saver = tf.train.import_meta_graph(&#39;model/my-model-290.meta&#39;)     saver.restore(sess, tf.train.latest_checkpoint(&quot;model/&quot;))</code></pre>首先<strong>import_meta_graph</strong>，这里填的名字是<strong>meta</strong>文件的名字。然后<strong>restore</strong>时，是检查<strong>checkpoint</strong>，所以只填到<strong>checkpoint</strong>所在的路径下即可，不需要填<strong>checkpoint</strong>，不然会报错<strong>“ValueError: Can’t load save_path when it is None.”</strong>。这个方法可以从文件中将保存的<strong>graph</strong>的所有节点加载到当前的<strong>default graph</strong>中，并返回一个<strong>saver</strong>。也就是说，我们在保存的时候，除了将变量的值保存下来，其实还有将对应<strong>graph</strong>中的各种节点保存下来，所以模型的结构也同样被保存下来了。</li></ol></blockquote><h3 id="1-5-相关网址"><a href="#1-5-相关网址" class="headerlink" title="1.5 相关网址"></a>1.5 相关网址</h3><blockquote><ol><li><a href="https://blog.csdn.net/liuxiao214/article/details/79048136" target="_blank" rel="noopener">【tensorflow】保存模型、再次加载模型等操作</a></li><li><a href="https://www.jianshu.com/p/52e7ae04cecf" target="_blank" rel="noopener">TensorFlow模型保存/载入的两种方法</a></li><li><a href="https://blog.csdn.net/shu15121856/article/details/85063043" target="_blank" rel="noopener">【TensorFlow学习笔记】5：variable_scope和name_scope,图的基本操作</a></li><li><a href="https://www.jianshu.com/p/c3a7f5c47b83" target="_blank" rel="noopener">TensorFlow：保存和提取模型</a></li><li><a href="https://www.jianshu.com/p/cb48e8e91d96" target="_blank" rel="noopener">2018-06-25《TensorFlow模型保存、提取、预测》</a></li><li><a href="https://blog.csdn.net/leo_xu06/article/details/79200634" target="_blank" rel="noopener">Tensorflow在不同训练场景下读取和使用不同格式pretrained model的方法</a></li><li><a href="https://blog.csdn.net/spylyt/article/details/71601174" target="_blank" rel="noopener">tensorflow 模型保存与加载</a></li><li><a href="https://blog.csdn.net/mieleizhi0522/article/details/80535189" target="_blank" rel="noopener">Tensorflow中保存与恢复模型tf.train.Saver类讲解（恢复部分模型参数的方法）</a></li></ol></blockquote>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>目标检测算法(2)</title>
      <link href="/2019/05/27/object-detection-1/"/>
      <url>/2019/05/27/object-detection-1/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>详细记录目标检测算法整个过程的原理.</strong><br><a id="more"></a></p></blockquote><h3 id="1-5-Bounding-Box-预测"><a href="#1-5-Bounding-Box-预测" class="headerlink" title="1.5 Bounding Box 预测"></a>1.5 Bounding Box 预测</h3><blockquote><p>卷积的滑动窗口实现效率很高，但是存在输出边界框不精确的问题。</p></blockquote><p>在滑动窗算法中，我们取这些离散的位置集合，然后在它们上面跑分类器。在这种情况下很有可能没有一个能完美匹配汽车位置的边界框，而真正完美的边界框甚至都是有点长方形的。<br><img src= "/img/loading.gif" data-src="/2019/05/27/object-detection-1/1558920463424.png" alt="Alt text"></p><p>其中一个能够得到更加精确的边界框的算法是$YOLO$，它的做法如下：</p><blockquote><p>首先，假设你的输入图片为$100 \times 100$，然后在图片上放入网格(这里假设使用的是$3 \times 3$的网格，实际在使用的时候会用更加精细的网格)。基本思路是<strong>使用图像分类和定位算法</strong>，然后将相应的算法逐一应用到这$9$个格子上。<br>更加具体一点的就是，你需要定义训练标签，所以对于$9$个格子中的每一个，指定一个标签$y$，其中$y$是和以前一样的$8$维向量：</p><script type="math/tex; mode=display">y =  \begin{bmatrix} p_c \\ b_x \\ b_y \\ b_h \\b_w \\c_1 \\ c_2 \\ c_3\end{bmatrix}</script><p>其中$(b_x, b_y, b_h, b_w)$代表如果那个格子有对象，那么就给出边界框(红色)的坐标。因此对于下面的图像有$9$个格子，则会有$9$个长度一样的标签向量。<br><img src= "/img/loading.gif" data-src="/2019/05/27/object-detection-1/1558921343655.png" alt="Alt text"><br>以上图中左上角的紫色包围的格子为例，由于里面什么都没有，因此：</p><script type="math/tex; mode=display">y =  \begin{bmatrix} 0 \\ ? \\ ? \\ ? \\ ? \\ ? \\ ? \\ ? \end{bmatrix}</script><hr><p>上图中第二行的第二个格子同时包含两量车的一部分，对于$YOLO$算法来说，要做的就是，取两个对象的重点，然后将各自的对象分配给包含对象中点的格子(这里这个格子指的是<strong>YOLO</strong>算法中将图像划分成很多个格子的那个格子，而不是指的边界框)。因此右边那辆车就分配给第二行第三个格子了。<br><img src= "/img/loading.gif" data-src="/2019/05/27/object-detection-1/1558921836899.png" alt="Alt text"></p></blockquote><p>对于上图中绿色框定的格子的标签值为:</p><script type="math/tex; mode=display">y =  \begin{bmatrix} 1\\ b_x \\ b_y \\ b_h \\b_w \\0\\ 1\\ 0\end{bmatrix}</script><p>因此对于每一个格子都是一个$8$维的输出，而整个图片是$3 \times 3$，因此，最后总的输出为$3 \times 3 \times 8$。<br><img src= "/img/loading.gif" data-src="/2019/05/27/object-detection-1/1558922138471.png" alt="Alt text"></p><p>如果你现在要训练一个输入为$100 \times 100 \times 3$的神经网络，然后通过一个普通的卷积网络，和选定的各个池化层等等… …最后映射到一个$3 \times 3 \times 8$的输出尺寸(这个应该是根据你一开始就将输入图片选定要生成多少网格就可以得到)，当你使用反向传播进行训练的时候，将任意输入$x$映射到这类输出向量$y$，<strong>这个算法的好处在于神经网络可以输出精确的边界框</strong>。只是需要注意的是只要每个格子的对象数目没有超过$1$个，那这个算法就是$ok$的，至于超过一个需要怎么处理，后面再讲。</p><p>另一个需要注意的是，例子中我们采用的是$3 \times 3$的网格，而在实践中我们可能会采用更精细的$19 \times 19$，所以得到的输出为$19 \times 19 \times 8$，那个时候同一个格子被分配多个对象的概率就会小得多。</p><p>再次强调的是: $YOLO$算法把对象分配到一个格子的过程是，观察对象的重点，然后将这个对象分配到其中点所在的格子，所以一个对象即使横跨了多个格子，也只会被分配到$9$个格子中的一个，而在越精细的格子数目划分中，两个对象的中点处于同一个格子的概率就会更低。$YOLO$算法能够让神经网络输出边界框可以具有任意的宽高比，并且能够输出更加精确的坐标，而又避免了滑动窗口分类器的步长大小限制；其次，这是一个卷积过程，算法并没有在$3 \times 3$的网格上跑$9$次算法，相反，这是单次卷积实现的，因为使用了卷积，使得很多过程共享计算步骤，所以这个算法效率很高，实际上它由于是卷积过程，它的运行速度非常快，可以达到事实识别。<br><img src= "/img/loading.gif" data-src="/2019/05/27/object-detection-1/1558923754768.png" alt="Alt text"></p><hr><p>如果编码标签中的边界框的位置$(b_x, b_y, b_h, b_w)$？<br>还是以上面的图为例，网格的大小设定为$3 \times 3$，我们以第二行第三个格子(面包车)为例，其标签为：</p><script type="math/tex; mode=display">y =  \begin{bmatrix} 1\\ b_x \\ b_y \\ b_h \\b_w \\0\\ 1\\ 0\end{bmatrix}</script><p>在$YOLO$算法中对于黄色的框，我们取它左上角的蓝色点为原点$(0, 0)$，而去黄色框的右下角的蓝色点为$(1,1)$(这与滑动窗口卷积中取整个图像左上角为原点$(0, 0)$，整个图片左下角为$(1, 1)$的方式是不同的)，所以要指定黄色中点的位置，对于$(b_x, b_y)$大体是$(0.4, 0.3)$，而对于$(b_h, b_w)$则红色框相较于格子的比例大小，这个大概为$(0.9, 0.5)$。换句话说，$(b_x, b_y, b_h, b_w)$是相对于格子尺度的比例大小。所以$(b_x, b_y)$必须在$(0,1)$之间，都在它就该被分配到别的格子了，而边界框的大小时可能是大于$1$的。</p><hr><p>所以最后总结一下:</p><blockquote><ol><li><p>滑动窗口的方式是选取固定大小的窗口进行滑动检测，因此会存在边界框不准确的情况，因为物体有大有小， 所以这种方式无法的到准确的位置；</p></li><li><p>而$YOLO$算法则不同，采用的是<strong>图像分类+目标定位+划分网格</strong>的方式去做的，而目标定位的特点就是得到的输出结果的标签中是包含物体的边界框参数的，这个东西会根据物体的大小和形状，得到不同的长方形或者正方形，所以说$YOLO$算法是能够得到物体精确的位置的，除此之外，$YOLO$通过划分网格的方式，直接一次卷积就可以得到相应的结果，而不是重复的让自己设定的滑动窗按照给定的步长滑过图像，这样计算就会非常的快速了，而相较于滑动窗口的卷积处理而言，虽然滑动窗口的卷积处理而言也是很快的，避免了大量重复计算，但是实际上的结果也是相当于取固定大小的边界框和固定大小的步长，只不过相比较于滑动窗口不断滑动的多次重复计算而言，滑动窗口的卷积处理通过全连接改动为卷积的神操作，一次卷积就达到了滑动窗口算法的效果<strong>(滑动窗口在整幅图片上进行滑动卷积的操作过程，就等同于在该图片上直接进行卷积运算的过程)</strong>，只不过还是那个致命问题：不管是固定的边界框和固定的步长还是滑动窗口的卷积操作中最后效果中相当于固定的边界框和固定的步长，都出在固定上了，这就造成了它们的输出结果不能得到物体的精确边界框。</p></li><li>因此实际上$YOLO$算法的网格划分是类似滑动窗口的卷积处理的，这也就使得$YOLO$一次卷积就$ok$了，而不是依据网格多少就跑多少次卷积的方式，那样就和滑动窗口一样了，另一点，需要注意的是，$YOLO$的网格划分其实类似于滑动窗口中的固定边界框大小，但是这种固定边界框大小的做法得到的结果是比较不精确的，所以$YOLO$再结合<strong>目标定位算法</strong>，这样再在固定大小的边界框(网格)中获得精确定位的边界框参数，所以才能有好的效果。</li><li><strong>YOLO</strong>显式地输出边界框，使得其可以具有任意宽高比，并且能输出更精确的坐标，不受滑动窗口算法滑动步幅大小的限制；</li><li><strong>YOLO</strong>是一次卷积实现，并不是在$n\times n $网格上进行$n^{2}$次运算，而是单次卷积实现，算法实现效率高，运行速度快，可以实现实时识别。</li></ol></blockquote><h3 id="1-6-交并比-Intersection-over-union"><a href="#1-6-交并比-Intersection-over-union" class="headerlink" title="1.6 交并比(Intersection over union)"></a>1.6 交并比(Intersection over union)</h3><blockquote><p><strong>交并比(Intersection over union):</strong> 用于评价对象算法，从而进一步改善对象检测算法，它通过计算两个边界框的交集和并集得到。</p></blockquote><p>在下图中，包围汽车的红色边界框代表实际的边界框，而结果你的算法给出了下面的紫色边框，那么这个结果是好呢还是坏呢？</p><blockquote><p><strong>Intersection over union: </strong></p><script type="math/tex; mode=display">IOU = \frac{intersection}{union}</script><p>对于上面的计算，一般约定，在计算机检测任务中：</p><script type="math/tex; mode=display">f(n)= \begin{cases} correct, & \text {if IOU $\geq$ 0.5} \\  \end{cases}</script><p>因此$IOU \geq 0.5$是一个阈值，用来判断预测的边界框是否正确。</p></blockquote><h3 id="1-7-非极大值抑制-Non-max-suppression"><a href="#1-7-非极大值抑制-Non-max-suppression" class="headerlink" title="1.7 非极大值抑制(Non-max suppression)"></a>1.7 非极大值抑制(Non-max suppression)</h3><blockquote><p>对象检测算法的一个可能的问题就是同一个对象被算法做出多次检测。而非极大值抑制可能帮助你的算法对每个对象只检测一次。<br><img src= "/img/loading.gif" data-src="/2019/05/27/object-detection-1/1558929523282.png" alt="Alt text"><br>假设现在你要在这张图片中检测行人和汽车，而现在你在图片上放$19 \times 19$的网格，那么对于不同的格子都是用<strong>图像分类+目标定位算法</strong>时，对于一辆车所占领的不同格子，都可能会觉得它们的格子里有车，<br><img src= "/img/loading.gif" data-src="/2019/05/27/object-detection-1/1558929740177.png" alt="Alt text"><br>因为划分为$n \times n$个网格，每个网格都会使用<strong>图像分类+目标定位算法</strong>，因此，很多格子可能都会举手说，我这个格子里有车的概率很高。因此当算法运行完毕之后，最后可能会对同一个对象做出多次检测，所以<strong>非极大值抑制</strong>要做的就是清理这些检测结果，使得每个物体仅被检测一次。</p></blockquote><p>首先这个算法每次会查看每个检查结果相关的概率$p_c \times c_1/c_2/c_3$，在下图中首先看右边那个最大的概率$0.9$，然后<strong>非极大值</strong>抑制就会逐一审视剩下的矩形：<strong>所有和这个最大的边界框有很高交并比、高度重叠的其他边界框</strong>，然后这些输出就会被抑制，所以概率显示为$0.6$和$0.7$的两个框就被抑制了，然后颜色变暗。<br><img src= "/img/loading.gif" data-src="/2019/05/27/object-detection-1/1558937531478.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/05/27/object-detection-1/1558937549748.png" alt="Alt text"></p><p>接下来，逐一审视剩下的矩形，找出概率最高的$p_c$最高的一个，这种情况下是$0.8$，我们就认为这里检测出了一辆车，然后<strong>非最大值抑制算法</strong>就会去掉其他$IOU$值很高的矩形(也就是其他和$0.8$重叠程度很高的矩阵)。所以现在每个矩形都会被高亮显示或者变暗，所以如果直接抛弃变暗的矩形，那就剩下高亮显示的那些矩形，这就是最后得到的两个预测结果：<br><img src= "/img/loading.gif" data-src="/2019/05/27/object-detection-1/1558938603264.png" alt="Alt text"><br>所以<strong>非最大值抑制</strong>意味着你只输出概率最大的分类结果，而抑制很接近，但是不是最大的其他预测结果。</p><hr><p><strong>非极大值抑制</strong>算法的细节如下：</p><blockquote><ol><li>首先假设网格为$19 \times 19$，然后在各个网格上跑一下算法，然后得到尺寸大小为$19 \times 19 \times 8$的输出结果。</li><li>要实现<strong>非极大值抑制</strong>，第一件事是去掉所有预测概率低于某个阈值的边界框，这里假设$p_c \leq 0.6$的框被去掉。</li><li>接下来剩下的边界框(没有被抛弃、没有被处理过的)，你就<strong>一直选择</strong>概率$p_c$最高的边界框，然后把它输出成预测结果。</li><li>接下来去掉所有剩下的边界框：把这些和输出边界框(概率最高的边界框)有很高的重叠面积，也就是和上一步输出边界框有很高的交并比的边界框全部抛弃。</li><li>循环上面的步骤，直到每个边界框都判断过了，它们有的作为输出结果，剩下的会被抛弃。</li><li>上面仅是介绍图片中只有一个类别物体时的情况，如果图片中有多个不同类别的物体时，则相应的独立进行多次非最大值抑制，每次对每个输出类别做一次。<br><img src= "/img/loading.gif" data-src="/2019/05/27/object-detection-1/1558939655151.png" alt="Alt text"></li></ol></blockquote><h3 id="1-8-Anchor-boxes"><a href="#1-8-Anchor-boxes" class="headerlink" title="1.8 Anchor boxes"></a>1.8 Anchor boxes</h3><blockquote><p>到目前为止，对象检测中存在的一个问题是：每个格子只能检测一个对象，如果你想让一个格子检测出多个对象，则可以使用<strong>Anchor Boxes</strong>。</p></blockquote><p><img src= "/img/loading.gif" data-src="/2019/05/27/object-detection-1/1558940177091.png" alt="Alt text"><br>以上图中的例子为例，在图中我们依旧使用的网格大小为$3 \times 3$，从图中我们能够发现一个非常明显的特点：<strong>行人的中点和汽车的中点基本是落在了同一点，也就是行人和汽车的中点都落在了同一个格子里。</strong>又由于我们的算法中涉及图像分类的算法，此时两者落与同一个格子，那么在那个格子的标签值$y$将无法输出检测结果(我们前面都是设定的<strong>多类单标签</strong>预测)。</p><p>而<strong>anchor boxes</strong>的思路是这样的：</p><blockquote><ol><li>预先定义两个不同形状的<strong>anchor boxes</strong>:<img src= "/img/loading.gif" data-src="/2019/05/27/object-detection-1/1558940149829.png" alt="Alt text"></li><li>把预测结果和这两个<strong>anchor boxes</strong>关联起来，一般来说，你可能会用到更多的<strong>anchor boxes</strong>(可能$5$个甚至更多)。</li><li>定义类别标签：<script type="math/tex; mode=display">y =  \begin{bmatrix} p_{c1}\\ b_{x1} \\ b_{y1} \\ ...\\p_{c2} \\b_{x2}\\ ...\\ c_3\end{bmatrix}</script>此时的输出维度为$16$维。上面的$y$的各个分量是对应<strong>anchor box</strong>的分量。<br><img src= "/img/loading.gif" data-src="/2019/05/27/object-detection-1/1558940557063.png" alt="Alt text"></li></ol></blockquote><p>由于存在<strong>anchor boxes</strong>这个概念，现在需要做的是：现在每个对象都和以前一样分配到同一个格子中，分配到对象中点所在的格子中。除此之外，它还被分配到一个和对象形状(应该就是边界框)交并比最高的<strong>anchor boxes</strong>中：假设你的对象形状如下(应该指的就是对象边界框)，然后你就看看你设定的两个<strong>anchor boxes</strong>哪个和实际的边界框的交并比最高，当然 ，不管分配哪一个<strong>anchor boxes</strong>，每个对象都不只分配到一个格子，而是分配到<strong>(网格，anchor boxes)</strong>。除此之外，标签$y$的维度也会变化，如果对象很多，那么$y$的维度也会很多。<br><img src= "/img/loading.gif" data-src="/2019/05/27/object-detection-1/1558941300847.png" alt="Alt text"></p><p>具体例子如下：<br><img src= "/img/loading.gif" data-src="/2019/05/27/object-detection-1/1558941608992.png" alt="Alt text"></p><p>需要注意的是：</p><blockquote><ol><li>假设你现在有两个<strong>anchor boxes</strong>，但是在同一个格子中有三个对象出现，这种情况算法处理不好，此时并没有很好的处理办法；</li><li>当两个对象分配到一个格子中，但是它们的<strong>anchor boxes</strong>形状一样，这是算法处理不好的另一种情况；除非此时引入一些打破僵局的默认手段用于专门处理这些情况。</li></ol></blockquote><hr><p><strong>Summary：</strong></p><blockquote><p>我们建立<strong>anchor boxes</strong>这个概念，是为了处理两个对象出现同一个格子的情况，实践中这种情况很少发生，特别是当你使用的网格大小是$19 \times 19$，两个对象中心处于$361$个格子中同一个格子的概率很低。也许设立<strong>anchor boxes</strong>的好处在于<strong>anchor boxes</strong>能够使你的学习算法，能够更有针对性，特别是如果你的数据集，有一些很高很瘦的对象，比如说：行人。这样让你的算法能够更有针对性。</p></blockquote><p><strong>Anchor box</strong> 的选择：</p><blockquote><ol><li>一般人工指定<strong>Anchor box</strong> 的形状，选择<strong>5~10</strong>个以覆盖到多种不同的形状，可以涵盖我们想要检测的对象的形状；</li><li>高级方法：<strong>K-means</strong> 算法：将不同对象形状进行聚类，用聚类后的结果来选择一组最具代表性的<strong>Anchor box</strong>，以此来代表我们想要检测对象的形状。</li></ol></blockquote><h3 id="1-9-YOLO算法"><a href="#1-9-YOLO算法" class="headerlink" title="1.9 YOLO算法"></a>1.9 YOLO算法</h3><blockquote><ol><li><strong>构造训练集：假设你有两个anchor boxes</strong><br>1.1 标签类别: 行人、汽车、摩托、背景<br>1.2 标签维度：$3 \times 3 \times 2 \times 8$，其中$3 \times 3$是因为选择的网格大小如此，然后$\times 2$代表有两个<strong>anchor boxes</strong>，$\times 8$是因为一个<strong>anchor boxes</strong>所对应的参数量。<br>要构造训练集，需要遍历$9$个格子，然后构成对应的目标向量$y$。对于下面的图可以看出，红色框是边界框，<strong>anchor boxes2</strong>和边界框的交并比要更大一下，那么车子就和向量的下半部分有关了。<br><img src= "/img/loading.gif" data-src="/2019/05/27/object-detection-1/1558946053778.png" alt="Alt text"></li><li><strong>模型预测：</strong><br>输入与训练集中相同大小的图片，同时得到每个格子中不同的输出结果：$3\times3\times2\times8$ 。<br><img src= "/img/loading.gif" data-src="/2019/05/27/object-detection-1/1558946335028.png" alt="Alt text"></li><li><strong>运行非极大值抑制(NMS)</strong>：<br>3.1 假设使用了<strong>2</strong>个<strong>Anchor box</strong>，那么对于每一个网格，我们都会得到预测输出的<strong>2</strong>个<strong>bounding boxes</strong>，其中一个 $P_{c}$比较高；<br><img src= "/img/loading.gif" data-src="/2019/05/27/object-detection-1/1558946471037.png" alt="Alt text"><br>3.2 需要注意的是：有些边界框是可以超过所在格子的高度和宽度的；<br>3.3 接着，抛弃概率$P_{c}$值低的预测<strong>bounding boxes</strong>；<br><img src= "/img/loading.gif" data-src="/2019/05/27/object-detection-1/1558946807709.png" alt="Alt text"><br>3.4 最后，如果你有三个对象检测类别，那么对于每一个类别，单独运行<strong>非最大值抑制</strong>去处理预测结果是对应类别的边界框。<br><img src= "/img/loading.gif" data-src="/2019/05/27/object-detection-1/1558946818419.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/05/27/object-detection-1/1558946885008.png" alt="Alt text"></li></ol></blockquote>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 目标检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>目标检测算法(1)</title>
      <link href="/2019/05/26/object-detection/"/>
      <url>/2019/05/26/object-detection/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>详细记录目标检测算法整个过程的原理.</strong><br><a id="more"></a></p></blockquote><h3 id="1-1-目标定位-Object-Localization"><a href="#1-1-目标定位-Object-Localization" class="headerlink" title="1.1 目标定位(Object Localization)"></a>1.1 目标定位(Object Localization)</h3><blockquote><ol><li><strong>Image Classification(图像分类)</strong></li><li><strong>Classification with Localization(定位分类): </strong>判断图像中是否为某一物体(<strong>分类</strong>)，还要在图片中标记处它的位置(<strong>定位</strong>)，用边框把物体圈出来。<strong>定位分类</strong>问题通常是<strong>图像中只有一个较大的对象，且对象位于图片中间位置。</strong></li><li><strong>Detection(检测):</strong>当图片中有多个对象的时候(<strong>例如自动驾驶中需要检测出汽车、行人以及交通灯等多个对象</strong>)，需要将它们的类别检测出来，还要分别都确定其位置。<br><img src= "/img/loading.gif" data-src="/2019/05/26/object-detection/1558873247390.png" alt="Alt text"></li></ol></blockquote><hr><p>对于<strong>定位分类</strong>问题来说，首先可以明确地是它是<strong>多类单标签</strong>问题，也就是说在图像中它仅有一个物体，这个物体的标签仅有一个，最后的<strong>softmax</strong>层输出最有可能的一个类别概率。</p><p>那么在<strong>分类</strong>基础之上，想要通过网络最后输出除了物体的<strong>类别</strong>之外，还包含物体的<strong>位置(定位)</strong>应该怎么办呢？方法是让神经网络除了仅有的一个<strong>softmax</strong>输出单元之外，再多输出几个单元，这几个单元就是物体的<strong>边界框(bounding box)</strong>。这里具体的就是让神经网络再多输出$4$个数字，分别标记为$(b_x, b_y, b_h, b_w)$，这四个数字就是<strong>bounding box</strong>的参数化。</p><p>这里需要先说明一下基本的设定，对于图像的坐标，我们设定图像的左上角为$(0, 0)$，而右下角的坐标为$(1, 1)$。想要确定<strong>边界框(bounding box)</strong>的具体位置，则需要指定框住了物体的边界框的中心点的坐标为$(b_x, b_y)$，而边界框的高度为$b_h$，宽度为$b_w$。</p><p>因此有上面可知，训练集中不仅包含对象的分类标签，还需要包含表示边界框的这四个数字$(b_x, b_y, b_h, b_w)$。然后将数据输入网络，训练完毕，给出被检测物体的<strong>类别标签</strong>以及想要的<strong>边界框位置</strong>。<br><img src= "/img/loading.gif" data-src="/2019/05/26/object-detection/1558874270553.png" alt="Alt text"></p><hr><p>这里假设我们的类别标签如下：</p><blockquote><ol><li><strong>pedestrain</strong></li><li><strong>car</strong></li><li><strong>motorcycle</strong></li><li><strong>background</strong></li></ol></blockquote><p>因此标签如下：</p><script type="math/tex; mode=display">y =  \begin{bmatrix} p_c \\ b_x \\ b_y \\ b_h \\b_w \\c_1 \\ c_2 \\ c_3\end{bmatrix}</script><blockquote><ol><li>其中$p_c$代表图片中是否有对象，如果对象属于上面类别标签中的前三类，则$p_c = 1$，如果是第$4$类，也就是背景，则代表没有要检测的物体，$p_c = 0$，因此$p_c$代表被检测对象属于某一类别的概率(背景除外)；</li><li>如果检测到对象，则输出被检测对象的边界框参数$(b_x, b_y, b_h, b_w)$；</li><li>当$p_c = 1$时，则$(c_1, c_2, c_3)$输出该对象属于$1-3$中的哪一类，需要注意的是针对分类定位问题，图片中最多只会出现其中一个对象类别。</li></ol></blockquote><p>以下图中有车的图为例，下图的标签输出为：</p><script type="math/tex; mode=display">y =  \begin{bmatrix} 1 \\ b_x \\ b_y \\ b_h \\b_w \\0 \\ 1 \\ 0\end{bmatrix}</script><p>$(c_1, c_2, c_3)$最多只有一个为$1$.</p><p>以下图中只有背景的图为例，下图的标签输出为：</p><script type="math/tex; mode=display">y =  \begin{bmatrix} 0 \\ ?\\ ?\\ ?\\?\\? \\ ? \\ ?\end{bmatrix}</script><p>其中$?$代表无意义的参数.</p><p>最后定义一下训练神经网络的<strong>损失函数</strong>(如果采用<strong>平方误差</strong>策略)</p><script type="math/tex; mode=display">\cal{L}(\hat{y},y)= \begin{cases} (\hat{y}_1 - y_1)^2 + (\hat{y}_2 - y_2)^2 + ... + (\hat{y}_8 - y_8)^2, & \text {if $p_c = 1$} \\ (\hat{y}_1 - y_1)^2, & \text{if $p_c = 0$} \end{cases}</script><p>需要注意的是采用平方误差策略只是为了简化而已，实际一般是对于坐标$(b_x, b_y, b_h, b_w)$采用平方误差，而对$p_c$采用逻辑回归函数，当然，采用平方误差也是可以的。<br><img src= "/img/loading.gif" data-src="/2019/05/26/object-detection/1558877137389.png" alt="Alt text"></p><h3 id="1-2-特征点检测-Landmark-Detection"><a href="#1-2-特征点检测-Landmark-Detection" class="headerlink" title="1.2 特征点检测(Landmark Detection)"></a>1.2 特征点检测(Landmark Detection)</h3><h4 id="1-2-1-人脸部特征定位"><a href="#1-2-1-人脸部特征定位" class="headerlink" title="1.2.1 人脸部特征定位"></a>1.2.1 人脸部特征定位</h4><p>假设你现在要对人的脸部各个特征点进行定位，那么你可以通过设定特征点的个数，假设设定脸部有$64$个特征点。选定特征点的个数之后，生成包含这些特征点的标签训练集(人为辛苦标注的)，然后利用神经网络输出脸部关键特征点的位置。</p><p>具体的做法是：准备一个卷积神经网络和一些特征集，将人脸图片输入卷积神经网络，然后输出对于的标签：</p><script type="math/tex; mode=display">y =  \begin{bmatrix} p_c \\ l_{x_1}\\ l_{y_1}\\ ...\\l_{64x}\\l_{64y} \\\end{bmatrix}</script><p>因此，对于这个例子来说$y$有$129$个输出单元，因此实现对图片的人脸进行检测和定位(现实中的例子：AR中在人的头上显示皇冠的效果)。</p><h4 id="1-2-2-人体姿态检测"><a href="#1-2-2-人体姿态检测" class="headerlink" title="1.2.2 人体姿态检测"></a>1.2.2 人体姿态检测</h4><p>通过神经网络去标注人物姿态的关键特征点，就相当于输出了人物的姿态动作。<br><img src= "/img/loading.gif" data-src="/2019/05/26/object-detection/1558878193152.png" alt="Alt text"></p><h3 id="1-3-目标检测-Object-Detection"><a href="#1-3-目标检测-Object-Detection" class="headerlink" title="1.3 目标检测(Object Detection)"></a>1.3 目标检测(Object Detection)</h3><blockquote><p>基于滑动窗口的目标检测算法.</p></blockquote><p>假设你现在需要构建一个汽车检测算法，步骤是：</p><blockquote><ol><li>首先创建一个标签训练集，也就是说$(x, y)$代表适当剪切的汽车图片样本。<br><img src= "/img/loading.gif" data-src="/2019/05/26/object-detection/1558878528054.png" alt="Alt text"></li><li>出于我们对这个训练集的期望，我们一开始可以使用适当剪切的图片：就是整张图片$x$几乎被汽车给占据，剪掉汽车以外的部分，使得汽车居于中心位置，并基本占据整张照片；</li><li>然后将这些适当剪切过的图像输入卷积神经网络中，然后让卷积神经网络输出标签$y = 0/1$，代表是否有车。</li></ol></blockquote><p>训练完这个卷积网络之后，就可以用它来实现滑动窗口目标检测了，具体步骤如下:</p><blockquote><ol><li>假设下图是一张测试图片，首先选定一个特定大小的窗口，比如图片下面的红色方框；</li><li>然后将这个红色小方块(<strong>所框定的图像</strong>)输入上面训练好了的物体检测的卷积网络，然后卷积网络开始进行预测，即判断红色方框中有没有汽车；</li><li>滑动窗口目标检测算法接下来会以一定步长稍向右边移动，得到第二个要处理的图像，然后输入卷积神经网络得到预测的标签；</li><li>然后继续<strong>以固定的步幅</strong>稍向右移，把框定后的图像输入卷积网络，然后继续按照上面进行处理，依次重复，直到这个窗口滑过图像的每一个角落，对每个位置按照$0/1$进行分类。</li><li>以上就是所谓的图像滑动窗口操作(<strong>sliding window through the image</strong>)。</li><li>接下来选择一个更大的窗口，截取更大的区域，输入给卷积网络处理，然后按照上面的重复，然后再一次选择更大一点的窗口，继续重复… …<br><img src= "/img/loading.gif" data-src="/2019/05/26/object-detection/1558879577145.png" alt="Alt text"></li></ol></blockquote><p>如果按照上面的思路，不管汽车在图像的哪个位置，总有一个窗口可以检测到它。不过<strong>滑动窗口目标检测算法</strong>有一个很明显的缺点就是<strong>计算成本</strong>，因为你在图像上剪出了很多的小块，而卷积要一个一个地处理；而如果你选用的窗口比较大，显然可以减少输入卷积网络的窗口数，但是粗粒度可能会影响到性能，可能会无法准确定位图片中的对象。<br><img src= "/img/loading.gif" data-src="/2019/05/26/object-detection/1558879928003.png" alt="Alt text"></p><h3 id="1-4-卷积的滑动窗口实现"><a href="#1-4-卷积的滑动窗口实现" class="headerlink" title="1.4 卷积的滑动窗口实现"></a>1.4 卷积的滑动窗口实现</h3><p>为了构建滑动窗口的卷积应用，首先需要知道如何把神经网络的全连接层转化为卷积层：假设对象检测算法输入一个$14 \times 14 \times 3$的图像(这里的尺寸大小应该是指的上一节中红色框定的图像大小)，这里设定滤波器大小为$5 \times 5$，数量为$16$个。</p><p>图像在滤波器处理过后变成$10 \times 10 \times 16$，然后继续如下：<br><img src= "/img/loading.gif" data-src="/2019/05/26/object-detection/1558881465218.png" alt="Alt text"><br>其中<strong>softmax</strong>层为$4$个类别的输出: <strong>行人、汽车、摩托车和其他</strong>。</p><p>下面将展示如何将全连接层转化为卷积层：前面的卷积层一样，最后一层卷积完毕之后不是直接连接全连接层，而是通过$5 \times 5 \times 16$，个数为$400$个的滤波器将其转化为了$1 \times 1 \times 400$的卷积块，因此我们不再将其看做是一个含有$400$个节点的集合，而是一个$1 \times 1 \times 400$的输出层，从数学的角度来看，它和全连接层是一样的。然后在添加另一个卷积层，滤波器为$1 \times 1 \times 400$，个数为$400$个。最后在经由$1 \times 1$的滤波器处理，得到一个$softmax$激活值，大小为$1 \times 1 \times 4$。<br><img src= "/img/loading.gif" data-src="/2019/05/26/object-detection/1558882030068.png" alt="Alt text"></p><p>接着我们再看看如果通过卷积实现滑动窗口对象检测算法：假设测试集图像为$16 \times 16 \times 3$(加上黄色条块的图像)，首先将测试图片集中蓝色区域输入卷积网络(也就是大小为$14 \times 14 \times 3$)生成$0/1$分类，接着滑动两个像素，将图中绿色框定的图像输入到卷积网络，得到另一个标签$0/1$，接着继续讲橘色框定的区域输入给卷积网络，得到另外的标签，最后将右下方紫色区域进行最后一次卷积操作，因此我们在这个$16 \times 16 \times 3$的图像上滑动窗口，如果运行$4$次，得到$4$个标签的话，会发现这$4$次卷积操作中本身很多的计算都是重复的。</p><p>但是使用滑动窗口的卷积应用则不同，它会使得上面$4$次的包含大量重复计算的卷积操作，在滑动窗口的卷积应用中把大量重复的计算进行共享：</p><blockquote><ol><li>通过$5 \times 5 \times 3$大小的滤波器核(卷积网络运行同样的参数)，得到$12 \times 12 \times 16$的输出层，然后跟$14 \times 14 \times 3$卷积过程一样的参数进行最大池化，最后得到$2 \times 2 \times 4$的输出层，最终在输出层这$4$个子方块中，左上角蓝色方块是最开始输入的测试图像$16 \times 16 \times 3$左上部分$14 \times 14$的输出；右上角的黄色块对应测试图片$16 \times 16 \times 3$右上部分$14 \times 14$的输出；左下角的黄色块对应测试图片$16 \times 16 \times 3$左下角部分$14 \times 14$的输出；右下角的黄色块对应测试图片$16 \times 16 \times 3$右下部分$14 \times 14$的输出；<strong>因此滑动窗口的卷积应用中，我们不需要把输入图片根据我们设定的固定大小的框把输入的测试图片分割成四个子集，分别4次执行卷积得到4个结果，而是直接一次卷积得到4个结果(因为4次分别卷积会有很多重复的计算，而滑动窗口的卷积应用一次就会将很多公有区域的计算结果进行共享，因此根据设定的参数可以准确的得到4个小块，对应4个类别)</strong>。</li><li>以另一个更大的预测图片为例($28 \times 28 \times 3$)，应用滑动窗口的卷积操作，以同样的方式进行卷积过程，最后得到$8 \times 8 \times 4$，其中相当于原始的不停的滑动窗口操作以步幅为<strong>2</strong>，不断滑动的结果，这里只需要<strong>1</strong>次，但是原始的话要得到<strong>8</strong>个结果需要<strong>8</strong>次卷积才能实现，这样就会导致超多的重复计算。<br><img src= "/img/loading.gif" data-src="/2019/05/26/object-detection/1558885048931.png" alt="Alt text"></li><li>因此相比较于依靠连续滑动的卷积操作来识别图片中的车，滑动窗口的卷积应用根据定好的窗口大小，一次直接对整张图片进行卷积，一次得到所有的预测值，避免了超多的重复运算(只不过缺点是边界框的位置可能不够准确，下一节解决)。<strong>而滑动窗口的卷积能够有这样的效果是因为，由于一次能够得到所有预测值，而所有预测值是堆叠成块的，这是全连接不能够做到的，这也就是上面为什么使用卷积来替代全连接才能达到的效果。</strong><br><img src= "/img/loading.gif" data-src="/2019/05/26/object-detection/1558885256455.png" alt="Alt text"></li></ol></blockquote>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 目标检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>YOLO_v3代码解析以及相关注意事项</title>
      <link href="/2019/05/25/YOLO/"/>
      <url>/2019/05/25/YOLO/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>对于目标检测算法YOLO在使用过程中遇到的问题以及知识点进行记录.</strong><br><a id="more"></a></p></blockquote><h2 id="1-项目介绍"><a href="#1-项目介绍" class="headerlink" title="1. 项目介绍"></a>1. 项目介绍</h2><p>&#160; &#160; &#160; &#160;本次YOLO_v3的项目来源于<a href="https://www.jiqizhixin.com/%5B%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83%5D" target="_blank" rel="noopener">机器之心</a>翻译的项目—-<a href="https://www.jiqizhixin.com/articles/2018-04-23-3" target="_blank" rel="noopener">从零开始PyTorch项目：YOLO v3目标检测实现</a>以及<a href="https://www.jiqizhixin.com/articles/042602" target="_blank" rel="noopener">从零开始 PyTorch 项目：YOLO v3 目标检测实现（下）</a>两部分组成，原版的博客在此<a href="https://blog.paperspace.com/tag/series-yolo/" target="_blank" rel="noopener">Series: YOLO object detector in PyTorch</a>，原始博客的GitHub地址为：<a href="https://github.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch" target="_blank" rel="noopener">ayooshkathuria/pytorch-yolo-v3</a>，最后附上论文的地址：<a href="https://pjreddie.com/media/files/papers/YOLOv3.pdf" target="_blank" rel="noopener">YOLOv3: An Incremental Improvement</a>。</p><h2 id="2-项目需求及相关文件解释"><a href="#2-项目需求及相关文件解释" class="headerlink" title="2. 项目需求及相关文件解释"></a>2. 项目需求及相关文件解释</h2><p>&#160; &#160; &#160; &#160;YOLO_v3官方原始的代码是由C语言所写，真是佩服作者手撸代码能力啊，但是由于源码并没有相关的任何注释，阅读起来特别费事，所以参考了网上关于YOLO_v3迁移到$Tensorflow$和$Pytorch$的代码进行阅读，以便对代码有更深的认识和理解。</p><p>关于此YOLO_v3的$Pytorch$的代码，其$Pytorch$作者的<a href="https://github.com/ayooshkathuria/pytorch-yolo-v3" target="_blank" rel="noopener">GitHub</a>提到相应的需求如下：</p><ul><li>Python3.5</li><li>OpenCV</li><li>Pytorch 0.4(<strong>其中作者提了一句：$Using$ $PyTorch$ $0.3$ $will$ $break$ $the$ $detector.$</strong>)</li></ul><p>&#160; &#160; &#160; &#160;在准备好相应的东西之后将相应的项目$Clone$ $or$ $downoad$下来，除此之外你首先需要下载$weights$ $file$(权重文件)，地址如下：<a href="https://pjreddie.com/media/files/yolov3.weights" target="_blank" rel="noopener"> a weightsfile only for COCO</a>，大小有237M，下载下来的权重文件只需放在下载好的$project$根目录下即可，权重文件名为：<strong>yolov3.weights</strong></p><p>&#160; &#160; &#160; &#160;一切准备就绪就可以进行图片检测了，如果想要检测图片，可以在$Pycharm$的底部栏找到$Terminal$，也就是$CMD$，将地址$cd$到你下载的项目所在的地址，如：<strong>D:\软件安装\pycharm\PyCharm Community Edition 2017.3.3\workplace\yolo_tensorflow-master&gt;</strong>，然后在$Terminal$中输入：<strong>python detect.py —images imgs —det det</strong>命令即可，其中 <strong>—images</strong>代表定义图片存储或加载的文件夹，而<strong>—det</strong>代表检测完图片之后将检测图片保存起来的文件夹，当然，如果需要查看其它标记含义(例如：<strong>—bs</strong>)，可以通过在命令行输入：<strong>python detect.py -h</strong> 或者直接代开$project$中<strong>detect.py</strong>文件查看<strong>arg_parse()</strong>函数下定义的参量进行查看。甚至直接运行<strong>detect.py</strong>文件也可以进行图片检测。</p><p>&#160; &#160; &#160; &#160;如果你想检测视频，可以运行<strong>video.py</strong>进行检测，要在视频或网络摄像头上运行这个检测器，代码基本可以保持不变，只是我们不会在 batch 上迭代，而是在视频的帧上迭代。</p><p>&#160; &#160; &#160; &#160;在视频上运行该检测器的代码可以在我们的 <strong>GitHub</strong> 中的 <strong>video.py</strong> 文件中找到。这个代码非常类似 <strong>detect.py</strong> 的代码，只有几处不太一样。这里需要注意的是，如果想要对视频进行检测需要将视频文件放入$projiect$的根目录中，而且在<strong>video.py</strong>文件中对视频定义的默认参数为：<strong>default = “video.avi”</strong>，所以，你需要更改你视频文件的名称或者更改参数的默认设定。</p><h2 id="3-源码详细解析"><a href="#3-源码详细解析" class="headerlink" title="3. 源码详细解析"></a>3. 源码详细解析</h2><p>&#160; &#160; &#160; &#160;<strong>PASS</strong></p><h2 id="4-源码中的问题"><a href="#4-源码中的问题" class="headerlink" title="4. 源码中的问题"></a>4. 源码中的问题</h2><blockquote><p>&#160; &#160; &#160; &#160;在项目下载下来之后发现了源码有一些比较坑的地方，以至于部分代码无法运行，这里举出暂时所遇到的坑以及解决办法。</p></blockquote><h3 id="4-1-视频检测中遇到的问题："><a href="#4-1-视频检测中遇到的问题：" class="headerlink" title="4.1 视频检测中遇到的问题："></a>4.1 视频检测中遇到的问题：</h3><p>&#160; &#160; &#160; &#160;此处非项目：<strong>YOLO_v3_tutorial_from_scratch-master</strong>中视频检测遇到的问题，而是项目<strong>yolo_tensorflow-master</strong>中视频检测遇到的问题，只是在此将所有和YOLO代码相关的问题都列举出来，在项目<strong>yolo_tensorflow-master</strong>的<strong>test.py</strong>中，第201-203行代码为摄像头检测的代码：<strong>detect from camera</strong><br>代码中：<strong>cap = cv2.VideoCapture(0)</strong>，原始的<a href="https://github.com/hizhangp/yolo_tensorflow" target="_blank" rel="noopener">GitHub：hizhangp/yolo_tensorflow</a>代码中为：<strong>cap = cv2.VideoCapture(-1)</strong>，运行时造成摄像头开启后显示的图像为满屏幕的雪花噪点，无法检测到任何东西，需要将括号中的参数<strong>-1</strong>改为<strong>0</strong>方可正常开始摄像头进行检测。此项目<strong>yolo_tensorflow-master</strong>的解读参照知乎相关专栏：<a href="https://zhuanlan.zhihu.com/p/25053311" target="_blank" rel="noopener">YOLO源码解析 作者：狗头山人七 </a></p><h3 id="4-2-图片检测中遇到的问题："><a href="#4-2-图片检测中遇到的问题：" class="headerlink" title="4.2 图片检测中遇到的问题："></a>4.2 图片检测中遇到的问题：</h3><blockquote><p>&#160; &#160; &#160; &#160;此处遇到的问题非常的多和杂，将代码修改正确以正常运行耗费了我很多精力，在此一一列举，以备以后遇到类似情况。<br>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/YOLO/1558791232225.png" alt="Alt text"></p></blockquote><h4 id="4-2-1-绝对路径与相对路径的问题"><a href="#4-2-1-绝对路径与相对路径的问题" class="headerlink" title="4.2.1 绝对路径与相对路径的问题"></a>4.2.1 绝对路径与相对路径的问题</h4><p>&#160; &#160; &#160; &#160;刚开始运行图片检测代码(项目：<strong>YOLO_v3_tutorial_from_scratch-master</strong>)的时候直接报错，报的错误为：</p><blockquote><p>&#160; &#160; &#160; &#160;<strong>AttributeError: ‘NoneType’ object has no attribute ‘shape’</strong><br>&#160; &#160; &#160; &#160;<strong>！！完全不知道错误的那种错！！</strong><br>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/YOLO/1558791246507.png" alt="Alt text"></p></blockquote><p>&#160; &#160; &#160; &#160;后来一堆百度，Google查证之后发现是报了一个空的对象没有<strong>shape</strong>这个属性的错误，可能是因为路径设置不对，所以返回的类型是None。后来通过bug排除发现是代码第<strong>126</strong>行：<strong>imlist = [osp.join(osp.realpath(‘.’), images, img) for img in os.listdir(images)]</strong>，这一行代码主要是用于生成图片所在的绝对地址：</p><blockquote><p>&#160; &#160; &#160; &#160;<strong>D:\软件安装\pycharm\PyCharm Community Edition 2017.3.3\workplace\pytorch-yolo-v3-master\imgs\dog.jpg</strong><br>&#160; &#160; &#160; &#160;<strong>D:\软件安装\pycharm\PyCharm Community Edition 2017.3.3\workplace\pytorch-yolo-v3-master\imgs\eagle.jpg</strong><br>&#160; &#160; &#160; &#160;<strong>D:\软件安装\pycharm\PyCharm Community Edition 2017.3.3\workplace\pytorch-yolo-v3-master\imgs\giraffe.jpg</strong><br>&#160; &#160; &#160; &#160; <strong>D:\软件安装\pycharm\PyCharm Community Edition 2017.3.3\workplace\pytorch-yolo-v3-master\imgs\herd_of_horses.jpg</strong><br>&#160; &#160; &#160; &#160; <strong>D:\软件安装\pycharm\PyCharm Community Edition 2017.3.3\workplace\pytorch-yolo-v3-master\imgs\img1.jpg</strong><br>&#160; &#160; &#160; &#160; <strong>D:\软件安装\pycharm\PyCharm Community Edition 2017.3.3\workplace\pytorch-yolo-v3-master\imgs\img2.jpg</strong><br>&#160; &#160; &#160; &#160;<strong>D:\软件安装\pycharm\PyCharm Community Edition 2017.3.3\workplace\pytorch-yolo-v3-master\imgs\img3.jpg</strong><br>&#160; &#160; &#160; &#160; <strong>D:\软件安装\pycharm\PyCharm Community Edition 2017.3.3\workplace\pytorch-yolo-v3-master\imgs\img4.jpg</strong><br>&#160; &#160; &#160; &#160;<strong>D:\软件安装\pycharm\PyCharm Community Edition 2017.3.3\workplace\pytorch-yolo-v3-master\imgs\lisa.jpg</strong></p><p>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/YOLO/1558791339113.png" alt="Alt text"></p></blockquote><p>&#160; &#160; &#160; &#160;这里我意识到可能此处的错误并非作者源代码的错误，而是作者在用这一句<strong>osp.join(osp.realpath(‘.’)</strong>的时候获取的是绝对路径，而我的绝对路径包含了中文！！！！<br>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/YOLO/1558791360085.png" alt="Alt text"></p><p>&#160; &#160; &#160; &#160;所以为了解决这个问题，我需要将绝对路径修改为相对路径，以避免出现中文这个脑壳疼的问题（话说好多与<strong>bug</strong>有关的问题是出现路径有中文上！），修改方法就是上面的代码修改为：<strong>osp.join(osp.relpath(‘.’)</strong>，其中<strong>rel</strong>指的就是<strong>relative</strong>。</p><hr><h4 id="4-2-2-斜杠’-‘与反斜杠’-’的问题"><a href="#4-2-2-斜杠’-‘与反斜杠’-’的问题" class="headerlink" title="4.2.2 斜杠’/‘与反斜杠’\\’的问题"></a>4.2.2 斜杠’/‘与反斜杠’\\’的问题</h4><p>&#160; &#160; &#160; &#160;在上面的问题解决以后运行代码发现代码运行正常，但是最后保存检测图片的文件夹<strong>—det</strong>并没有任何图片存放其中，后来定位到存放图片的代码：</p><pre><code>det_names = pd.Series(imlist).apply(lambda x: &quot;{}/det_{}&quot;.format(args.det,x.split(&quot;/&quot;)[-1]))list(map(cv2.imwrite, det_names, orig_ims))</code></pre><p>&#160; &#160; &#160; &#160;每张图像都以<strong>「det_」</strong>加上图像名称的方式保存。我们创建了一个地址列表，这是我们保存我们的检测结果图像的位置。最后，将带有检测结果的图像写入到 <strong>det_names</strong> 中的地址。</p><p>&#160; &#160; &#160; &#160;其中<strong>det_name</strong>打印出来结果如下：</p><blockquote><p>&#160; &#160; &#160;<strong>0                det/det_.\imgs\dog.jpg</strong><br>&#160; &#160; &#160;<strong>1              det/det_.\imgs\eagle.jpg</strong><br>&#160; &#160; &#160;<strong>2            det/det_.\imgs\giraffe.jpg</strong><br>&#160; &#160; &#160;<strong>3     det/det_.\imgs\herd_of_horses.jpg</strong><br>&#160; &#160; &#160;<strong>4               det/det_.\imgs\img1.jpg</strong><br>&#160; &#160; &#160;<strong>5               det/det_.\imgs\img2.jpg</strong><br>&#160; &#160; &#160;<strong>6               det/det_.\imgs\img3.jpg</strong><br>&#160; &#160; &#160;<strong>7               det/det_.\imgs\img4.jpg</strong><br>&#160; &#160; &#160;<strong>8               det/det_.\imgs\lisa.jpg</strong><br>&#160; &#160; &#160;<strong>9              det/det_.\imgs\messi.jpg</strong><br>&#160; &#160; &#160;<strong>10            det/det_.\imgs\person.jpg</strong><br>&#160; &#160; &#160;<strong>11            det/det_.\imgs\scream.jpg</strong><br>&#160; &#160; &#160;<strong>12             det/det_.\imgs\vagaa.jpg</strong></p></blockquote><p>&#160; &#160; &#160; &#160;而<strong>imlist</strong>打印出来的结果为：</p><blockquote><p>&#160; &#160; &#160; &#160; <strong>[‘.\\imgs\\dog.jpg’,’.\\imgs\\eagle.jpg’, ‘.\\imgs\\giraffe.jpg’,’.\\imgs\\herd_of_horses.jpg’, ‘.\\imgs\\img1.jpg’,’.\\imgs\\img2.jpg’, ‘.\\imgs\\img3.jpg’]</strong></p></blockquote><p>&#160; &#160; &#160; &#160;下一句代码：<strong>list(map(cv2.imwrite, det_names, orig_ims))</strong>中：</p><blockquote><p>&#160; &#160; &#160; &#160;1.<strong>cv2.imwrite()</strong>函数：保存图片的函数，共两个参数，第一个为保存文件名，第二个为读入图片。<br>&#160; &#160; &#160; &#160;2.<strong>orig_ims</strong>：为list所包裹这的array矩阵，类型为无符号8位<strong>dtype=uint8</strong>，所以为图片的编码矩阵。<br>&#160; &#160; &#160; &#160;3.<strong>map()</strong>函数：会根据提供的函数对指定序列做映射。第一个参数 function 以参数序列中的每一个元素调用 function 函数，返回包含每次 function 函数返回值的新列表。语法为：<strong>map(function, iterable, …)</strong>，其中function — 函数，有两个参数；iterable — 一个或多个序列，例如：<strong>map(square, [1,2,3,4,5])</strong>，打印：<strong>[1, 4, 9, 16, 25]</strong>，其中<strong>square(x)</strong>为一个函数，<strong>return x$^2$</strong>。</p></blockquote><p>&#160; &#160; &#160; &#160;所以从上可以看出<strong>map</strong>函数将<strong>cv2.imwrite, det_names, orig_ims</strong>之间建立映射，其中<strong>det_names, orig_ims</strong>作为<strong>cv2.imwrite()</strong>的参数，其中一个作为保存文件名，一个作为读入的图片。</p><p>&#160; &#160; &#160; &#160;运行此代码，显示：</p><blockquote><p>&#160; &#160; &#160; &#160;[False, False, False, False, False, False, False, False, False, False, False, False, False]</p></blockquote><p>&#160; &#160; &#160; &#160;说明映射失败，图片存储不成功。而由<strong>det_name</strong>所打印的显示表明失败是由于文件名中存在反斜杠’\’，反斜杠在<strong>python</strong>中有实际转义含义的，所以需要将反斜杠换为斜杠，不然运行的时候代码会将反斜杠一起运行。</p><p>&#160; &#160; &#160; &#160;修改方法如下：</p><pre><code>for i in range(len(imlist)):        imlist[i] = imlist[i].replace(&#39;\\&#39;, &#39;/&#39;)</code></pre><p>&#160; &#160; &#160; &#160;此处还需要注意的就是<strong>imlist[i].replace(‘\\’, ‘/‘)</strong>会生成一个列表存放修改后的值，而不是在原本的列表<strong>imlist[]</strong>上进行修改。</p><p>&#160; &#160; &#160; &#160;修改后的<strong>det_name</strong>为：</p><blockquote><p>&#160; &#160; &#160; &#160;<strong>0                det/det_dog.jpg</strong><br>&#160; &#160; &#160; &#160;<strong>1              det/det_eagle.jpg</strong><br>&#160; &#160; &#160; &#160;<strong>2            det/det_giraffe.jpg</strong><br>&#160; &#160; &#160; &#160;<strong>3     det/det_herd_of_horses.jpg</strong><br>&#160; &#160; &#160; &#160;<strong>4               det/det_img1.jpg</strong><br>&#160; &#160; &#160; &#160;<strong>5               det/det_img2.jpg</strong><br>&#160; &#160; &#160; &#160;<strong>6               det/det_img3.jpg</strong><br>&#160; &#160; &#160; &#160;<strong>7               det/det_img4.jpg</strong><br>&#160; &#160; &#160; &#160;<strong>8               det/det_lisa.jpg</strong><br>&#160; &#160; &#160; &#160;<strong>9              det/det_messi.jpg</strong><br>&#160; &#160; &#160; &#160;<strong>10            det/det_person.jpg</strong><br>&#160; &#160; &#160; &#160;<strong>11            det/det_scream.jpg</strong><br>&#160; &#160; &#160; &#160;<strong>12             det/det_vagaa.jpg</strong></p></blockquote><p>&#160; &#160; &#160; &#160;此时，反斜杠已经改为了斜杠，代码运行正常，且<strong>det</strong>文件夹也正常存放了检测后的图片，如下：<br>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/YOLO/1558791410182.png" alt="Alt text"></p><h2 id="5-关于YOLO-v3作者"><a href="#5-关于YOLO-v3作者" class="headerlink" title="5. 关于YOLO_v3作者"></a>5. 关于YOLO_v3作者</h2><p>&#160; &#160; &#160; &#160;在知乎中有一个问题是关于<a href="https://www.zhihu.com/question/269909535?rf=269932466" target="_blank" rel="noopener">如何评价最新的YOLOv3？</a>，非常有意思，列举如下一些有趣的点：</p><p>&#160; &#160; &#160; &#160;1. 首先，YOLO_v3的论文根本就不算论文，更多的算是一片技术报告，读起来相当的欢乐。作者首先就诚实的表明自己去年没做什么研究，而是主要花在完Twitter上和玩了下GAN。</p><p>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/YOLO/1558791419395.png" alt="Alt text"></p><p>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/YOLO/1558791432929.png" alt="Alt text"></p><p>&#160; &#160; &#160; &#160;2. 其次，yolo的作者编码能力真的强，darknet几乎不用啥依赖库，全部手撸，编译起来也是快到没朋友。而且，作业可能是个<strong>小马宝莉</strong>的迷吧，哈哈哈，蛮有意思，感觉像个小萌妹。看看他的resume、个人主页、git的commit message感受一下萌萌哒。<br>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/YOLO/1558791517510.png" alt="Alt text"></p><p>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/YOLO/1558791523803.png" alt="Alt text"></p><p>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/YOLO/1558791547788.png" alt="Alt text"></p><p>&#160; &#160; &#160; &#160;而他本人长这样：<br>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/YOLO/1558791553065.png" alt="Alt text"></p><p>&#160; &#160; &#160; &#160;3. 直接diss一众算法，例如他论文中出现的：<br>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/YOLO/1558791558772.png" alt="Alt text"></p><p>&#160; &#160; &#160; &#160;这张图把自己放在第二象限，赤裸裸的表达你们这些都是辣鸡。。。。<br>&#160; &#160; &#160; &#160;这图应该作者从其他论文裁剪过来，再强行画上的;<br>&#160; &#160; &#160; &#160;实力嘲讽啊，取了Retina里面的图，然后diss一波。</p><p>&#160; &#160; &#160;4. 论文结尾亮点满满，挺佩服能把自己论文写的这么随意的，羡慕大佬：<br>&#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/YOLO/1558791566119.png" alt="Alt text"></p><p>&#160; &#160; &#160;效果好到论文可以随意写，反正我效果摆在这里，论文写的再随意，你们还是要引用的。</p><p>&#160; &#160; &#160;5. 而且有细心网友发现，模型一作在arXiv上发布研究论文时，脑回路清奇地将自己这篇论文自引自用了一下。<br>&#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/YOLO/1558791580144.png" alt="Alt text"></p><p>&#160; &#160; &#160;而在小哥自引自用后没多久，arXiv官方账号宣布服务器由于不明原因挂掉了……<br>&#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/YOLO/1558791585566.png" alt="Alt text"></p><h2 id="6-补完计划"><a href="#6-补完计划" class="headerlink" title="6. 补完计划"></a>6. 补完计划</h2><p>&#160; &#160; &#160;文章的第三部分代码详细解析，有空了会继续补完，待续。。。</p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> YOLO </tag>
            
            <tag> 目标检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kaggle竞赛相关知识</title>
      <link href="/2019/05/25/Kaggle-2/"/>
      <url>/2019/05/25/Kaggle-2/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>Kaggle相关的知识点.</strong><br><a id="more"></a></p></blockquote><h2 id="1-分类算法基础篇"><a href="#1-分类算法基础篇" class="headerlink" title="1. 分类算法基础篇"></a>1. 分类算法基础篇</h2><h3 id="1-1-相应内容"><a href="#1-1-相应内容" class="headerlink" title="1.1 相应内容"></a>1.1 相应内容</h3><blockquote><p>&#160; &#160; &#160; &#160;1. 线性分类器基本原理与案例实战<br>&#160; &#160; &#160; &#160;2. 支持向量机分类器原理与案例实战<br>&#160; &#160; &#160; &#160;3. 朴素贝叶斯分类器原理与案例实战<br>&#160; &#160; &#160; &#160;4. K近邻分类器原理与案例实战<br>&#160; &#160; &#160; &#160;5. 决策树分类器原理与案例实战<br>&#160; &#160; &#160; &#160;6. 集成模型分类器原理与案例实战</p></blockquote><h3 id="1-2-线性分类器（Logistic-Regression）"><a href="#1-2-线性分类器（Logistic-Regression）" class="headerlink" title="1.2 线性分类器（Logistic Regression）"></a>1.2 线性分类器（<strong>Logistic Regression</strong>）</h3><h4 id="1-2-1-监督学习基本架构和流程"><a href="#1-2-1-监督学习基本架构和流程" class="headerlink" title="1.2.1 监督学习基本架构和流程"></a>1.2.1 监督学习基本架构和流程</h4><p>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/Kaggle-2/1558792273135.png" alt="Alt text"></p><p>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/Kaggle-2/1558792278297.png" alt="Alt text"></p><h4 id="1-2-2-监督学习之分类问题"><a href="#1-2-2-监督学习之分类问题" class="headerlink" title="1.2.2 监督学习之分类问题"></a>1.2.2 监督学习之分类问题</h4><p>&#160; &#160; &#160; &#160;监督学习的重点在于根据已有的经验知识对未知样本的目标、标记进行预测。根据目标预测变量的不同，监督学习分类可以分为两类：分类任务和回归任务。<br>&#160; &#160; &#160; &#160;其中分类问题可以分为：<strong>二分类问题</strong>和<strong>多分类问题</strong>，根据预测标签的个数还可以分为：<strong>单标签分类问题</strong>和<strong>多标签分类问题(实际问题中遇到的比较多)</strong>。所以上下两种是可以组合的，比方说：<strong>两类多标签分类问题</strong>。</p><h4 id="1-2-3-分类器模型之线性分类器"><a href="#1-2-3-分类器模型之线性分类器" class="headerlink" title="1.2.3 分类器模型之线性分类器"></a>1.2.3 分类器模型之线性分类器</h4><p>&#160; &#160; &#160; &#160;<strong>模型介绍</strong>：线性分类器(<strong>Linear classifiers</strong>)，顾名思义，是一种假设特征向量与分类结果存在线性关系的模型。这个模型通过累加计算每个维度的特征与对应的权重的乘积来进行分类决策。<br>&#160; &#160; &#160; &#160;比如：$n$维特征向量：$x$ = [$x_1$,$x_2$,$…….$,$x_n$]${^T}$<br>&#160; &#160; &#160; &#160;相应：$n$维权重向量：$w$ = [$w_1$,$w_2$,$…….$,$w_n$]${^T}$<br>&#160; &#160; &#160; &#160;线性模型：$f(w,x,b)$ = $w{^T}x$ + $b$，其中$f∈R$<br>&#160; &#160; &#160; &#160;在最简单的二分类问题中，我们希望$f∈${$0,1$}，因此我们需要一个函数把$f$从实数域映射到{$0,1$}，因此引入$Logistic$ $Function$(逻辑回归函数):<br>&#160; &#160; &#160; &#160;$g(z)=\frac{1}{1+e^{-z}}$，$z∈R$，$g(z)∈(0,1)$<br>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/Kaggle-2/1558792314026.png" alt="Alt text"></p><p>&#160; &#160; &#160; &#160;将变量$z$替换为$f(w,x,b)$，就可以得到一个典型的<strong>线性分类器</strong>:逻辑回归模型($Logistic$ $Regression$):<br>&#160; &#160; &#160; &#160;$h_{w,b}(x) = g(f(w,b,x)) = \frac{1}{1+e^{-(w^{T}x+b)}}$<br>&#160; &#160; &#160; &#160;如果$h_{w,b} &lt; 0.5$，就把$x$分为一类；<br>&#160; &#160; &#160; &#160;如果$h_{w,b} \geq 0.5$，就把$x$分为另一类。<br>&#160; &#160; &#160; &#160;如何在给定的样本集上估计模型参数呢？<br>&#160; &#160; &#160; &#160;$m$个样本特征向量构成的训练集：$X =$ {$x^1,x^2,….,x^m$}<br>&#160; &#160; &#160; &#160;$m$个样本特征向量的真实类标签：$Y =$ {$y^1,y^2,….,y^m$}<br>&#160; &#160; &#160; &#160;我们希望逻辑回归模型能够在上述数据集上取得最大似然估计($Maximum$ $Likelihood$)：<br>&#160; &#160; &#160; &#160;$\mathop{\arg \max}_{w,b} L(w,b) = \mathop{\arg \max}_{w,b} \prod_{i=1}^m (h_{w,b}(x^i))^{y^{i}}·(1-h_{w,b}(x^i))^{1-y^i}$<br>&#160; &#160; &#160; &#160;因为这里要求解一个最大化的优化问题，而且目标函数是解析的，所以我们使用随机梯度上升算法(<strong>Stochastic Gradient Ascend</strong>)来进行目标函数的优化进而寻找最优的模型参数。                </p><h4 id="1-2-4-分类器性能评估"><a href="#1-2-4-分类器性能评估" class="headerlink" title="1.2.4 分类器性能评估"></a>1.2.4 分类器性能评估</h4><p>&#160; &#160; &#160; &#160;混淆矩阵，下图所示：<br>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/Kaggle-2/1558792324266.png" alt="Alt text"></p><p>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/Kaggle-2/1558792329492.png" alt="Alt text"></p><p>&#160; &#160; &#160; &#160;<strong>精确率(Precision)</strong>：<br>&#160; &#160; &#160; &#160;$Precision = \frac{tp}{tp + fp}$，其中$tp = True$ $positive$，$fp = True$ $negative$<br>&#160; &#160; &#160; &#160;<strong>召回率(Recall)</strong>：<br>&#160; &#160; &#160; &#160;$Precision = \frac{tp}{tp + fn}$，其中$tp = True$ $positive$，$fp = False$ $negative$<br>&#160; &#160; &#160; &#160;相关$wiki$链接：<a href="https://en.wikipedia.org/wiki/Confusion_matrix" target="_blank" rel="noopener">Confusion matrix</a><br>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/Kaggle-2/1558792337314.png" alt="Alt text"></p><p>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/Kaggle-2/1558792345311.png" alt="Alt text"></p><p>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/Kaggle-2/1558792357487.png" alt="Alt text"></p><p>&#160; &#160; &#160; &#160;关于$Precision$和$Recall$的进一步解释：<br>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/Kaggle-2/1558792414989.png" alt="Alt text"></p><p>&#160; &#160; &#160; &#160;$Precision$：被分类器挑选($selected$)出来的正样本究竟有多少是真正的正样本！说白了，准确率就是<strong>找的对</strong>！<br>&#160; &#160; &#160; &#160;$Recall$：在所有的真正的正样本中分类器挑选了多少个，召回率就是<strong>找的全</strong>！<br>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/Kaggle-2/1558792421997.png" alt="Alt text"></p><p>&#160; &#160; &#160; &#160;参考书目及链接：<br>&#160; &#160; &#160; &#160;1. <a href="https://www.cnblogs.com/sddai/p/5696870.html" target="_blank" rel="noopener">博客园—赏月斋：准确率(Accuracy), 精确率(Precision), 召回率(Recall)和F1-Measure</a><br>&#160; &#160; &#160; &#160;2. 李航. 统计学习方法[M]. 北京:清华大学出版社,2012.<br>&#160; &#160; &#160; &#160;3. <a href="https://www.zhihu.com/question/19645541" target="_blank" rel="noopener">如何解释召回率与准确率？</a><br>&#160; &#160; &#160; &#160;4. <a href="https://blog.csdn.net/u010705209/article/details/53037481" target="_blank" rel="noopener">SK_Lavender的博客—机器学习模型评价指标 — 混淆矩阵</a><br>&#160; &#160; &#160; &#160;5. <a href="https://www.zybuluo.com/codeep/note/163962" target="_blank" rel="noopener">Markdown 公式指导手册</a><br>&#160; &#160; &#160; &#160;6. <a href="https://blog.csdn.net/zdk930519/article/details/54137476" target="_blank" rel="noopener">Markdown中数学公式整理</a><br>&#160; &#160; &#160; &#160;7. <a href="https://blog.argcv.com/articles/1036.c" target="_blank" rel="noopener">准确率(Accuracy), 精确率(Precision), 召回率(Recall)和F1-Measure</a></p><h4 id="1-2-5-线性分类器案例实战"><a href="#1-2-5-线性分类器案例实战" class="headerlink" title="1.2.5 线性分类器案例实战"></a>1.2.5 线性分类器案例实战</h4><h5 id="1-2-5-1-数据描述：良-恶性乳腺肿瘤预测"><a href="#1-2-5-1-数据描述：良-恶性乳腺肿瘤预测" class="headerlink" title="1.2.5.1 数据描述：良/恶性乳腺肿瘤预测"></a>1.2.5.1 数据描述：良/恶性乳腺肿瘤预测</h5><p>&#160; &#160; &#160; &#160;数据地址：<a href="https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/" target="_blank" rel="noopener">良/恶性肿瘤数据集</a><br>&#160; &#160; &#160; &#160;样本个数：699($as$ $of$ $15$ $July$ $1992$)<br>&#160; &#160; &#160; &#160;样本属性个数：10加上类别标签<br>&#160; &#160; &#160; &#160;特征属性描述：(类比标签已经被移到了最后一列上)</p><div class="table-container"><table><thead><tr><th style="text-align:left">#</th><th style="text-align:right">属性</th><th style="text-align:center">值域</th></tr></thead><tbody><tr><td style="text-align:left">1</td><td style="text-align:right">样本编号</td><td style="text-align:center">id number</td></tr><tr><td style="text-align:left">2</td><td style="text-align:right">Clump Thickness</td><td style="text-align:center">1-10</td></tr><tr><td style="text-align:left">3</td><td style="text-align:right">Uniformity of Cell Size</td><td style="text-align:center">1-10</td></tr><tr><td style="text-align:left">4</td><td style="text-align:right">Uniformity of Cell shape</td><td style="text-align:center">1-10</td></tr><tr><td style="text-align:left">5</td><td style="text-align:right">Marginal Adhesion</td><td style="text-align:center">1-10</td></tr><tr><td style="text-align:left">6</td><td style="text-align:right">Singal Epithelial Cell Size</td><td style="text-align:center">1-10</td></tr><tr><td style="text-align:left">7</td><td style="text-align:right">Bare Nuclei</td><td style="text-align:center">1-10</td></tr><tr><td style="text-align:left">8</td><td style="text-align:right">Bland Chromatin</td><td style="text-align:center">1-10</td></tr><tr><td style="text-align:left">9</td><td style="text-align:right">Normal Nucleoli</td><td style="text-align:center">1-10</td></tr><tr><td style="text-align:left">10</td><td style="text-align:right">Mitoses</td><td style="text-align:center">1-10</td></tr><tr><td style="text-align:left">11</td><td style="text-align:right">类别标签</td><td style="text-align:center">2代表良性，4代表恶性</td></tr></tbody></table></div><p>&#160; &#160; &#160; &#160;缺失属性值的样本个数：16，对应的缺失属性值标记为’?’。<br>&#160; &#160; &#160; &#160;类分布：<br>&#160; &#160; &#160; &#160;&#160; &#160; &#160; &#160;良性($Benign$)：458(65.5%)；<br>&#160; &#160; &#160; &#160;&#160; &#160; &#160; &#160;恶性($Malignant$)：241(34.5%)</p><h5 id="1-2-5-2-实战步骤"><a href="#1-2-5-2-实战步骤" class="headerlink" title="1.2.5.2 实战步骤"></a>1.2.5.2 实战步骤</h5><blockquote><p>&#160; &#160; &#160; &#160;1. 数据预处理(由于缺失值的存在)<br>&#160; &#160; &#160; &#160;2. 划分训练集和测试集<br>&#160; &#160; &#160; &#160;3. 训练学习模型并在测试集上预测<br>&#160; &#160; &#160; &#160;4. 对学习器模型进行评估<br>&#160; &#160; &#160; &#160;5. 实战总结</p></blockquote><h5 id="1-2-5-3-实战代码"><a href="#1-2-5-3-实战代码" class="headerlink" title="1.2.5.3 实战代码"></a>1.2.5.3 实战代码</h5><p>&#160; &#160; &#160; &#160;这一部分见Pycharm。</p><h3 id="1-3-支持向量机原理-support-vector-machine"><a href="#1-3-支持向量机原理-support-vector-machine" class="headerlink" title="1.3 支持向量机原理(support vector machine)"></a>1.3 支持向量机原理(support vector machine)</h3><h4 id="1-3-1-主要内容"><a href="#1-3-1-主要内容" class="headerlink" title="1.3.1 主要内容"></a>1.3.1 主要内容</h4><blockquote><p>&#160; &#160; &#160; &#160;1. 支持向量机的基本原理<br>&#160; &#160; &#160; &#160;2. 支持向量机实战：手写数字分类</p></blockquote><h4 id="1-3-2-基本原理"><a href="#1-3-2-基本原理" class="headerlink" title="1.3.2 基本原理"></a>1.3.2 基本原理</h4><blockquote><p>&#160; &#160; &#160; &#160;1. <strong>线性分类器的间隔(margin):</strong>到超平面最近的样本与此超平面之间的距离。<br>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/Kaggle-2/1558792440848.png" alt="Alt text"></p></blockquote><p>&#160; &#160; &#160; &#160;2. 具有最大间隔的线性分类器叫做<strong>最大间隔线性分类器</strong>。其中最简单的一种就是支持向量机(<strong>SVM</strong>)，成为<strong>线性支持向量机(LSVM)</strong><br>&#160; &#160; &#160; &#160;3. 支持向量就是那些距离超平面最近的点。</p><h4 id="1-3-3-为何需要寻找最大间隔"><a href="#1-3-3-为何需要寻找最大间隔" class="headerlink" title="1.3.3 为何需要寻找最大间隔"></a>1.3.3 为何需要寻找最大间隔</h4><p>&#160; &#160; &#160; &#160;1. 直观上感觉很好。<br>&#160; &#160; &#160; &#160;2. 学习得到的线性分类器其对未知样本的预测能力与分类器间隔如下关系：<br>&#160; &#160; &#160; &#160;$R{(w)} \leq R_{emp}(α) + \Phi(\frac{1}{margin})$<br>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/Kaggle-2/1558792449659.png" alt="Alt text"></p><p>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/Kaggle-2/1558792458927.png" alt="Alt text"></p><p>&#160; &#160; &#160; &#160;3. 利用二次优化求解：<br>&#160; &#160; &#160; &#160;$\mathop{Minimize} : {\frac{1}{2}w^Tw}$<br>&#160; &#160; &#160; &#160;$suject$ $to：y_k(w·x_k + b) \geq 1; k = 1,2,…..,n$<br>&#160; &#160; &#160; &#160;用拉格朗日乘数发转换为无约束二次优化问题。</p><h4 id="1-3-4-实战案例"><a href="#1-3-4-实战案例" class="headerlink" title="1.3.4 实战案例"></a>1.3.4 实战案例</h4><h5 id="1-3-4-1-案例数据集"><a href="#1-3-4-1-案例数据集" class="headerlink" title="1.3.4.1 案例数据集"></a>1.3.4.1 案例数据集</h5><p>&#160; &#160; &#160; &#160;1.案例的数据集为手写数字数据集:<strong>load_digits()</strong><br>&#160; &#160; &#160; &#160;2.其为多分类任务的数据集，其构成如下:<br>&#160; &#160; &#160; &#160;3. <strong>Data set Characteristics:</strong> </p><div class="table-container"><table><thead><tr><th style="text-align:left">Number of Instances:</th></tr></thead><tbody><tr><td style="text-align:left">5620</td></tr><tr><td style="text-align:left"><strong>Number of Attributes:</strong></td></tr><tr><td style="text-align:left"></td></tr><tr><td style="text-align:left">64</td></tr><tr><td style="text-align:left"><strong>Attribute information:</strong></td></tr><tr><td style="text-align:left"></td></tr><tr><td style="text-align:left">8x8 image of integer pixels in the range 0:16</td></tr><tr><td style="text-align:left"><strong>Miss Attribute Values:</strong></td></tr><tr><td style="text-align:left"></td></tr><tr><td style="text-align:left">None</td></tr></tbody></table></div><p>&#160; &#160; &#160; &#160;4. 其中<strong>64</strong>代表有64个特征分量，它是一个<strong>8x8</strong>的图像，每个像素点的范围是<strong>0-16</strong>的灰度图像，且无缺失值。<br>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/Kaggle-2/1558792468660.png" alt="Alt text"></p><h5 id="1-3-4-2-实战步骤"><a href="#1-3-4-2-实战步骤" class="headerlink" title="1.3.4.2 实战步骤"></a>1.3.4.2 实战步骤</h5><blockquote><p>&#160; &#160; &#160; &#160;1. 数据预处理<br>&#160; &#160; &#160; &#160;2. 划分训练集和测试集<br>&#160; &#160; &#160; &#160;3. 训练学习模型并在测试集上预测<br>&#160; &#160; &#160; &#160;4. 对学习器模型的性能进行评估<br>&#160; &#160; &#160; &#160;5. 实战总结</p></blockquote><h5 id="1-3-4-3-实战代码"><a href="#1-3-4-3-实战代码" class="headerlink" title="1.3.4.3 实战代码"></a>1.3.4.3 实战代码</h5><p>&#160; &#160; &#160; &#160;这一部分见Pycharm。</p><h3 id="1-4-朴素贝叶斯分类器基本原理"><a href="#1-4-朴素贝叶斯分类器基本原理" class="headerlink" title="1.4 朴素贝叶斯分类器基本原理"></a>1.4 朴素贝叶斯分类器基本原理</h3><h4 id="1-4-1-主要内容"><a href="#1-4-1-主要内容" class="headerlink" title="1.4.1 主要内容"></a>1.4.1 主要内容</h4><blockquote><p>&#160; &#160; &#160; &#160;1. 基本原理<br>&#160; &#160; &#160; &#160;2. 分类实战：新闻文本分类</p></blockquote><h4 id="1-4-2-基本原理"><a href="#1-4-2-基本原理" class="headerlink" title="1.4.2 基本原理"></a>1.4.2 基本原理</h4><p>&#160; &#160; &#160; &#160;朴素贝叶斯分类器是建立在贝叶斯概率论基础之上的。<br>&#160; &#160; &#160; &#160;它的基本假定是特征向量的各个分量(属性)是条件独立的，因为这个假设在大多数时候都是不成立的，这也是<strong>‘朴素(naive)’</strong>这个叫法的来源。<br>&#160; &#160; &#160; &#160;虽然上述关于特征分量之间条件独立的假定比较<strong>naive</strong>，但是朴素贝叶斯分类器却能比较好的工作。朴素贝叶斯分类器首先单独考察每一个特征分量下的类别分配概率，然后把每个特征分量的条件概率按照贝叶斯概率论综合起来得出最终的判决结果。<br>&#160; &#160; &#160; &#160;朴素贝叶斯分类器的训练过程其实就是估计所有类的类条件概率分布的过程。这个过程可以并行计算。</p><h4 id="1-4-3-数学推导过程"><a href="#1-4-3-数学推导过程" class="headerlink" title="1.4.3 数学推导过程"></a>1.4.3 数学推导过程</h4><p>&#160; &#160; &#160; &#160;1. $n$维特征向量：$x = <x_1,x_2,....x_n>$  类别标签集合：$y ∈${$c_1,c_2,….c_k$}$$</x_1,x_2,....x_n></p><p>&#160; &#160; &#160; &#160;2. 特征向量$x$属于类别$c_i$的概率：$P(y=c_i|x)$<br>&#160; &#160; &#160; &#160;3. 依据贝叶斯原理：</p><blockquote><p>&#160; &#160; &#160; &#160;$P(y=c_i|x) = \frac{P(x|y=c_i)P(y=c_i)}{P(x)}$，其中$P(y=c_i)$是先验概率$y=c_i$代表性别，而$P(y=c_i|x)$则代表后验概率。 </p></blockquote><p>&#160; &#160; &#160; &#160;4. 分类决策过程，在$k$个可能的类中找到一个类标签使得$P(y|x)$最大。由于$P(x)$在所有的类标签下都是相同的(也就是不管$c_i$是多少，我们的观测量$P({\bf x})$都是不依赖它的)，所以我们事实上要最大化是分子部分：</p><blockquote><p>&#160; &#160; &#160; &#160;$\mathop{\arg \max}_{y}P(x|y)P(y) = \mathop{\arg \max}_{y}P(x_1,x_2,…x_n|y)P(y)$</p></blockquote><p>&#160; &#160; &#160; &#160;5.要想最大化上面的式子，我们必须要首先知道先验概率分布$P(y)$以及类条件概率分布$P(x_1,x_2,….x_n|y)$<br>&#160; &#160; &#160; &#160;6. 先验概率分布的估计一般有两种办法：</p><blockquote><p>&#160; &#160; &#160; &#160;①$P(y=c_1) = P(y=c_2) = ···· = P(y=c_k) = \frac{1}{k}$    <strong>极大熵方法(也就是最大熵原理)，可参考：李航 《统计学习方法》 2012年清华大学出版社 第6章 逻辑斯啼回归与最大熵模型</strong>，这里考虑所有分布的概率均等，极大熵的意思就是我的估计要是我的熵最大，在<strong>均匀分布</strong>的时候概率分布的熵最大。<u>极大熵的原理是在没有任何实际观察的情况下，我们就按照最简单的逻辑进行推理估计其取值，我们不给它添加任何先验的信息</u>。<br>&#160; &#160; &#160; &#160;②$P(y=c_1) = \frac{N_1}{N}, P(y=c_2) = \frac{N_2}{N}, ….,P(y=c_k) = \frac{N_k}{N}$   <strong>极大似然方法(从样本中估计)</strong>，其中$N$是总的样本量，$N_i$是$c_i$类的样本量：$\sum^{k}_{i = 1}N_k = N$，这种方式依赖于你的样本量。</p></blockquote><p>&#160; &#160; &#160; &#160;7. 大多数时候使用的<strong>最大熵原理</strong>，除非你的总的样本是全部覆盖了所有可能的取值情况，而且是不偏不倚的，这时候你再用<strong>极大似然估计</strong>才能准确。<br>&#160; &#160; &#160; &#160;8. 类联合条件概率分布：</p><blockquote><p>&#160; &#160; &#160; &#160;$\mathop{\arg \max}_{y}P({\bf x}|y)P(y) = \mathop{\arg \max}_{y}P(x_1,x_2,…x_n|y)P(y)$<br>&#160; &#160; &#160; &#160;$P(x_1,x_2,….,x_n|y) = P(x_1|y)P(x_2,….,x_n|x_1,y)P(x_3,…..,x_n|x_1,x_2,y)······P(x_n|x_1,x_2,….,x_{n-1},y)$<br>&#160; &#160; &#160; &#160;在此发现展开还是很难估计，因为若每个特征分量只取$0$或者$1$这两个值，那么上面的联合概率分布就有$k*2^n$个，参数需要估计太多,不可行！其中$k$为类的数目，其中$y = c_1$我们要估计一遍上面的式子，$y=c_2$我们要估计一遍上面的式子，$y=c_k$我们要估计一遍上面的式子，所以上面的式子要估计$k$次，而每个特征分量可以取$0$或者$1$，所以会有$2^n$个排列数。有时候$x$的取值不仅仅两个的时候，那么取值就会非常的大。所以我们要假定特征分量之间相互条件独立($x_1$到$x_n$相互独立)$P(x_n|x_1,x_2,…..,x_{n-1},y) = P(x_n|y)$，这样，联合概率分布就可以用边缘调价概率分布的乘积来计算。</p><p>&#160; &#160; &#160; &#160;$P(x_1,x_2,….,x_n|y) = \mathop \prod^{n}_{i=1}P(x_i|y) = P(x_1|y)P(x_2|y)·····P(x_n|y)$<br>&#160; &#160; &#160; &#160;这种时候只需要估计$2n*k$个参数。<br>&#160; &#160; &#160; &#160;每个类的每个特征分类只有两个概率值：<br>&#160; &#160; &#160; &#160;$P(x_1=0|y=c_1)$和$P(x_1=1|y=c_1)$<br>&#160; &#160; &#160; &#160;类边缘条件概率分布的估计：对于任意一个类$c_i$，我们要估计它的每个特征分量取值的概率分布$P(x_1=v|y=c_i)$。这种时候，我们一般假定每个特征分量的取值是有限个离散的数值。如果原来是连续的，我们可以将其离散化为若干个有限的取值水平。<br>&#160; &#160; &#160; &#160;而且需要注意的是$x_1$和$x_2$的取值可以不一样，$x_1 ∈ V_1 = $ { $v_1,v_2,…..,v_m$ }，$x_2 ∈ V_2,….,x_n∈V_n$<br>&#160; &#160; &#160; &#160;用极大似然法估计每个特征分量在每个可能取值上的类条件概率：<br>&#160; &#160; &#160; &#160;$P(x_1=v_1|y=c_i) = \frac{N_{x_1=v_1,y=c_i}}{N_{y=c_i}}$，$P(x_1=v_2|y=c_i) = \frac{N_{x_1=v_2,y=c_i}}{N_{y=c_i}}$</p></blockquote><p>&#160; &#160; &#160; &#160;9.万一分子上的样本数$N_{x_1=v_1,y=c_i}$等于零，也就是某个类(比方说$c_i$类)在某个特征分量(比方说$x_1$这个特征分量)的某个取值上(比方说$v_1$这个取值)完全没有样本咋办？这时会造成联合概率分布为0。</p><blockquote><p>&#160; &#160; &#160; &#160;这时，我们假定所有类在所有特征分量上的每种取值上都至少落入了$q$个样本。这其实就是事先假定所有的类条件概率分布都是均匀分布。然后在训练过程中不断的根据样本的实际情况去更新类条件概率分布。改进如下：<br>&#160; &#160; &#160; &#160;$P(x_1=v_1|y=c_i) = \frac {N_{x_1=v_1,y=c_i} + q}{N_{y=c_i} + m<em>q}$，$P(x_1=v_2|y=c_i) = \frac {N_{x_1=v_2,y=c_i} + q}{N_{y=c_i} + m</em>q}$<br>&#160; &#160; &#160; &#160;其中$q = 1$的时候，叫做<strong>拉普拉斯平滑</strong>。</p></blockquote><h4 id="1-4-4-新闻文本分类实战"><a href="#1-4-4-新闻文本分类实战" class="headerlink" title="1.4.4 新闻文本分类实战"></a>1.4.4 新闻文本分类实战</h4><h5 id="1-4-4-1-数据描述"><a href="#1-4-4-1-数据描述" class="headerlink" title="1.4.4.1 数据描述"></a>1.4.4.1 数据描述</h5><blockquote><p>&#160; &#160; &#160; &#160;20类新闻文本数据集：<br>&#160; &#160; &#160; &#160;该数据集包含了关于20个话题(<strong>topic</strong>)的18000条新闻报道，这些数据被分为两个子集，训练集和测试集。<br>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/Kaggle-2/1558792487149.png" alt="Alt text"></p></blockquote><h4 id="1-4-5-贝叶斯实战"><a href="#1-4-5-贝叶斯实战" class="headerlink" title="1.4.5 贝叶斯实战"></a>1.4.5 贝叶斯实战</h4><h5 id="1-4-5-1-数据处理与实战步骤"><a href="#1-4-5-1-数据处理与实战步骤" class="headerlink" title="1.4.5.1 数据处理与实战步骤"></a>1.4.5.1 数据处理与实战步骤</h5><p>&#160; &#160; &#160; &#160;和上面一样。</p><h2 id="2-回归算法基础篇"><a href="#2-回归算法基础篇" class="headerlink" title="2. 回归算法基础篇"></a>2. 回归算法基础篇</h2><h3 id="2-1-相应内容"><a href="#2-1-相应内容" class="headerlink" title="2.1 相应内容"></a>2.1 相应内容</h3><blockquote><p>&#160; &#160; &#160; &#160;1. 线性回归器基本原理与案例实战<br>&#160; &#160; &#160; &#160;2. 支持向量机回归器原理与案例实战<br>&#160; &#160; &#160; &#160;3. K近邻回归器原理与案例实战<br>&#160; &#160; &#160; &#160;4. 决策树回归器原理与案例实战<br>&#160; &#160; &#160; &#160;5. 集成模型回归原理与案例实战</p></blockquote><h2 id="3-无监督学习基础篇"><a href="#3-无监督学习基础篇" class="headerlink" title="3. 无监督学习基础篇"></a>3. 无监督学习基础篇</h2><h3 id="3-1-相应内容"><a href="#3-1-相应内容" class="headerlink" title="3.1 相应内容"></a>3.1 相应内容</h3><blockquote><p>&#160; &#160; &#160; &#160;1. K均值聚类基本原理与案例实战<br>&#160; &#160; &#160; &#160;2. 主成分分析(<strong>PCA</strong>)原理与案例实战</p></blockquote><h2 id="4-进阶篇"><a href="#4-进阶篇" class="headerlink" title="4. 进阶篇"></a>4. 进阶篇</h2><h3 id="4-1-相应内容"><a href="#4-1-相应内容" class="headerlink" title="4.1 相应内容"></a>4.1 相应内容</h3><blockquote><p>&#160; &#160; &#160; &#160;1. 特征提取技法提升<br>&#160; &#160; &#160; &#160;2. 模型选择技法提升<br>&#160; &#160; &#160; &#160;3. 模型验证技法提升<br>&#160; &#160; &#160; &#160;4. 其他常用机器学习工具的用法</p></blockquote><h2 id="5-实战篇"><a href="#5-实战篇" class="headerlink" title="5. 实战篇"></a>5. 实战篇</h2><h3 id="5-1-相应内容"><a href="#5-1-相应内容" class="headerlink" title="5.1 相应内容"></a>5.1 相应内容</h3><blockquote><p>&#160; &#160; &#160; &#160;1. Kaggle平台简介<br>&#160; &#160; &#160; &#160;2. Titanic罹难乘客预测<br>&#160; &#160; &#160; &#160;3. IMDB影评得分估计<br>&#160; &#160; &#160; &#160;4. MNIST手写数字识别</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kaggle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据预处理---数据清洗 &amp; 特征工程</title>
      <link href="/2019/05/25/data-preprocess/"/>
      <url>/2019/05/25/data-preprocess/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>收集的一些比较重要的特征工程相关的博客链接.</strong><br><a id="more"></a></p></blockquote><h1 id="1-相应参考链接"><a href="#1-相应参考链接" class="headerlink" title="1.相应参考链接"></a>1.相应参考链接</h1><blockquote><p>&#160; &#160; &#160; &#160;1. <a href="http://www.cnblogs.com/charlotte77/" target="_blank" rel="noopener">数学系的数据挖掘民工(公众号:CharlotteDataMining)</a><br>&#160; &#160; &#160; &#160;2. <a href="https://tech.meituan.com/machinelearning-data-feature-process.html" target="_blank" rel="noopener">机器学习中的数据清洗与特征处理综述</a><br>&#160; &#160; &#160; &#160;3. <a href="https://www.cnblogs.com/wxquare/p/5484636.html" target="_blank" rel="noopener">机器学习之特征工程</a><br>&#160; &#160; &#160; &#160;4. <a href="https://www.cnblogs.com/jasonfreak/category/823064.html" target="_blank" rel="noopener">随笔分类 - 特征工程</a><br>&#160; &#160; &#160; &#160;5. <a href="https://www.cnblogs.com/weibao/p/6252280.html" target="_blank" rel="noopener">weibao—特征工程</a><br>&#160; &#160; &#160; &#160;6. <a href="https://blog.csdn.net/power0405hf/article/details/49644041" target="_blank" rel="noopener">数据清洗—power0405hf的专栏</a><br>&#160; &#160; &#160; &#160;7. <a href="https://zhuanlan.zhihu.com/p/20571505" target="_blank" rel="noopener">知乎专栏—数据清洗的一些梳理</a><br>&#160; &#160; &#160; &#160;8. <a href="https://blog.csdn.net/yen_csdn/article/details/53445616" target="_blank" rel="noopener">利用Python Pandas进行数据预处理-数据清洗</a><br>&#160; &#160; &#160; &#160;9. <a href="http://www.cnblogs.com/wkslearner/default.html?page=3" target="_blank" rel="noopener">molearner—python数据预处理</a><br>&#160; &#160; &#160; &#160;10. <a href="https://www.cnblogs.com/nxld/p/6085605.html?utm_source=itdadao&amp;utm_medium=referral" target="_blank" rel="noopener">python数据清洗</a><br>&#160; &#160; &#160; &#160;11.<a href="http://bluewhale.cc/2016-08-21/python-data-cleaning.html" target="_blank" rel="noopener">蓝鲸的网站分析笔记—-使用python进行数据清洗</a><br>&#160; &#160; &#160; &#160;12.<a href="https://github.com/ferventdesert/etlpy/" target="_blank" rel="noopener">GitHub—-etlpy是基于配置文件的数据采集和清洗工具</a><br>&#160; &#160; &#160; &#160;13. <a href="https://www.dataivy.cn/blog/3-1-%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97%EF%BC%9A%E7%BC%BA%E5%A4%B1%E5%80%BC%E3%80%81%E5%BC%82%E5%B8%B8%E5%80%BC%E5%92%8C%E9%87%8D%E5%A4%8D%E5%80%BC%E7%9A%84%E5%A4%84%E7%90%86-2%E4%BB%A3%E7%A0%81/" target="_blank" rel="noopener">数据常青藤</a><br>&#160; &#160; &#160; &#160;14. <a href="https://my.oschina.net/dfsj66011/blog/601546" target="_blank" rel="noopener">Python数据清洗实用小工具</a><br>&#160; &#160; &#160; &#160;15. <a href="https://blog.csdn.net/yehui_qy/article/details/53791006" target="_blank" rel="noopener">机器学习-常见的数据预处理</a><br>&#160; &#160; &#160; &#160;16. <a href="http://www.cnblogs.com/zhizhan/p/4870397.html" target="_blank" rel="noopener">数据预处理（完整步骤）</a><br>&#160; &#160; &#160; &#160;17.<a href="https://zhuanlan.zhihu.com/p/31885996" target="_blank" rel="noopener">从零构建机器学习模型(一)数据预处理初阶</a><br>&#160; &#160; &#160; &#160;18. <a href="https://ljalphabeta.gitbooks.io/python-/content/missingvalue.html" target="_blank" rel="noopener">重点：处理缺失值</a><br>&#160; &#160; &#160; &#160;19. <a href="https://docs.transwarp.io/5.0/goto?file=MidasManual__%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86.html" target="_blank" rel="noopener">重点：数据预处理</a><br>&#160; &#160; &#160; &#160;20. <a href="https://github.com/jacksu/machine-learning/blob/master/markdown/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86.md" target="_blank" rel="noopener">github—数据预处理</a><br>&#160; &#160; &#160; &#160;21. <a href="https://ask.hellobi.com/blog/CharlotteDataMining/10958" target="_blank" rel="noopener">深度学习系列—-PaddlePaddle之数据预处理</a><br>&#160; &#160; &#160; &#160;22. <a href="https://zhuanlan.zhihu.com/p/33030631" target="_blank" rel="noopener">Python数据处理 II：数据的清洗（预处理）</a><br>&#160; &#160; &#160; &#160;23. <a href="http://www.cnblogs.com/BoyceYang/p/8182053.html" target="_blank" rel="noopener">[数据清洗]-Pandas 清洗“脏”数据（一）</a><br>&#160; &#160; &#160; &#160;23. <a href="https://blog.csdn.net/ggwcr/article/details/78168623" target="_blank" rel="noopener">tensorflow图像数据预处理</a><br>&#160; &#160; &#160; &#160;23. <a href="https://blog.csdn.net/xinyu3307/article/details/74643019" target="_blank" rel="noopener">TensorFlow——训练自己的数据（一）数据处理</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据清洗 </tag>
            
            <tag> 特征工程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kaggle简单小例子代码</title>
      <link href="/2019/05/25/Kaggle/"/>
      <url>/2019/05/25/Kaggle/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>Kaggle简单小例子介绍.</strong><br><a id="more"></a></p></blockquote><h2 id="1-分类器例子"><a href="#1-分类器例子" class="headerlink" title="1.分类器例子"></a>1.分类器例子</h2><h3 id="1-1-Logistic-Regression分类器-乳腺肿瘤"><a href="#1-1-Logistic-Regression分类器-乳腺肿瘤" class="headerlink" title="1.1 Logistic Regression分类器(乳腺肿瘤)"></a>1.1 Logistic Regression分类器(乳腺肿瘤)</h3><pre><code>#_*_ coding:utf-8 _*_&quot;&quot;&quot;Logistics Regression模型和随机梯度下降（SGDC）用于乳腺肿瘤的二分类预测&quot;&quot;&quot;#导入工具包import numpy as npimport pandas as pd#第一步：数据预处理#创建特征列表column_names = [&#39;Sample code number&#39;,&#39;Clump Thickness&#39;,&#39;Uniformity of Cell Size&#39;,                &#39;Uniformity of Cell Shape&#39;,&#39;Marginal Adhesion&#39;,                &#39;Signle Epithelial Cell Size&#39;,&#39;Bare Nuclei&#39;,                &#39;Bland Chromatin&#39;,&#39;Normal Nucleoli&#39;,&#39;Mitoses&#39;,&#39;Class&#39;]#使用pandas.read_csv()从互联网读取数据集,其中names=column_names用于指定获取的数据每一项的含义data = pd.read_csv(&#39;https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data&#39;,names=column_names)#将？代替为标准缺失值（np.nan）表示data = data.replace(to_replace=&#39;?&#39;,value=np.nan)#丢弃带有标准缺失值的维度（只要有任何一维缺失），还有一种补充缺失值的办法是把那一维缺失的值用那一维的均值代替data = data.dropna(how=&#39;any&#39;)#输出data的数据量和维度print(data.shape)&#39;&#39;&#39;经过上面的操作后，无缺失值的样本数为683条，特征向量包括细胞厚度，细胞大小，形状等9个维度，并且每一个属性的取值范围都量化到1-10之间的数来表示。&#39;&#39;&#39;#第二步：将数据集划分为训练集和测试集#使用sklearn.model_selection里的train_test_split划分数据集from sklearn.model_selection import train_test_split#随机采样25%的数据来测试，75%的数据用于训练#train_test_split()接收两个参数，一个是样本特征向量：data[column_names[1:10]]；以及样本对应的标签：data[column_names[10]]#在指定数据划分的时候，如果测试集指定为0.25，而训练集指定为0.85，则代表训练集和测试集有重叠部分，但是一般不这么指定X_train,X_test,y_train,y_test = train_test_split(data[column_names[1:10]],data[column_names[10]],test_size=0.25,random_state=33)#查验训练样本和测试样本的数目和类别分类print(&#39;-------------------------&#39;)print(&#39;训练样本的数目和类别样本：&#39;)print(y_train.value_counts())print(&#39;-------------------------&#39;)print(&#39;测试样本的数目和类别样本：&#39;)print(y_test.value_counts())print(&#39;-------------------------&#39;)#第三步：使用Logistic线性回归学习数据集并进行预测#StandardScaler数据标准化，它属于sklearn的数据预处理包preprocessing下from sklearn.preprocessing import StandardScalerfrom sklearn.linear_model import LogisticRegressionfrom sklearn.linear_model import SGDClassifier#标准化数据，使得每个维度的数据的方差为1，均值为0，使得预测结果不会被某些维度过大的特征值给主导ss = StandardScaler()X_train = ss.fit_transform(X_train)X_test = ss.transform(X_test)print(&#39;标准化数据运行完毕！&#39;)print(&#39;初始化Logistic Regression 和 SGDClassifier！&#39;)lr = LogisticRegression()sgdc = SGDClassifier()print(&#39;调用Logistic Regression中的fit()函数来训练模型参数：&#39;)lr.fit(X_train,y_train)print(&#39;使用训练好的模型lr对X_test进行预测，结果存储在变量lr_y_predict中&#39;)lr_y_predict = lr.predict(X_test)print(&#39;调用SGDCClassifer中的fit()函数来训练模型参数：&#39;)sgdc.fit(X_train,y_train)print(&#39;使用训练好的模型sgdc对x_test进行预测，结果存储在sgdc_y_predict中&#39;)sgdc_y_predict = sgdc.predict(X_test)print(&#39;运行完毕！！&#39;)#第四步：评估分类器分类性能print(&#39;使用学习器自带的score函数获得模型在测试集上的准确率：&#39;)#这里score()函数传入X_test会调用上面的predict函数从而得到y的预测值，再与真实标签y_test进行对比得到准确率lr_accuracy = lr.score(X_test,y_test)print(&#39;Logistic回归的分类准确率为： %f&#39;%lr_accuracy)print(&#39;利用classification_report获得其他三个评估指标&#39;)from sklearn.metrics import classification_report#利用classification_report(分类报告)获得其他三个评估指标:F1-score；Precision；Recalllr_report = classification_report(y_test,lr_y_predict,target_names=[&#39;良性&#39;,&#39;恶性&#39;])print(lr_report)print(&#39;--------------------------&#39;)print(&#39;使用学习器自带的score函数获得模型在测试集上的准确率：&#39;)#这里score()函数传入X_test会调用上面的predict函数从而得到y的预测值，再与真实标签y_test进行对比得到准确率sgdc_accuracy = sgdc.score(X_test,y_test)print(&#39;随机梯度下降回归的分类准确率为： %f&#39;%sgdc_accuracy)print(&#39;利用classification_report获得其他三个评估指标&#39;)from sklearn.metrics import classification_report#利用classification_report(分类报告)获得其他三个评估指标:F1-score；Precision；Recall#打印结果中的support代表的是你使用的数据个数，也就是数据的支撑集sgdc_report = classification_report(y_test,sgdc_y_predict,target_names=[&#39;良性&#39;,&#39;恶性&#39;])print(sgdc_report)#数据集比较小的时候sgdc的效果不是太好，但是一般情况下数据集大的时候都用sgdc，因为运行速度快，而lr模型评估笔记复杂。</code></pre><h3 id="1-2-LSVM手写体分类器"><a href="#1-2-LSVM手写体分类器" class="headerlink" title="1.2 LSVM手写体分类器"></a>1.2 LSVM手写体分类器</h3><pre><code>#_*_ coding:utf-8 _*_&quot;&quot;&quot;SVM分类器在手写数字识别中的应用&quot;&quot;&quot;#第一步：加载数据集，了解数据集的规模，特征属性的取值情况等信息。print(&#39;从sklearn.datasets中导入手写数字家在函数&#39;)from sklearn.datasets import load_digitsprint(&#39;将加载的数据对象保存在digits变量中&#39;)digits = load_digits()print(&#39;digits对象是一个Bunch字典对象，所以输出它的key看看：&#39;)print(digits.keys())print(&#39;检测数据规模和特征维度：&#39;)n_samples ,n_features = digits.data.shapeprint((n_samples,n_features)) #(1797, 64)print(digits.images.shape) #(1797, 8, 8)&#39;&#39;&#39;上面的结果说明共有1797个手写字体的图像，每个图像是8*8灰度图像，data里面的样本特征向量是直接把对应的字符图像按行展开成一列，变成64维特征向量，下面导入Matplotlib将数字相比图像展现出来。&#39;&#39;&#39;import matplotlib.pyplot as plt#设置画布fig = plt.figure(figsize=(6,6)) #画布尺寸fig.subplots_adjust(left=0,right=1,bottom=0,top=1,hspace=0.05,wspace=0.05)#绘制数字：每张图像8x8像素点for i in range(64):    ax = fig.add_subplot(8,8,i+1,xticks=[],yticks=[])    ax.imshow(digits.images[i],cmap=plt.cm.binary,interpolation=&#39;nearest&#39;)    #用目标值标记图像    ax.text(0,7,str(digits.target[i]))plt.show()#第二步：把数据集划分成训练集和测试集print(&#39;使用sklearn.model_selection里的train_test_split划分数据集&#39;)from sklearn.model_selection import train_test_splitprint(&#39;随机采样25%的数据用于测试，75%用于训练&#39;)X_train,X_test,y_train,y_test = train_test_split(digits.data,digits.target,test_size=0.25,random_state=33,stratify=digits.target)print(&#39;查验训练样本和测试样本的数目和类别分类&#39;)import numpy as npprint(&#39;训练样本的数目和类别样本：&#39;)print(np.bincount(y_train))print(&#39;测试样本的数目和类别样本：&#39;)print(np.bincount(y_test))#第三步：训练支持向量机对手写字体进行分类识别#StandardScaler数据标准化，它属于sklearn的数据预处理包preprocessing下from sklearn.preprocessing import StandardScaler#从sklearn.svm里导入LinearSVCfrom sklearn.svm import LinearSVCprint(&#39;标准化数据，使得每个维度的数据的方差为1，均值为0，使得预测结果不会被某些维度过大的特征值给主导&#39;)ss = StandardScaler()X_train = ss.fit_transform(X_train)X_test = ss.fit_transform(X_test)print(&#39;数据标准化运行完毕&#39;)print(&#39;初始化线性支持向量分类器&#39;)lsvc = LinearSVC()print(&#39;进行模型训练&#39;)lsvc.fit(X_train,y_train)print(&#39;进行模型预测&#39;)lsvc_pred_test = lsvc.predict(X_test)print(&#39;运行完毕！&#39;)#第四步：对模型的预测性能进行评估print(&#39;使用学习器自带的score函数获得模型在测试集上的准确率：&#39;)lsvc_accuracy = lsvc.score(X_test,y_test)print(&#39;线性支持向量分类器的分类准确率：%f&#39; %lsvc_accuracy)print(&#39;利用classification_report获得其他三个评估指标&#39;)from sklearn.metrics import classification_reportlsvc_report = classification_report(y_test,lsvc_pred_test,target_names=digits.target_names.astype(str))print(lsvc_report)&#39;&#39;&#39;需要指出的是，precision，recall和f1-score这些一开始被用于二分类问题度量指标是无法直接用于多分类的。通常的做法是将10个数字的分类任务看成是10个二分类问题，每一个问题中，将其中一个数字看成是正类，其他数字看成是负类。最后将10个二分类问题的评估结果做平均作为多分类任务的性能评估。&#39;&#39;&#39;</code></pre><h3 id="1-3-朴素贝叶斯新闻分类"><a href="#1-3-朴素贝叶斯新闻分类" class="headerlink" title="1.3 朴素贝叶斯新闻分类"></a>1.3 朴素贝叶斯新闻分类</h3><pre><code>#_*_ coding:utf-8 _*_&quot;&quot;&quot;朴素贝叶斯分类器实战案例：新闻文本分类&quot;&quot;&quot;#第一步：加载数据集from sklearn.datasets import fetch_20newsgroups#这里data_home默认为None，此时下载的数据会被存放在你的用户目录下，所以这里直接指定存放地址为项目地址#subset代表选择要加载的数据集，其中数据集默认是打乱的(shuffle=True)news = fetch_20newsgroups(data_home=&#39;datasets&#39;,subset=&#39;all&#39;)print(&#39;总的样本数量：&#39;,len(news.data))#保存的是新闻的类型print(news.target_names)categras = [&#39;alt.atheism&#39;,&#39;comp.graphics&#39;,&#39;soc.religion.christian&#39;,&#39;sci.med&#39;]#categories之抽取部分的类别作为训练参数new_train = fetch_20newsgroups(data_home=&#39;datasets&#39;,subset=&#39;train&#39;,categories=categras)print(&#39;总的训练样本数目：&#39;,len(new_train.data))print(new_train.target_names)import numpy as npprint(&#39;训练样本的分布情况：&#39;)print(new_train.target_names)print(np.bincount(new_train.target))#打印新闻内容print(&#39;.\n&#39;.join(new_train.data[0].split(&#39;.\n&#39;)[:3]))print(new_train.data[0:10])print(new_train.target[0:10])for t in new_train.target[0:10]:    print(t,&#39;&lt;----&gt;&#39;,new_train.target_names[t])#第二步：特征向量提取,CountVectorizer特征抽取器from sklearn.feature_extraction.text import CountVectorizervec = CountVectorizer()X_train = vec.fit_transform(new_train.data)print(X_train.shape)#第三步：训练分类器from sklearn.naive_bayes import MultinomialNBmnb = MultinomialNB(alpha=1.0)mnb.fit(X_train,new_train.target)#第四步：计算分离器在训练样本集上的误差predicted_y_train = mnb.predict(X_train)error_predicted = predicted_y_train != new_train.targeterror_count = sum(error_predicted)print(&#39;分类器在训练样本集上的错分个数：&#39;,error_count)print(&#39;分类器在训练集上的正确率：&#39;,1 - error_count/len(new_train.target))error_predicted_samples = new_train.target[error_predicted]for t in error_predicted_samples:    print(t,&#39;&lt;-----&gt;&#39;,new_train.target_names[t])#第五步：加载测试集，计算测试误差categras = [&#39;alt.atheism&#39;,&#39;comp.graphics&#39;,&#39;soc.religion.christian&#39;,&#39;sci.med&#39;]#categories之抽取部分的类别作为训练参数news_test = fetch_20newsgroups(data_home=&#39;datasets&#39;,subset=&#39;test&#39;,categories=categras)print(&#39;总的测试样本数目：&#39;,len(news_test.data))print(news_test.target_names)print(&#39;测试样本的分布情况：&#39;)print(news_test.target_names)print(np.bincount(news_test.target))#第六步：提取测试样本的特征向量集合X_test = vec.transform(news_test.data)print(X_test.shape)#第七步：对测试特征向量集合进行预测，计算预测误差predicted_y_test = mnb.predict(X_test)correct_predicted = predicted_y_test == news_test.targetaccuracy = np.mean(correct_predicted)print(&#39;分类器在测试样本上的正确率：&#39;,accuracy)#第八步：评估分类器性能from sklearn.metrics import classification_reportprint(classification_report(news_test.target,predicted_y_test,target_names=news_test.target_names))error_predicted_samples = news_test.target[predicted_y_test!=news_test.target]print(&#39;错分的测试样本数目：&#39;,len(error_predicted_samples))for t in error_predicted_samples:    print(t,&#39;&lt;-----&gt;&#39;,news_test.target_names[t])#每个类的错分样本数目print(news_test.target_names)print(np.bincount(error_predicted_samples))</code></pre><h2 id="2-回归例子"><a href="#2-回归例子" class="headerlink" title="2. 回归例子"></a>2. 回归例子</h2><blockquote><p>&#160; &#160; &#160; &#160;待续。。。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kaggle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Visualizing and Understanding ConvNet---CNN可视化理解</title>
      <link href="/2019/05/25/CNN/"/>
      <url>/2019/05/25/CNN/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>卷积可视化的一些相关定义以及链接.</strong><br><a id="more"></a></p></blockquote><h2 id="1-感受野的定义-receptive-field"><a href="#1-感受野的定义-receptive-field" class="headerlink" title="1. 感受野的定义(receptive field)"></a>1. 感受野的定义(<strong>receptive field</strong>)</h2><p>&#160; &#160; &#160; &#160;此处抛出感受野(<strong>receptive field</strong>)的定义和理解：</p><blockquote><p>&#160; &#160; &#160; &#160;感受野其实就是卷积神经网络每一层输出的特征图（<strong>feature map</strong>）上的像素点在原始图像上映射的区域大小。或者说输出<strong>feature map</strong>某个节点的响应对应的输入图像的区域就是感受野。<br>&#160; &#160; &#160; &#160;比如我们第一层是一个3<em>3的卷积核，那么我们经过这个卷积核得到的<strong>feature map</strong>中的每个节点都源自这个3</em>3的卷积核与原图像中3<em>3的区域做卷积，那么我们就称这个<strong>feature map</strong>的节点感受野大小为3</em>3<br>&#160; &#160; &#160; &#160;如果再经过pooling层，假定卷积层的stride是1，pooling层大小2<em>2，stride是2，那么pooling层节点的感受野就是4</em>4<br>&#160; &#160; &#160; &#160;有几点需要注意的是，padding并不影响感受野，stride只影响下一层featuremap的感受野，size影响的是该层的感受野。<br>&#160; &#160; &#160; &#160;它的另外的定义还有：在卷积神经网络CNN中，决定某一层输出结果中一个元素所对应的输入层的区域大小，被称作感受野receptive field。<br>&#160; &#160; &#160; &#160;这里附上部分链接以备参考：<br>&#160; &#160; &#160; &#160;1. <a href="https://zhuanlan.zhihu.com/p/28492837" target="_blank" rel="noopener">深度神经网络中的感受野(Receptive Field)</a><br>&#160; &#160; &#160; &#160;2. <a href="https://www.quora.com/What-is-a-receptive-field-in-a-convolutional-neural-network" target="_blank" rel="noopener">What is a receptive field in a convolutional neural network?</a><br>&#160; &#160; &#160; &#160;3. <a href="https://zhuanlan.zhihu.com/p/22627224" target="_blank" rel="noopener">无痛理解CNN中的感受野receptive field</a><br>&#160; &#160; &#160; &#160;4. <a href="http://cs231n.github.io/understanding-cnn/" target="_blank" rel="noopener">Visualizing what ConvNets learn—-CS231n</a><br>&#160; &#160; &#160; &#160;5. <a href="https://zhuanlan.zhihu.com/p/24833574" target="_blank" rel="noopener">Deep Visualization:可视化并理解CNN</a><br>&#160; &#160; &#160; &#160;6. <a href="https://airaria.github.io/2017/10/28/CNN%20RF%20calculator/" target="_blank" rel="noopener">CNN Receptive Field Calculator — CNN感受野计算器</a><br>&#160; &#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/CNN/a.png" alt="Alt text"></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Alpha Go论文解析链接</title>
      <link href="/2019/05/25/alpha-go/"/>
      <url>/2019/05/25/alpha-go/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>一些解读AlphaGo论文的博文链接.</strong><br><a id="more"></a></p></blockquote><h2 id="1-参考文献："><a href="#1-参考文献：" class="headerlink" title="1. 参考文献："></a>1. 参考文献：</h2><blockquote><p>&#160; &#160; &#160; 1. <a href="http://xtf615.com/2018/02/10/AlphaGo/" target="_blank" rel="noopener">蘑菇先生学习记—-Alpha Go论文解析</a><br>&#160; &#160; &#160; 2. <a href="https://rongyi.blog/2016/3/10/alphago-intro-mcts.html" target="_blank" rel="noopener">AlphaGo核心技术之一，蒙特卡洛树搜索</a><br>&#160; &#160; &#160; 3. <a href="http://blog.jobbole.com/98769/" target="_blank" rel="noopener">AlphaGo相关技术：蒙特卡罗方法简介</a><br>&#160; &#160; &#160; 4. <a href="https://www.botvs.com/bbs-topic/455" target="_blank" rel="noopener">阿尔法狗的利器：蒙特卡洛算法，看完就懂了！</a><br>&#160; &#160; &#160; 5. <a href="https://blog.csdn.net/songrotek/article/details/51065143" target="_blank" rel="noopener">深度解读 AlphaGo 算法原理</a><br>&#160; &#160; &#160; 6. <a href="http://xjnine.iteye.com/blog/2282379" target="_blank" rel="noopener">Alphago中的蒙特卡洛算法</a><br>&#160; &#160; &#160; 7. <a href="https://www.cnblogs.com/think90/p/6380013.html" target="_blank" rel="noopener">AlphaGo原理-蒙特卡罗树搜索+深度学习</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AlphaGo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>WGAN一些需要注意的细节</title>
      <link href="/2019/05/25/WGAN-2/"/>
      <url>/2019/05/25/WGAN-2/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>Wasserstein GAN需要注意的一些关键点.</strong><br><a id="more"></a></p><ol><li><strong>WGAN</strong>是非凸优化，只能通过迭代的方式进行求解，无法一步找到最优值。</li><li><strong>WGAN</strong>无法使用拉格朗日进行求解，因为拉格朗日的条件是以不等式的形式表示的，但是<strong>WGAN</strong>则是对某个函数做约束(<strong>$1-Lipschitz$</strong>条件)。</li><li>由于$||f(x_1)-f(x_2)|| \leq K||x_1-x_2||$，<script type="math/tex; mode=display">\therefore$$ \frac{||f(x_1)-f(x_2)||}{||x_1-x_2||} \leq K</script>这其实就是要求$f(x)$的导数要小于$K$，所以在初始的<strong>WGAN</strong>中采用了<strong>weight clipping</strong>方法，因为在做<strong>Gradient Descent</strong>的更新的时候，权重$W$的范围是不可控的。</li><li>但是需要注意的是在做<strong>weight clipping</strong>方法的时候只能保证函数是一个满足<strong>K - Lipschitz</strong>条件的函数，虽然最后只满足<strong>K - Lipschitz</strong>条件，但是论文后面也提到说距离前面乘以$K$即可，也就是成正比的。</li></ol></blockquote>]]></content>
      
      
      <categories>
          
          <category> 生成对抗网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Wasserstein GAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>创建自己的训练数据集--TFrecords实战</title>
      <link href="/2019/05/25/tfrecords-2/"/>
      <url>/2019/05/25/tfrecords-2/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>Tfrecords理论介绍、使用方法以及相关博客链接.</strong><br><a id="more"></a></p></blockquote><h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a>1. 前言</h2><blockquote><p>&#160; &#160; &#160;刚开始学习<strong>TensorFlow</strong>的时候都是跑官方的例子：比如我们熟知的：<strong>MNIST</strong>手写体数据集或者<strong>cifar-10/100</strong>数据集，这些数据集都是官方以及整理好了的，直接使用就好。但是后面实际上不可能总是官方的数据集跑一跑就能学好<strong>TensorFlow</strong>的，所以一些项目需要处理自己的数据，整理自己的数据集。做过<strong>Kaggle</strong>竞赛的应该很熟悉<strong>.csv</strong>文件了，<strong>.csv</strong>文件非常方便,但是通常读取的时候,是一次性读取到内存里面的.要是内存小的话,就要想其他的办法了,那就变得很麻烦了. </p><p>&#160; &#160; &#160;或者有时候,从硬盘上面直接读取图片啊什么的,因为图片的文件格式,存放位置各种各样等等一些因素,要是想在训练阶段直接这么使用的话,就更加麻烦了.所以,对于数据进行统一的管理是很有必要的<strong>.TFRecord</strong>就是对于输入数据做统一管理的格式.加上一些多线程的处理方式,使得在训练期间对于数据管理把控的效率和舒适度都好于暴力的方法. </p><p>&#160; &#160; &#160;小的任务什么方法差别不大,但是对于大的任务,使用统一格式管理的好处就非常显著了.因此,TFRecord的使用方法很有必要熟悉. </p><p>&#160; &#160; &#160;自己通过查找很多资料，完成了一个简单的自己的图片通过<strong>TFRecord</strong>做成数据集以在<strong>TensorFlow</strong>运行的例子，现将其汇总，以便日后以往还能查找到。</p></blockquote><h2 id="2-TFrecord实战代码"><a href="#2-TFrecord实战代码" class="headerlink" title="2. TFrecord实战代码"></a>2. <strong>TFrecord</strong>实战代码</h2><blockquote><p>&#160; &#160; &#160;1. 自己的图片的<strong>TFrecords</strong><br>```</p><h1 id="coding-utf-8"><a href="#coding-utf-8" class="headerlink" title="__ coding:utf-8 __"></a>_<em>_ coding:utf-8 _</em>_</h1><p>‘’’<br>    做过kaggle竞赛的应该很熟悉.csv文件了,.csv文件非常方便,但是通常读取的时候,是一次性读取到内存里面的.<br>要是内存小的话,就要想其他的办法了,那就变得很麻烦了. 或者有时候,从硬盘上面直接读取图片啊什么的,因为图片的文件格式,<br>存放位置各种各样等等一些因素,要是想在训练阶段直接这么使用的话,就更加麻烦了.所以,对于数据进行统一的管理是很有必要的.<br>TFRecord就是对于输入数据做统一管理的格式.加上一些多线程的处理方式,<br>使得在训练期间对于数据管理把控的效率和舒适度都好于暴力的方法.<br>小的任务什么方法差别不大,但是对于大的任务,使用统一格式管理的好处就非常显著了.因此,TFRecord的使用方法很有必要熟悉.</p></blockquote><pre><code>本程序主要用于将自己的数据做成Tfrecords，以便tensorflow能够很好的进行划分batch和Tensor读取</code></pre><p>对于数据量较小而言，可能一般选择直接将数据加载进内存，然后再分batch输入网络进行训练<br>如果数据量较大，这样的方法就不适用了，因为太耗内存，所以这时最好使用tensorflow提供的队列queue，<br>也就是从文件读取数据。对于一些特定的读取，比如csv文件格式，官网有相关的描述，<br>这里引入一种比较高效的读取方法（官网介绍的少），即使用tensorflow内定标准格式——TFRecords。</p><pre><code>TFRecords其实是一种二进制文件，虽然它不如其他格式好理解，但是它能更好的利用内存，更方便复制和移动，并且不需要单独的标签文件。</code></pre><p>TFRecords文件包含了tf.train.Example 协议内存块(protocol buffer)(协议内存块包含了字段 Features)。<br>我们可以写一段代码获取你的数据， 将数据填入到Example协议内存块(protocol buffer)，将协议内存块序列化为一个字符串，<br>并且通过tf.python_io.TFRecordWriter 写入到TFRecords文件。</p><pre><code>从TFRecords文件中读取数据， 可以使用tf.TFRecordReader的tf.parse_single_example解析器。</code></pre><p>这个操作可以将Example协议内存块(protocol buffer)解析为张量。<br>‘’’</p><h1 id="导入相关的包"><a href="#导入相关的包" class="headerlink" title="导入相关的包"></a>导入相关的包</h1><p>import os<br>import tensorflow as tf<br>from PIL import Image<br>import matplotlib.pyplot as plt<br>import time</p><p>EPOCH = 5</p><h1 id="设置batch-size的大小"><a href="#设置batch-size的大小" class="headerlink" title="设置batch_size的大小"></a>设置batch_size的大小</h1><p>BATCH_SIZE = 5</p><h1 id="设置出队后最小剩余量"><a href="#设置出队后最小剩余量" class="headerlink" title="设置出队后最小剩余量"></a>设置出队后最小剩余量</h1><p>min_after_dequeue = 10</p><h1 id="设置队列的容量"><a href="#设置队列的容量" class="headerlink" title="设置队列的容量"></a>设置队列的容量</h1><p>capacity = min_after_dequeue + 4 * BATCH_SIZE<br>OUTPUT_SIZE = 440</p><h1 id="OUTPUT-SIZE-630"><a href="#OUTPUT-SIZE-630" class="headerlink" title="OUTPUT_SIZE = 630"></a>OUTPUT_SIZE = 630</h1><h1 id="图片通道数为3，代表彩色"><a href="#图片通道数为3，代表彩色" class="headerlink" title="图片通道数为3，代表彩色"></a>图片通道数为3，代表彩色</h1><p>DEPTH = 3</p><h1 id="定义各个路径"><a href="#定义各个路径" class="headerlink" title="定义各个路径"></a>定义各个路径</h1><p>data_path = ‘data/‘<br>tfrecords_path = ‘tfrecords/‘</p><h1 id="需要生产的-tfrecords数目"><a href="#需要生产的-tfrecords数目" class="headerlink" title="需要生产的.tfrecords数目"></a>需要生产的.tfrecords数目</h1><p>tfrecords_num = 6</p><h1 id="用于获取项目所在绝对路径"><a href="#用于获取项目所在绝对路径" class="headerlink" title="用于获取项目所在绝对路径"></a>用于获取项目所在绝对路径</h1><h1 id="cwd-D-软件安装-pycharm-PyCharm-Community-Edition-2017-3-3-workplace-TFrecods-practicing"><a href="#cwd-D-软件安装-pycharm-PyCharm-Community-Edition-2017-3-3-workplace-TFrecods-practicing" class="headerlink" title="cwd = D:\软件安装\pycharm\PyCharm Community Edition 2017.3.3\workplace\TFrecods_practicing"></a>cwd = D:\软件安装\pycharm\PyCharm Community Edition 2017.3.3\workplace\TFrecods_practicing</h1><h1 id="这里可以获取cwd，也可以不用获取，反正我使用的是相对路径-relative-path-也一样能行"><a href="#这里可以获取cwd，也可以不用获取，反正我使用的是相对路径-relative-path-也一样能行" class="headerlink" title="这里可以获取cwd，也可以不用获取，反正我使用的是相对路径(relative path)也一样能行"></a>这里可以获取cwd，也可以不用获取，反正我使用的是相对路径(relative path)也一样能行</h1><p>cwd = os.getcwd()</p><h1 id="把传入的value转化为整数型的属性，int64-list对应着-tf-train-Example-的定义"><a href="#把传入的value转化为整数型的属性，int64-list对应着-tf-train-Example-的定义" class="headerlink" title="把传入的value转化为整数型的属性，int64_list对应着 tf.train.Example 的定义"></a>把传入的value转化为整数型的属性，int64_list对应着 tf.train.Example 的定义</h1><p>def _int64_feature(value):<br>    return tf.train.Feature(int64_list = tf.train.Int64List(value = [value]))</p><h1 id="把传入的value转化为字符串型的属性，bytes-list对应着-tf-train-Example-的定义"><a href="#把传入的value转化为字符串型的属性，bytes-list对应着-tf-train-Example-的定义" class="headerlink" title="把传入的value转化为字符串型的属性，bytes_list对应着 tf.train.Example 的定义"></a>把传入的value转化为字符串型的属性，bytes_list对应着 tf.train.Example 的定义</h1><p>def _byte_feature(value):<br>    return tf.train.Feature(bytes_list = tf.train.BytesList(value = [value]))</p><h1 id="生成TFRecords文件"><a href="#生成TFRecords文件" class="headerlink" title="生成TFRecords文件"></a>生成TFRecords文件</h1><p>def create_record(data_path,tfrecords_path,tfrecords_num):</p><pre><code>rows = 32cols = 32depth = DEPTH#第一个for循环确定要将自己的数据划分为多少个.tfrecords文件for i in range(tfrecords_num):    # 先定义writer对象，writer负责将得到的记录写入TFRecords文件，此处有多个.tfrecords文件    writer = tf.python_io.TFRecordWriter(tfrecords_path + str(i) + &quot;.tfrecords&quot;)    #os.listdir() 方法用于返回指定的文件夹包含的文件或文件夹的名字的列表。这个列表以字母顺序。 它不包括 &#39;.&#39; 和&#39;..&#39; 即使它在文件夹中。    #一张一张的写入TFRecords文件(这里有15张照片，准备划分为5个.tfrecords,每三张划分到一个.tfrecords文件)    #当然，.tfrecords的数目和每次划分的数据的数目的乘积不一定满足总的数据的数目    #img_name:[]    for img_name in os.listdir(data_path)[i*BATCH_SIZE:(i+1)*BATCH_SIZE]:        &#39;&#39;&#39;        img_name:            1.JPG            10.JPG            11.jpg            12.JPG            13.jpg            14.jpg            15.JPG            2.JPG            3.JPG            4.JPG            5.JPG            6.JPG            7.JPG            8.JPG            9.JPG        &#39;&#39;&#39;        # 打开图片        img_path = data_path + img_name        img = Image.open(img_path)        #对图片做一些预处理操作        img = img.resize((OUTPUT_SIZE, OUTPUT_SIZE))        # 设置裁剪参数        h, w = img.size[:2]        j, k = (h - OUTPUT_SIZE) / 2, (w - OUTPUT_SIZE) / 2        box = (j, k, j + OUTPUT_SIZE, k + OUTPUT_SIZE)        # 裁剪图片        img = img.crop(box=box)        # 将图片转化为原生bytes        img_raw = img.tobytes()        #使用tf.train.Example来封装我们的数据        example = tf.train.Example(features=tf.train.Features(feature={            &#39;height&#39;: _int64_feature(rows),            &#39;width&#39;: _int64_feature(cols),            &#39;depth&#39;: _int64_feature(depth),            &#39;img_raw&#39;: _byte_feature(img_raw),            &#39;label&#39;: _int64_feature(i)        }))        #Example调用SerializeToString()方法将自己序列化并由        #writer = tf.python_io.TFRecordWriter(&quot;train.tfrecords&quot;)对象保存，        #最终是将所有的图片文件和label保存到同一个tfrecords文件中        writer.write(example.SerializeToString())writer.close()</code></pre><p>‘’’<br>基本的，一个Example中包含Features，Features里包含Feature（这里没s）的字典。<br>最后，Feature里包含有一个 FloatList， 或者ByteList，或者Int64List</p><ul><li>tf.train.FloatList：列表每个元素为float。</li><li>tf.train.Int64List：列表每个元素为int64。</li><li>tf.train.BytesList：列表每个元素为string。<br>‘’’</li></ul><p>‘’’<br>读取数据则以上过程的逆，先获取序列化数据，再解析：<br>一旦生成了TFRecords文件，接下来就可以使用队列（queue）读取数据了<br>TF多线程机制：<br>‘’’<br>def read_and_decode(filename):</p><pre><code>#读取tfrecords文件名到队列中，使用tf.train.string_input_producer函数，该函数可以接收一个文件名列表，#并自动返回一个对应的文件名队列filename_queue，之所以用队列是为了后续多线程考虑（队列和多线程经常搭配使用）filename_queue = tf.train.string_input_producer(filename)#实例化tf.TFRecordReader()类生成reader对象，接收filename_queue参数，并读取该队列中文件名对应的文件，reader = tf.TFRecordReader()#得到serialized_example(读到的就是.tfrecords序列化文件)_, serialized_example = reader.read(filename_queue)&#39;&#39;&#39;tf.parse_single_example函数，该函数能从serialized_example中解析出一条数据,这里tf.parse_single_example函数传入参数serialized_example和features，其中features是字典的形式，指定每个key的解析方式，比如image_raw使用tf.FixedLenFeature方法解析，这种解析方式返回一个Tensor，大多数解析方式也都是这种，另一种是tf.VarLenFeature方法，返回SparseTensor，用于处理稀疏数据，不再多提。这里还要注意必须告诉解析函数以何种数据类型解析，这必须与生成TFRecords文件时指定的数据类型一致。最后返回features是一个字典，里面存放了每一项的解析结果。最后只要读出features中的数据即可。比如，features[&#39;label&#39;],features[&#39;pixels&#39;]。但要注意的是，此时的image_raw依然是字符串类型的，需要进一步还原成像素数组，用TF提供的函数tf.decode_raw来搞定：images = tf.decode_raw(features[&#39;image_raw&#39;],tf.uint8)。&#39;&#39;&#39;features = tf.parse_single_example(serialized_example,                                   features={                                       &#39;label&#39;: tf.FixedLenFeature([], tf.int64),                                       #这里解析图片的类型与生成TFrecords文件是指定images的类型得一致                                       #所以解析的时候使用string类型，但是images解析出来是string，还需要                                       #将其进一步还原为像素数组(无符号8位---uint8类型)                                       &#39;img_raw&#39; : tf.FixedLenFeature([], tf.string),                                   })imgs = tf.decode_raw(features[&#39;img_raw&#39;], tf.uint8)imgs = tf.reshape(imgs, [OUTPUT_SIZE, OUTPUT_SIZE, 3])#tf.cast(x, dtype, name=None) 对于传入的数据将其数据格式转换为dtype类型。imgs = tf.cast(imgs, tf.float32) * (1. / 255)labels = tf.cast(features[&#39;label&#39;], tf.int32)&#39;&#39;&#39;上面已经得到了images和labels,这是一条数据，训练一次需要一个batch的数据，TF提供了tf.train.shuffle_batch函数，上述解析代码只要提供一次，然后将labels和images作为tf.train.shuffle_batch函数的参数，tf.train.shuffle_batch就能自动获取到一个batch的labels和images。tf.train.shuffle_batch函数获取batch的过程需要生成一个队列（加入计算图中），然后一个一个入队labels和images，然后出队组合batch.batch_size就是batch的大小，capacity指的是队列的容量，比如capacity设为1，而batch_szie为3，那么组成一个batch的过程中，出队的操作就会因为数据不足而频繁地被阻塞来等待入队加入数据，运行效率很低。相反，如果capacity被设置的很大，比如设为1000，而batch_size设置为3，那么入队操作在空闲时就会频繁入队，供过于求并非坏事，糟糕的是这样会占用很多内存资源，而且没有得到多少效率上的提升。还有一点值得注意，当使用tf.train.shuffle_batch时，为了使得shuffle效果好一点，出队后队列剩余元素必须得足够多，因为太少的话也没什么必要打乱了，因此tf.train.shuffle_batch函数要求提供min_after_dequeue参数来保证出队后队内元素足够多，这样队列就会等队内元素足够多时才会出队。显而易见，capacity必须大于min_after_dequeue。min_after_dequeue根据数据集大小和batch_size综合考虑，而capacity则通常设置为capacity= min_after_dequeue + 3*batch_size，在效率和资源占用之间取得平衡。&#39;&#39;&#39;#制作打乱顺序的batchimg_batch, label_batch = tf.train.shuffle_batch([imgs, labels], batch_size=BATCH_SIZE,                                                capacity=capacity,                                                min_after_dequeue=min_after_dequeue)return img_batch,label_batch</code></pre><h1 id="TFRecords-collection-模型汇总"><a href="#TFRecords-collection-模型汇总" class="headerlink" title="TFRecords_collection(模型汇总)"></a>TFRecords_collection(模型汇总)</h1><p>def TFRecords_collection():</p><pre><code># 注意os.path.isfile只是判断传入的文件是否存在,而os.path.exists()则是判断文件或者文件夹是否存在# 这里判断.tfrecords文件是否已经写入成功if os.path.isfile(tfrecords_path + &#39;0.tfrecords&#39;):    print(&#39;--------------.tfrecords文件已存在--------------&#39;)else:    start_time = time.time()    print(&#39;--------------开始制作tfrecords--------------&#39;)    # 制作tfrecords    create_record(data_path, tfrecords_path, tfrecords_num)    print(&#39;------------制作结束：耗时%.2f seconds-----------&#39; % (time.time() - start_time))# os.path模块主要用于文件的属性获取,os.path.join(path1[, path2[, ...]])将多个路径组合后返回，# 第一个绝对路径之前的参数将被忽略filenames = [os.path.join(tfrecords_path, &#39;%d.tfrecords&#39; % ii) for ii in range(tfrecords_num)]# 获取img_batch和label_batchimg_batch, label_batch = read_and_decode(filenames)# 打印img_batch和label_batch的type,发现都是Tensor类型&#39;&#39;&#39;img_batch.type Tensor(&quot;shuffle_batch:0&quot;, shape=(5, 440, 440, 3), dtype=float32)label_batch.type Tensor(&quot;shuffle_batch:1&quot;, shape=(5,), dtype=int32)&#39;&#39;&#39;print(&#39;img_batch.type&#39;, img_batch)print(&#39;label_batch.type&#39;, label_batch)# 初始化所有的opinit = tf.global_variables_initializer()with tf.Session() as sess:    sess.run(init)    # 启用队列，tf.train.start_queue_runners函数，这个函数中传入参数sess,就可以做到多线程训练    threads = tf.train.start_queue_runners(sess=sess)    for i in range(EPOCH):        plt.figure(figsize=(15, 15))        value, label = sess.run([img_batch, label_batch])        print(&#39;第%d次打印标签:&#39; % (i + 1), label)        print(&#39;value.shape:&#39;, value.shape)        print(&#39;value.type&#39;, type(value))        for j in range(BATCH_SIZE):            # 每个batch的照片数目：value.shape[0]            plt.subplot(1, value.shape[0], (j + 1))            plt.imshow(value[j:j + 1, :, :, :].reshape(OUTPUT_SIZE, OUTPUT_SIZE, 3))        plt.show()#需要注意的是，如果需要对图片裁切大小的OUTPUT_SIZE进行更改的话，一定要将tfrecords文件夹的.tfrecords文件#全部删除，因为.tfrecoeds是上一次保存的，也就包含了上一次图片裁切大小的OUTPUT_SIZE的设定，#所以，如果不删除，则会导致读取了上一次的.tfrecords文件，而导致图片.reshape失败，从而程序报错#中间遇到一个错误就是这个，改了很久都没效果，所以要记住。</code></pre><p>if <strong>name</strong> == ‘<strong>main</strong>‘:<br>    TFRecords_collection()</p><pre><code>&gt;&amp;#160; &amp;#160; &amp;#160;2. Kaggle猫狗大战(Cats_vs_Dogs)训练集**TFrecords**</code></pre><h1 id="coding-utf-8-1"><a href="#coding-utf-8-1" class="headerlink" title="-- coding: utf-8 --"></a>-<em>- coding: utf-8 -</em>-</h1><p>import os<br>import tensorflow as tf<br>from PIL import Image<br>import matplotlib.pyplot as plt<br>import numpy as np</p><p>data_path = ‘Cat_vs_Dog/‘<br>tfrecords_path = ‘Cat_vs_Dog_tfrecords/‘<br>filename = os.path.join(tfrecords_path,’train.tfrecords’)<br>BATCH_SIZE = 4</p><h1 id="预先定义自己的类-如果数据集类别比较多，可以批量读取，比如我的train文件夹下面有一百多个文件夹，"><a href="#预先定义自己的类-如果数据集类别比较多，可以批量读取，比如我的train文件夹下面有一百多个文件夹，" class="headerlink" title="预先定义自己的类(如果数据集类别比较多，可以批量读取，比如我的train文件夹下面有一百多个文件夹，"></a>预先定义自己的类(如果数据集类别比较多，可以批量读取，比如我的train文件夹下面有一百多个文件夹，</h1><h1 id="每个存放相应类别图片，我的classes就这样读出来的——classes-os-listdir-train-dir"><a href="#每个存放相应类别图片，我的classes就这样读出来的——classes-os-listdir-train-dir" class="headerlink" title="每个存放相应类别图片，我的classes就这样读出来的——classes = os.listdir(train_dir))"></a>每个存放相应类别图片，我的classes就这样读出来的——classes = os.listdir(train_dir))</h1><p>classes = {‘cats’, ‘dogs’}</p><p>def _int64_feature(value):<br>    return tf.train.Feature(int64_list = tf.train.Int64List(value = [value]))</p><p>def _bytes_feature(value):<br>    return tf.train.Feature(bytes_list = tf.train.BytesList(value = [value]))</p><p>def create_record(data_path,tfrecords_path):</p><pre><code># 输出成TFrecords文件writer = tf.python_io.TFRecordWriter(tfrecords_path + &#39;train.tfrecords&#39;)for index, name in enumerate(classes):    class_path = data_path + name + &#39;/&#39;    for img_name in os.listdir(class_path):        img_path = class_path + img_name    #每个图片的地址        img = Image.open(img_path)        img = img.resize((208, 208))        img_raw = img.tobytes()  #将图片转化为二进制格式        example = tf.train.Example(features = tf.train.Features(feature = {                                                            &quot;label&quot;: _int64_feature(index),                                                            &quot;img_raw&quot;: _bytes_feature(img_raw),                                                                           }))        writer.write(example.SerializeToString())  #序列化为字符串writer.close()</code></pre><p>def read_and_decode(filename, batch_size): #读取.tfrecords文件</p><pre><code># 创建一个队列filename_queue = tf.train.string_input_producer([filename])reader = tf.TFRecordReader()#返回文件名和文件_, serialized_example = reader.read(filename_queue)#features保存&#39;label&#39;和&#39;img_raw&#39;features = tf.parse_single_example(serialized_example,                                   features={                                       &#39;label&#39;: tf.FixedLenFeature([], tf.int64),                                       &#39;img_raw&#39; : tf.FixedLenFeature([], tf.string),                                   })img = tf.decode_raw(features[&#39;img_raw&#39;], tf.uint8)img = tf.reshape(img, [208, 208, 3])  #reshape image to 512*80*3</code></pre><h1 id="img-tf-cast-img-tf-float32-1-255-0-5-throw-img-tensor"><a href="#img-tf-cast-img-tf-float32-1-255-0-5-throw-img-tensor" class="headerlink" title="img = tf.cast(img, tf.float32) * (1. / 255) - 0.5 #throw img tensor"></a>img = tf.cast(img, tf.float32) * (1. / 255) - 0.5 #throw img tensor</h1><pre><code>label = tf.cast(features[&#39;label&#39;], tf.int32) #throw label tensorimg_batch, label_batch = tf.train.shuffle_batch([img, label],                                                batch_size= batch_size,                                                num_threads=64,                                                capacity=2000,                                                min_after_dequeue=1500,                                                )return img_batch, tf.reshape(label_batch,[batch_size])</code></pre><p>if <strong>name</strong> == ‘<strong>main</strong>‘:<br>    create_record(data_path, tfrecords_path)<br>    image_batch, label_batch = read_and_decode(filename, BATCH_SIZE)<br>    print(‘image_batch.type:’,image_batch)<br>    print(‘label_batch.type:’, label_batch)</p><pre><code>with tf.Session()  as sess:    i = 0    # 启动多线程处理输入数据    coord = tf.train.Coordinator()    threads = tf.train.start_queue_runners(coord=coord)    try:        while not coord.should_stop() and i&lt;1:            # just plot one batch size            image, label = sess.run([image_batch, label_batch])            print(&#39;image.type:&#39;,type(image))            print(&#39;image.shape:&#39;,image.shape)            plt.figure(figsize=(10, 8))            for j in np.arange(BATCH_SIZE):                # print()                plt.subplot(2, image.shape[0]/2, (j + 1))                plt.title(&#39;label: %d&#39; % label[j],fontsize = 16)                plt.imshow(image[j,:,:,:])            plt.show()            i+=1    except tf.errors.OutOfRangeError:        print(&#39;done!&#39;)    finally:        # When done, ask the threads to stop.        coord.request_stop()    #等待线程结束    coord.join(threads)</code></pre><p>‘’’<br>可以利用sklearn下的train_test_split()方法将数据分为三部分，训练集、开发集、验证集，例如：<br>train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.4, random_state=40)<br>‘’’<br>```</p><h2 id="3-参考链接以及相关附注"><a href="#3-参考链接以及相关附注" class="headerlink" title="3. 参考链接以及相关附注"></a>3. 参考链接以及相关附注</h2><p>&#160; &#160; &#160;1. 项目的图片如下：<br>&#160; &#160; &#160;<img src= "/img/loading.gif" data-src="/2019/05/25/tfrecords-2/b.png" alt><br>&#160; &#160; &#160;2. 参考链接：</p><blockquote><p>&#160; &#160; &#160;1. <a href="https://github.com/Blssel/TF-learing/blob/master/tfrecord/readme.md" target="_blank" rel="noopener">Github：TF-learing/tfrecord/readme.md</a><br>&#160; &#160; &#160;2. <a href="https://www.jianshu.com/p/ec456fbbcf45" target="_blank" rel="noopener">简书：TensorFlow高效读取数据 | Ycszen-物语</a><br>&#160; &#160; &#160;3. <a href="https://zhuanlan.zhihu.com/p/27238630" target="_blank" rel="noopener">十图详解tensorflow数据读取机制（附代码</a><br>&#160; &#160; &#160;4. <a href="https://blog.csdn.net/xierhacker/article/details/72357651" target="_blank" rel="noopener">TensorFlow学习（十一）：保存TFRecord文件</a><br>&#160; &#160; &#160;5. <a href="https://lguduy.github.io/2017/05/20/TensorFlow%E6%95%99%E7%A8%8B-%E5%A4%84%E7%90%86%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE/#%E5%89%8D%E8%A8%80" target="_blank" rel="noopener">TensorFlow教程：利用TensorFlow处理自己的数据</a><br>&#160; &#160; &#160;6. <a href="https://blog.csdn.net/shenxiaolu1984/article/details/52857437" target="_blank" rel="noopener">TensorFlow动手玩：数据导入2</a><br>&#160; &#160; &#160;7. <a href="https://blog.csdn.net/wiinter_fdd/article/details/72835939" target="_blank" rel="noopener">用Tensorflow处理自己的数据：制作自己的TFRecords数据集——Cats_vs_Dogs</a><br>&#160; &#160; &#160;8. <a href="https://blog.csdn.net/Best_Coder/article/details/70141075?locationNum=3&amp;fps=1" target="_blank" rel="noopener">Tensorflow 训练自己的数据集（一）（数据直接导入到内存）</a><br>&#160; &#160; &#160;9. <a href="https://www.cnblogs.com/wktwj/p/7227544.html" target="_blank" rel="noopener">tensorflow训练自己的数据集实现CNN图像分类1</a><br>&#160; &#160; &#160;10. <a href="https://blog.csdn.net/yimi_ac/article/details/79008555" target="_blank" rel="noopener">tensorflow实现逻辑回归，在kaggle《泰坦尼克》训练并测试准确率</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tfrecord </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>原始数据划分以及TFrecords实战</title>
      <link href="/2019/05/25/tfrecords-1/"/>
      <url>/2019/05/25/tfrecords-1/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>Tfrecords应用在Kaggle猫狗大战中的例子.</strong><br><a id="more"></a></p></blockquote><h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a>1. 前言</h2><blockquote><p>&#160; &#160; &#160;本次代码是实现对自己的数据进行训练集、验证集和测试集划分，以及将三个集合制作成<strong>.TFrecords</strong>文件的实际操作，其中原始图片是<strong>Kaggle</strong>经典的猫狗大战的训练集中各抽出100章图片组合成的。</p><p>&#160; &#160; &#160;其中总的图片数目为200张，训练集设定为总数据的<strong>70%</strong>，验证集为总数据的<strong>20%</strong>，而测试集为总数据的<strong>10%</strong>。</p></blockquote><h2 id="2-实际代码"><a href="#2-实际代码" class="headerlink" title="2. 实际代码"></a>2. 实际代码</h2><pre><code>#_*_ coding:utf-8 _*_&quot;&quot;&quot;@author:Stoner@time:2018/5/1722:14&quot;&quot;&quot;import osimport numpy as npimport mathfrom sklearn.model_selection import train_test_splitimport tensorflow as tffrom PIL import Imageimport matplotlib.pyplot as plt#存放图片文件的地址data_path = &#39;Cat_vs_Dog/&#39;#各个集合所占的比例train_size = 0.7val_size = 0.2#TFrecords文件存放文件夹：tfrecords_path = &#39;Train_val_test_tfrecords/&#39;#选择需要将train、val还是test转换为TFrecords文件tfrecords_list = [&#39;train&#39;,&#39;val&#39;,&#39;test&#39;]tfrecords_choise = tfrecords_list[2]#.tfrecords文件所在目录filename = os.path.join(tfrecords_path,tfrecords_choise+&#39;.tfrecords&#39;)BATCH_SIZE = 4NUM_CLASSES = 2#获得数据，并将其转换为数据集、交叉验证机以及测试集def getDatafile(data_path,train_size,val_size):    #用于存放从文件中读取到的文件名    images_path = []    #os.walk是一个简单易用的文件、目录遍历器    for root,sub_folders,files in os.walk(&#39;Cat_vs_Dog&#39;):        for name in files:            images_path.append(os.path.join(root,name))    # print(&#39;root:\n&#39;,root)    # print(&#39;sub_folder:\n&#39;,sub_folders)    # print(&#39;files:\n&#39;,files)    # print(&#39;images_path:\n&#39;,images_path)    # 用于存放图片数据集所有的标签    labels = []    for image_path in images_path:        label = int(image_path.replace(&#39;\\&#39;,&#39;/&#39;)[11])  # 将对应的label提取出来        labels.append(label)    print(&#39;labels:\n&#39;,labels)    # 先将图片路径和标签合并    print(&#39;np.array([images_path, labels]):\n&#39;,np.array([images_path, labels]))    temp = np.array([images_path, labels]).transpose()    #通过transpose将数组合并，也就是文件和标签对应    print(&#39;temp:\n&#39;,temp)    # 提前随机打乱    np.random.shuffle(temp)    #temp第0列全为image数据    images_data_list = temp[:, 0]    # image path    #temp第1列全为label数据    labels_data_list = temp[:, 1]         # label    #通过sklearn完成数据划分    &#39;&#39;&#39;     X_train,X_test,y_train,y_test = train_test_split(images_data_list,labels_data_list,test_size=0.3,random_state=0)    print(X_train)    y_test = [int(float(i)) for i in y_test]    print(y_train)    &#39;&#39;&#39;    # 手动代码实现数据集的划分    # math.ceil()函数返回数字的上入整数    # 1.首先实现训练集、验证集和测试集的划分数目    train_num = math.ceil(len(temp) * train_size)    val_num = math.ceil(len(temp) * val_size)    #训练集数据划分    train_img = images_data_list[0:train_num]    train_labels = labels_data_list[0:train_num]    train_labels = [int(float(i)) for i in train_labels]    # print(train_img)    # print(train_labels)    #验证集数据划分    val_img = images_data_list[train_num:train_num+val_num]    val_labels = labels_data_list[train_num:train_num+val_num]    val_labels = [int(float(i)) for i in val_labels]    #测试集数据划分    test_img = images_data_list[train_num+val_num:]    test_labels = labels_data_list[train_num+val_num:]    test_labels = [int(float(i)) for i in test_labels]    #打印查看    print(&#39;训练集数据：\n&#39;,len(train_img))    print(&#39;测试集标签：\n&#39;,len(test_labels))    #把训练集、验证集和测试集存放在一个字典中，方便调用    data = {        &#39;train_img&#39;:train_img,        &#39;train_labels&#39;:train_labels,        &#39;val_img&#39;:val_img,        &#39;val_labels&#39;:val_labels,        &#39;test_img&#39;:test_img,        &#39;test_labels&#39;:test_labels    }    # 返回图片路径列表和对应标签列表    return data#把传入的value转化为整数型的属性，int64_list对应着 tf.train.Example 的定义def _int64_feature(value):    return tf.train.Feature(int64_list = tf.train.Int64List(value = [value]))#把传入的value转化为字符串型的属性，bytes_list对应着 tf.train.Example 的定义def _bytes_feature(value):    return tf.train.Feature(bytes_list = tf.train.BytesList(value = [value]))#制作TFrecords文件def create_record(data,data_path,tfrecords_path,tfrecords_choise):    # 根据tfrecords_choise来对应输出TFrecords文件    writer = tf.python_io.TFRecordWriter(tfrecords_path +tfrecords_choise+&#39;.tfrecords&#39;)    choice_data = data[tfrecords_choise+&#39;_img&#39;]    choice_labels = data[tfrecords_choise + &#39;_labels&#39;]    #打印看一下自己选择的是哪个数据集及其大小    print(&#39;选择的数据集是：&#39;,tfrecords_choise)    print(&#39;%s集的大小为：&#39;%tfrecords_choise,data[tfrecords_choise+&#39;_img&#39;].shape)    for i in range(len(choice_data)):        img_path = choice_data[i]    #每个图片的地址        img = Image.open(img_path)        img = img.resize((300, 300))        img_raw = img.tobytes()  #将图片转化为二进制格式        example = tf.train.Example(features = tf.train.Features(feature = {                                    &quot;label&quot;: _int64_feature(choice_labels[i]),                                    &quot;img_raw&quot;: _bytes_feature(img_raw),                                    }))        writer.write(example.SerializeToString())  #序列化为字符串    writer.close()#解析TFrecords文件def read_and_decode(filename, batch_size,one_hot,standardized): #读取.tfrecords文件    # 创建一个队列    filename_queue = tf.train.string_input_producer([filename])    reader = tf.TFRecordReader()    #返回文件名和文件    _, serialized_example = reader.read(filename_queue)    #features保存&#39;label&#39;和&#39;img_raw&#39;    features = tf.parse_single_example(serialized_example,                        features={                        &#39;label&#39;: tf.FixedLenFeature([], tf.int64),                        &#39;img_raw&#39; : tf.FixedLenFeature([], tf.string),                        })    img = tf.decode_raw(features[&#39;img_raw&#39;], tf.uint8)    #这里将img从string转换为uint    img = tf.reshape(img, [300, 300, 3])    # standardized    # 训练网络时，需要标准化    # 测试这个函数时，需要把读取的图片显示出来，标准化后会显示异常，不需要标准化    # 当训练出现异常时，也方便debug，观察训练数据是否异常    # tf.image.per_image_standardization(image)，此函数的运算过程是将整幅图片标准化（不是归一化），    # 加速神经网络的训练。主要有如下操作，(x - mean) / adjusted_stddev，其中x为图片的RGB三通道像素值，    # mean分别为三通道像素的均值，adjusted_stddev = max(stddev, 1.0/sqrt(image.NumElements()))。    # stddev为三通道像素的标准差，image.NumElements()计算的是三通道各自的像素个数。    if standardized:        img = tf.image.per_image_standardization(img)    #这里是做图像归一化    &#39;&#39;&#39;    ValueError: Floating point image RGB values must be in the 0..1 range.    imshow是用来显示图片的，如    I = imread(&#39;moon.tif&#39;);    figure,imshow(I);    而有时为了数据处理，要把读取的图片信息转化为更高的精度，    I = double(imread(&#39;moon.tif&#39;));    为了保证精度，经过了运算的图像矩阵I其数据类型会从unit8型变成double型。如果直接运行imshow(I)，我们会发现显示的是一个白色的图像。这是因为imshow()显示图像时对double型是认为在0~1范围内，即大于1时都是显示为白色，而imshow显示uint8型时是0~255范围。而经过运算的范围在0-255之间的double型数据就被不正常得显示为白色图像了。    有两个解决方法：     1.imshow(I/256); -----------将图像矩阵转化到0-1之间     2.imshow(I,[]); -----------自动调整数据的范围以便于显示.    3.从实验结果看两种方法都解决了问题，但是从显示的图像看，第二种方法显示的图像明暗黑白对比的强烈些！    &#39;&#39;&#39;    img = tf.cast(img, tf.float32) * (1. / 255)    label = tf.cast(features[&#39;label&#39;], tf.int32)    #打乱顺序组合成batch    img_batch, label_batch = tf.train.shuffle_batch([img, label],                                            batch_size= batch_size,                                            num_threads=64,                                            capacity=2000,                                            min_after_dequeue=1500,                                            )    #如果数据的类别比较多，可能会需要将数据的标签转化为one_hot类型    if one_hot:        n_classes = NUM_CLASSES        label_batch = tf.one_hot(label_batch, depth=n_classes)        # tf.one_hot之后label的类型变为tf.float32，后面运行会出bug        # 所以在这里再次调用tf.cast        label_batch = tf.cast(label_batch, tf.int32)        label_batch = tf.reshape(label_batch, [batch_size, n_classes])    else:        label_batch = tf.reshape(label_batch, [batch_size])    #返回指定数据集生成的batch    return img_batch, label_batch#主函数if __name__ == &#39;__main__&#39;:    #返回包含训练集、验证集和测试集的数据综合    data = getDatafile(data_path, train_size, val_size)    #通过tfrecords_choise可以指定将哪个集转化为TFrecords文件    create_record(data,data_path,tfrecords_path,tfrecords_choise)    #生成指定数据集的TFrecords文件    image_batch, label_batch = read_and_decode(filename, BATCH_SIZE,one_hot=True,standardized=False)    #打印查看batch的类型、大小等信息    print(&#39;image_batch.type:&#39;,image_batch)    print(&#39;label_batch.type:&#39;, label_batch)    with tf.Session()  as sess:        i = 0        # 启动多线程处理输入数据        coord = tf.train.Coordinator()        threads = tf.train.start_queue_runners(coord=coord)        try:            while not coord.should_stop() and i&lt;1:                #获取batch这个Tensor中的图像和标签的值                images, labels = sess.run([image_batch, label_batch])                print(&#39;image.type:&#39;,type(images))                print(&#39;image.shape:&#39;,images.shape)                print(&#39;labels.type:&#39;, type(labels))                print(&#39;labels.shape:&#39;,labels.shape)                print(&#39;one_hot_labels:\n&#39;,labels)                #由于labels是one_hot编码，plt无法换图，所以使用np.argmax返回沿轴axis最大值的索引                labels_ = np.argmax(labels, 1)                plt.figure(figsize=(10, 8))                for j in np.arange(BATCH_SIZE):                    plt.subplot(2, images.shape[0]/2, (j + 1))                    plt.title(&#39;label: %d&#39; % labels_[j],fontsize = 16)                    plt.imshow(images[j,:,:,:])                plt.show()                i+=1        except tf.errors.OutOfRangeError:            print(&#39;done!&#39;)        finally:            # When done, ask the threads to stop.            coord.request_stop()        #等待线程结束        coord.join(threads)</code></pre>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tfrecord </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>神经网络实战之前的注意事项</title>
      <link href="/2019/05/25/NN/"/>
      <url>/2019/05/25/NN/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>创建神经网络需要注意的各个要点.</strong><br><a id="more"></a></p><h2 id="1-变量初始化"><a href="#1-变量初始化" class="headerlink" title="1. 变量初始化"></a>1. 变量初始化</h2><h3 id="1-1-零初始化"><a href="#1-1-零初始化" class="headerlink" title="1.1 零初始化"></a>1.1 零初始化</h3></blockquote><pre><code>W = np.zero((n_in,n_out))</code></pre><blockquote><p>结果：<br>零初始化会导致训练过程无效，所有的神经元节点做的都是同样的计算,相当于重复劳动了。通常来说，零初始化都会导致神经网络无法打破对称性，最终导致的结构就是无论网络有多少层，最终只能得到和Logistic函数相同的效果。</p></blockquote><h3 id="1-2-标准高斯分布初始化"><a href="#1-2-标准高斯分布初始化" class="headerlink" title="1.2 标准高斯分布初始化"></a>1.2 标准高斯分布初始化</h3><pre><code>W = np.random.randn((n_in,n_out))</code></pre><blockquote><p>结果：<br>高斯分布：$ f(x)=\frac{1}{\sqrt{2\pi }\sigma }exp(-\frac{(x-\mu )^{2}}{2\sigma ^{2}})$<br>根据独立标准高斯分布变量来选择权重和偏置， $μ=0$ ， $σ=1$<br>由于隐藏神经元的输出 $σ(z)$($sigmoid$函数)会接近0或1，使隐藏层神经元达到饱和．此时对神经元权重进行微小调整只能给神经元的激活值带来非常微弱的变化．结果，在进行梯度下降算法时会导致神经网络学习缓慢。</p></blockquote><h3 id="1-3-改进高斯分布初始化"><a href="#1-3-改进高斯分布初始化" class="headerlink" title="1.3 改进高斯分布初始化"></a>1.3 改进高斯分布初始化</h3><pre><code>W = np.random.randn((n_in,n_out))/np.sqrt(n_in)</code></pre><p>使用 $μ=0$,$\sigma=\frac{1}{ \sqrt{n_{in} }}$ 高斯分布的随机值,对权重和偏向进行初始化</p><blockquote><p>结果：<br>在-1到1区间上 σ(z)的斜率比较大，对神经元权重进行微小调整能给神经元的激活值带来非常明显的变化，解决了神经网络学习缓慢的问题．</p></blockquote><h3 id="1-4-Xavier初始化"><a href="#1-4-Xavier初始化" class="headerlink" title="1.4 Xavier初始化"></a>1.4 Xavier初始化</h3><p>$W\sim U\left[ -\frac{\sqrt{6}}{\sqrt{n_i + n_{i+1}}},\frac{\sqrt{6}}{\sqrt{n_i + n_{i+1}}} \right]$</p><p>其中$U[−a,a]$是区间$(−a,a)$上的均匀分布</p><pre><code>def xavier_init(fan_in, fan_out, constant = 1):    low = -constant * np.sqrt(6.0 / (fan_in + fan_out))    high = constant * np.sqrt(6.0 / (fan_in + fan_out))    return tf.random_uniform((fan_in, fan_out),minval=low, maxval=high, dtype=tf.float32)</code></pre><blockquote><p>论文来源：<br>$Xavier Glorot, Antoine Bordes, and Yoshua Bengio. Deep sparse rectifier neural networks. In International Conference on Artificial Intelligence and Statistics, pages 315–323, 2011$</p></blockquote><h3 id="1-5-He初始化"><a href="#1-5-He初始化" class="headerlink" title="1.5 He初始化"></a>1.5 He初始化</h3><p>He初始化中，系数为<strong>sqrt(2./layers_dims[l-1])</strong></p><pre><code>W = np.random.randn(layers-dims[l], layers-dims[l-1]) * np.sqrt(2./layers-dims[l-1])</code></pre><blockquote><p>He初始化搭配ReLU激活函数常常可以得到不错的效果。</p></blockquote><h2 id="2-正则化"><a href="#2-正则化" class="headerlink" title="2. 正则化"></a>2. 正则化</h2><blockquote><p>在深度学习中，如果数据集没有足够大的话，可能会导致一些过拟合的问题。过拟合导致的结果就是在训练集上有着很高的精确度，但是在遇到新的样本时，精确度下降严重。为了避免过拟合的问题，需要使用正则化。</p></blockquote><h3 id="2-1-L2正则化"><a href="#2-1-L2正则化" class="headerlink" title="2.1 L2正则化"></a>2.1 L2正则化</h3><p>$J(w,b) = \frac{1}{m}\sum_{i=1}^mL(\hat{y}^{(i)},y^{(i)}) + \frac{\lambda}{m}||w||_2^2$</p><p>其中，$||w||_2^2=\sum_{j=1}^{n_x}w_j^2=w^Tw$</p><h3 id="2-2-L1正则化"><a href="#2-2-L1正则化" class="headerlink" title="2.2 L1正则化"></a>2.2 L1正则化</h3><p>$J(w; X, y) = L_{emp}(w; X, y) + \alpha|w|_1$</p><blockquote><p>L1正则化是指权值向量w中各个元素的绝对值之和，通常表示为$||w||_1$<br>L1正则化可以产生稀疏权值矩阵，即产生一个稀疏模型，可以用于特征选择。<br>稀疏矩阵指的是很多元素为0，只有少数元素是非零值的矩阵，即得到的线性回归模型的大部分系数都是0. 通常机器学习中特征数量很多，例如文本处理时，如果将一个词组（term）作为一个特征，那么特征数量会达到上万个（bigram）。在预测或分类时，那么多特征显然难以选择，但是如果代入这些特征得到的模型是一个稀疏模型，表示只有少数特征对这个模型有贡献，绝大部分特征是没有贡献的，或者贡献微小（因为它们前面的系数是0或者是很小的值，即使去掉对模型也没有什么影响），此时我们就可以只关注系数是非零值的特征。这就是稀疏模型与特征选择的关系。<br><strong>注意：</strong><br>the L1 regularizer is punished uniformly for low and high values, and<br>has an incentive to decrease all the non-zero parameter values toward zero. It thus encourages a sparse solutions—models with many parameters with a zero value. The L1 regularizer is also called a sparse prior or lasso </p></blockquote><h3 id="2-3-Elastic-Net"><a href="#2-3-Elastic-Net" class="headerlink" title="2.3     Elastic-Net"></a>2.3     Elastic-Net</h3><blockquote><p>The elastic-net regularization [Zou and Hastie, 2005] combines both L1 and L2regularization:</p></blockquote><p>$R_{elastic-net} = λ_1R_{L1} (W)+  λ_2R_{L2}(W)$</p><h3 id="2-4-Dropout"><a href="#2-4-Dropout" class="headerlink" title="2.4 Dropout"></a>2.4 Dropout</h3><p>除了以上正则化方法之外，Dropout方法也是一个十分常用的正则化手段<br><img src= "/img/loading.gif" data-src="/2019/05/25/NN/1558794215795.png" alt="Alt text"></p><p>假设我们在上图的神经网络结构中进行训练，验证时发现了较严重的过拟合现象。 那么Dropout的基本原理如下： </p><ul><li>遍历每层的神经元节点，并设置每层节点随机消失的概率。 </li><li>例如，我们设置所有节点都是有0.5的概率会消失。 </li><li>那么，在完成这个过程后，我们会发现有一些节点现在已经被失效：<br><img src= "/img/loading.gif" data-src="/2019/05/25/NN/1558793465755.png" alt="Alt text"></li></ul><ul><li>然后，我们删除掉与这些节点关联的连线：<br><img src= "/img/loading.gif" data-src="/2019/05/25/NN/1558793471128.png" alt="Alt text"></li></ul><ul><li>此时，我们将会得到一个节点更少，网络更加简单的模型结构。<br>对于该样本，以同样的结构进行前向传播和反向传播。<br>而当下一样本输入时，我们需要重新随机选择节点置为失效并进行前向传播和反向传播。 <blockquote><p><strong>注意：</strong><br>需要注意的是，在使用Dropout进行训练得到的模型，在进行验证，测试或应用时，应该不再适用Dropout函数进行随机失效处理。 主要原因是因为在测试或验证阶段，我们不希望输出的结果是随机的。<br>添加了Dropout函数后，我们无法对某些神经元或特征进行强依赖，而是更多地会依赖于整个的权重分配。</p></blockquote></li><li>在使用Dropout函数时，不同层的keep_prob可以变化。例如，对于某些神经元较多的层，我们可以设置更低的keep_prob来避免过拟合，因此理论上，在参数越多的层，造成过拟合的可能性通常更大。</li><li>Dropout函数在计算机视觉领域应用相对较多。</li><li>只有在模型过拟合的时候才考虑使用Dropout函数。</li><li>缺点是在使用了Dropout函数后，代价函数J不再能够被明确的定义。每次迭代中会随机删除一些节点。此时，我们很难进行调试验证。因此，我们通常建议先将keep_prob设置为1，进行调试，保证代价函数单调递减时，再开启Dropout层进行训练。</li></ul><h2 id="3-优化算法"><a href="#3-优化算法" class="headerlink" title="3. 优化算法"></a>3. 优化算法</h2><h3 id="3-1-Mini-batch-梯度下降法"><a href="#3-1-Mini-batch-梯度下降法" class="headerlink" title="3.1 Mini-batch 梯度下降法"></a>3.1 Mini-batch 梯度下降法</h3><p>对整个训练集进行梯度下降法的时候，我们必须处理整个训练数据集，然后才能进行一步梯度下降，即每一步梯度下降法需要对整个训练集进行一次处理，如果训练数据集很大的时候，如有500万或5000万的训练数据，处理速度就会比较慢。</p><p>但是如果每次处理训练数据的一部分，即用其子集进行梯度下降，则我们的算法速度会执行的更快。而处理的这些一小部分训练子集即称为Mini-batch。</p><p>对于普通的梯度下降法，一个epoch只能进行一次梯度下降；而对于Mini-batch梯度下降法，一个epoch可以进行Mini-batch的个数次梯度下降。</p><p><strong>不同size大小的比较</strong><br>普通的batch梯度下降法和Mini-batch梯度下降法代价函数的变化趋势，如下图所示：</p><p><img src= "/img/loading.gif" data-src="/2019/05/25/NN/1558793481124.png" alt="Alt text"></p><ul><li>batch梯度下降：</li></ul><ol><li>对所有m个训练样本执行一次梯度下降，每一次迭代时间较长；</li><li>Cost function 总是向减小的方向下降。</li></ol><ul><li>随机梯度下降：</li></ul><ol><li>对每一个训练样本执行一次梯度下降，但是丢失了向量化带来的计算加速；</li><li>Cost function总体的趋势向最小值的方向下降，但是无法到达全局最小值点，呈现波动的形式。</li></ol><ul><li>Mini-batch梯度下降：</li></ul><ol><li>选择一个 1&lt;size&lt;m 的合适的size进行Mini-batch梯度下降，可以实现快速学习，也应用了向量化带来的好处；</li><li>Cost function的下降处于前两者之间。</li></ol><ul><li>Mini-batch 大小的选择：</li></ul><ol><li>如果训练样本的大小比较小时，如 m\leqslant 2000 时 ——— 选择batch梯度下降法；</li><li>如果训练样本的大小比较大时，典型的大小为： $2^{6}、2^{7}、\cdots、2^{10} $；</li><li>Mini-batch的大小要符合CPU/GPU内存。</li></ol><h3 id="3-2-动量（Momentum）梯度下降法"><a href="#3-2-动量（Momentum）梯度下降法" class="headerlink" title="3.2 动量（Momentum）梯度下降法"></a>3.2 动量（Momentum）梯度下降法</h3><p>动量梯度下降的基本思想就是计算梯度的指数加权平均数，并利用该梯度来更新权重。</p><p>在我们优化 Cost function 的时候，以下图所示的函数图为例：</p><p><img src= "/img/loading.gif" data-src="/2019/05/25/NN/1558793488590.png" alt="Alt text"></p><p>在利用梯度下降法来最小化该函数的时候，每一次迭代所更新的代价函数值如图中蓝色线所示在上下波动，而这种幅度比较大波动，减缓了梯度下降的速度，而且我们只能使用一个较小的学习率来进行迭代。</p><p>如果用较大的学习率，结果可能会如紫色线一样偏离函数的范围，所以为了避免这种情况，只能用较小的学习率。</p><p>但是我们又希望在如图的纵轴方向梯度下降的缓慢一些，不要有如此大的上下波动，在横轴方向梯度下降的快速一些，使得能够更快的到达最小值点，而这里用动量梯度下降法既可以实现，如红色线所示。</p><p><strong>算法实现:</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/NN/1558793493870.png" alt="Alt text"></p><p>$\beta$ 常用的值是0.9。</p><p>在我们进行动量梯度下降算法的时候，由于使用了指数加权平均的方法。原来在纵轴方向上的上下波动，经过平均以后，接近于0，纵轴上的波动变得非常的小；但在横轴方向上，所有的微分都指向横轴方向，因此其平均值仍然很大。最终实现红色线所示的梯度下降曲线。</p><h3 id="3-3-RMSprop"><a href="#3-3-RMSprop" class="headerlink" title="3.3 RMSprop"></a>3.3 RMSprop</h3><p>除了上面所说的Momentum梯度下降法，RMSprop（root mean square prop）也是一种可以加快梯度下降的算法。<br>$S_{dw}=βS_{dw}+(1-β)dw^2$<br>$S_{db}=βS_{db}+(1-β)db^2$<br>$w:=w-α\frac{dw}{\sqrt{S_{dw}}}$<br>$b:=b-α\frac{db}{\sqrt{S_{db}}}$<br>这里假设参数b的梯度处于纵轴方向，参数w的梯度处于横轴方向（当然实际中是处于高维度的情况），利用RMSprop算法，可以减小某些维度梯度更新波动较大的情况，如图中蓝色线所示，使其梯度下降的速度变得更快，如图绿色线所示。</p><p>在如图所示的实现中，RMSprop将微分项进行平方，然后使用平方根进行梯度更新，同时为了确保算法不会除以0，平方根分母中在实际使用会加入一个很小的值如$ \varepsilon=10^{-8}$ 。</p><h3 id="3-4-Adam-优化算法"><a href="#3-4-Adam-优化算法" class="headerlink" title="3.4  Adam 优化算法"></a>3.4  Adam 优化算法</h3><p>Adam （Adaptive Moment Estimation）优化算法的基本思想就是将 Momentum 和  RMSprop 结合起来形成的一种适用于不同深度学习结构的优化算法。<br><strong>算法实现：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/NN/1558793508697.png" alt="Alt text"></p><p><strong>超参数的选择：</strong></p><ul><li>$\alpha$ ：需要进行调试；</li><li>$\beta_{1}$ ：常用缺省值为0.9，$ dw $的加权平均；</li><li>$\beta_{2}$ ：推荐使用0.999， $dw^{2} $的加权平均值；</li><li>$\varepsilon$ ：推荐使用 $10^{-8} $。</li></ul><h3 id="3-5-学习率衰减"><a href="#3-5-学习率衰减" class="headerlink" title="3.5 学习率衰减"></a>3.5 学习率衰减</h3><p>在我们利用 mini-batch 梯度下降法来寻找Cost  function的最小值的时候，如果我们设置一个固定的学习速率$ \alpha$ ，则算法在到达最小值点附近后，由于不同batch中存在一定的噪声，使得不会精确收敛，而一直会在一个最小值点较大的范围内波动，如下图中蓝色线所示。</p><p>但是如果我们使用学习率衰减，逐渐减小学习速率$ \alpha$ ，在算法开始的时候，学习速率还是相对较快，能够相对快速的向最小值点的方向下降。但随着 $\alpha $的减小，下降的步伐也会逐渐变小，最终会在最小值附近的一块更小的区域里波动，如图中绿色线所示。<br><img src= "/img/loading.gif" data-src="/2019/05/25/NN/1558793517430.png" alt="Alt text"></p><p><strong>学习率衰减的实现</strong></p><ul><li>常用：$ \alpha = \dfrac{1}{1+decay_rate*epoch_num}\alpha_{0} $</li><li>指数衰减： $decayed$_ $learning$_ $rate$ = $learning$_ $rate$ $*$ $decay$_ $rate^{(global-step/decay-step)}$</li><li>其他： $\alpha = \dfrac{k}{epoch_num}\cdot\alpha_{0} $</li><li>离散下降（不同阶段使用不同的学习速率）</li></ul><h2 id="4-VANISHING-AND-EXPLODING-GRADIENTS"><a href="#4-VANISHING-AND-EXPLODING-GRADIENTS" class="headerlink" title="4. VANISHING AND EXPLODING GRADIENTS"></a>4. VANISHING AND EXPLODING GRADIENTS</h2><p>Dealing with the vanishing gradients problem is still an open research question<br><strong>Solutions include:</strong> </p><ul><li>making the networks shallower,</li><li>step-wise training(first train the first layers based on some auxiliary output signal, then fix them and train the upper layers of the complete network based on the real task signal)</li><li>performing batch-normalization<br>(for every minibatch, normalizing the inputs to each of the network<br>layers to have zero mean and unit variance) </li><li>using specialized architectures that are designed to<br>assist in gradient flow (e.g., the LSTM and GRU architectures for recurrent networks. </li><li>Dealing with the exploding gradients has a simple but very effective solution: clipping the gradients if their norm exceeds a given threshold.<br><img src= "/img/loading.gif" data-src="/2019/05/25/NN/1558793524763.png" alt="Alt text"></li></ul><h2 id="5-各类激活函数"><a href="#5-各类激活函数" class="headerlink" title="5. 各类激活函数"></a>5. 各类激活函数</h2><blockquote><p>Layers with tanh and sigmoid activations can become saturated—resulting in output values for that layer that are all close to one, the upper-limit of the activation function. Saturated neurons have very small gradients, and should be avoided. Layers with the ReLU activation cannot be saturated, but can “die”—most or all values are negative and thus clipped at zero for all inputs, resulting in a gradient of zero for that layer. If your network does not train well, it is advisable to monitor the network for layers with many saturated or dead neurons. Saturated neurons are caused by too large values entering the layer. This may be controlled for by changing the initialization, scaling the range of the input values, or changing the learning rate. Dead neurons are caused by all signals entering the layer being negative (for example this can happen after a large gradient update)</p></blockquote><h2 id="6-Normalizing-activations-in-a-network"><a href="#6-Normalizing-activations-in-a-network" class="headerlink" title="6. Normalizing activations in a network"></a>6. Normalizing activations in a network</h2><h3 id="6-1-原理"><a href="#6-1-原理" class="headerlink" title="6.1 原理"></a>6.1 原理</h3><p>Sergey Ioffe和Christian Szegedy两位学者提出了Batch Normalization方法。Batch Normalization不仅可以让调试超参数更加简单，而且可以让神经网络模型更加“健壮”。也就是说较好模型可接受的超参数范围更大一些，包容性更强，使得更容易去训练一个深度神经网络。</p><p>训练神经网络时，标准化输入可以提高训练的速度。方法是对训练数据集进行归一化的操作，即将原始数据减去其均值μ后，再除以其方差σ2。但是标准化输入只是对输入进行了处理，那么对于神经网络，又该如何对各隐藏层的输入进行标准化处理呢？</p><p>其实在神经网络中，第l层隐藏层的输入就是第l−1层隐藏层的输出A[l−1]。对A[l−1]进行标准化处理，从原理上来说可以提高W[l]和b[l]的训练速度和准确度。这种对各隐藏层的标准化处理就是Batch Normalization。值得注意的是，实际应用中，一般是对Z[l−1]进行标准化处理而不是A[l−1]，其实差别不是很大。</p><p>Batch Normalization对第l层隐藏层的输入$Z^{[l−1]}$做如下标准化处理，忽略上标[l−1]:</p><p>$\mu=\frac1m\sum_iz^{(i)}$<br>$\sigma^2=\frac1m\sum_i(z_i-\mu)^2$<br>$z^{(i)}_{norm}=\frac{z^{(i)}-\mu}{\sqrt{\sigma^2+\varepsilon}}$</p><p>其中，m是单个mini-batch包含样本个数，$ε$是为了防止分母为零，可取值$10^{−8}$。这样，使得该隐藏层的所有输入$z^{(i)}$均值为0，方差为1。</p><p>但是，大部分情况下并不希望所有的$z^{(i)}$均值都为0，方差都为1，也不太合理。通常需要对$z^{(i)}$进行进一步处理:<br>$\tilde z^{(i)}=\gamma\cdot z^{(i)}_{norm}+\beta$</p><p>上式中，$γ$和$β$是learnable parameters，类似于W和b一样，可以通过梯度下降等算法求得。这里，γ和β的作用是让 $\tilde z^{(i)}$ 的均值和方差为任意值，只需调整其值就可以了。例如，令：<br>$\gamma=\sqrt{\sigma^2+\varepsilon},  \beta=u$<br>则$\tilde z^{(i)}=z^{(i)}$, 即identity function。可见，设置γ和β为不同的值，可以得到任意的均值和方差。</p><p>这样，通过Batch Normalization，对隐藏层的各个$z^{<a href="i">l</a>}$进行标准化处理，得到$\tilde z^{<a href="i">l</a>}$，替代$z^{<a href="i">l</a>}$。</p><h3 id="6-2-Fitting-Batch-Norm-into-a-neural-network"><a href="#6-2-Fitting-Batch-Norm-into-a-neural-network" class="headerlink" title="6.2 Fitting Batch Norm into a neural network"></a>6.2 Fitting Batch Norm into a neural network</h3><p>我们已经知道了如何对某单一隐藏层的所有神经元进行Batch Norm，接下来将研究如何把Bath Norm应用到整个神经网络中。</p><p>对于L层神经网络，经过Batch Norm的作用，整体流程如下：<br><img src= "/img/loading.gif" data-src="/2019/05/25/NN/1558793537077.png" alt="Alt text"></p><p>实际上，Batch Norm经常使用在mini-batch上，这也是其名称的由来。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PIL缩放切图,抗锯齿</title>
      <link href="/2019/05/25/PIL/"/>
      <url>/2019/05/25/PIL/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>PIL图像处理函数介绍.</strong><br><a id="more"></a></p><p>&#160; &#160; &#160;使用<strong>PIL</strong>中的<strong>resize</strong> 对图片进行缩放的时候，发现缩放过小会造成图片失真，通过查找资料发现在<strong>resize</strong>函数中还有一个参数叫：<strong>Image.ANTIALIAS</strong>，发现<strong>PIL</strong>带<strong>ANTIALIAS</strong>滤镜缩放结果，对图片的缩放有抗锯齿的作用，在此贴出小代码实验一下（上面是不加抗锯齿，下面是加上抗锯齿）：<br><img src= "/img/loading.gif" data-src="/2019/05/25/PIL/a.png" alt><br><img src= "/img/loading.gif" data-src="/2019/05/25/PIL/b.png" alt><br><img src= "/img/loading.gif" data-src="/2019/05/25/PIL/c.png" alt><br><img src= "/img/loading.gif" data-src="/2019/05/25/PIL/d.png" alt><br>&#160; &#160; &#160;代码如下：<br>```</p><pre><code>#_*_ coding:utf-8 _*_&quot;&quot;&quot;@author:Stoner@time:2018/5/1918:52&quot;&quot;&quot;from PIL import Imageimport matplotlib.pyplot as plt</code></pre></blockquote><pre><code>img = Image.open(&#39;data/2.JPG&#39;)img1 = img.resize((200,200))plt.figure(1)plt.imshow(img1)plt.show()plt.figure(2)img2 = img.resize((200,200),Image.ANTIALIAS)plt.imshow(img2)plt.show()</code></pre><p>```</p><blockquote><p>&#160; &#160; &#160;参考链接：<br>&#160; &#160; &#160;1. <a href="https://blog.csdn.net/u013378306/article/details/70156842" target="_blank" rel="noopener">python PIL 图像处理 （二）</a><br>&#160; &#160; &#160;2. <a href="https://www.cnblogs.com/hzm112567/p/4155167.html" target="_blank" rel="noopener">Python高质量缩放切图,抗锯齿</a><br>&#160; &#160; &#160;3. <a href="http://www.cnblogs.com/RChen/archive/2007/03/31/pil_thumb.html" target="_blank" rel="noopener">用 PIL 写了个简单的缩略图生成程序</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PIL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>WGAN的相关链接</title>
      <link href="/2019/05/25/WGAN/"/>
      <url>/2019/05/25/WGAN/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>Wasserstein GAN的相关链接.</strong><br><a id="more"></a></p><p>&#160; &#160; &#160;1. <a href="http://www.atyun.com/7470.html" target="_blank" rel="noopener">GANs实现：比较生成对抗网络（无需择优挑选）</a><br>&#160; &#160; &#160;2. <a href="https://twistedw.github.io/2018/02/02/WGAN-GP.html" target="_blank" rel="noopener">WGAN-GP(改进的WGAN)介绍</a><br>&#160; &#160; &#160;3. <a href="https://ewanlee.github.io/2017/07/18/WGAN-GP/" target="_blank" rel="noopener">WGAN-GP [Repost]</a><br>&#160; &#160; &#160;4. <a href="http://lotabout.me/2018/WGAN/" target="_blank" rel="noopener">WGAN 笔记</a><br>&#160; &#160; &#160;5. <a href="http://friskit.me/2017/07/10/ntu-gan-wgan/" target="_blank" rel="noopener">再读WGAN（重点）</a><br>&#160; &#160; &#160;6. <a href="https://www.jianshu.com/p/32e164883eab" target="_blank" rel="noopener">记录一次与大神们的关于GAN应用于NLP的讨论</a><br>&#160; &#160; &#160;7. <a href="https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html" target="_blank" rel="noopener">From GAN to WGAN</a><br>&#160; &#160; &#160;8. <a href="https://kexue.fm/archives/4439" target="_blank" rel="noopener">互怼的艺术：从零直达WGAN-GP</a><br>&#160; &#160; &#160;9. <a href="https://zhuanlan.zhihu.com/p/25168509" target="_blank" rel="noopener">GAN for NLP (论文笔记及解读)</a><br>&#160; &#160; &#160;10. <a href="https://blog.csdn.net/sinat_26917383/article/details/54233599" target="_blank" rel="noopener">GAN︱生成模型学习笔记（运行机制、NLP结合难点、应用案例、相关Paper）</a><br>&#160; &#160; &#160;11. <a href="http://nooverfit.com/wp/%E7%8B%AC%E5%AE%B6%EF%BD%9Cgan%E5%A4%A7%E7%9B%98%E7%82%B9%EF%BC%8C%E8%81%8A%E8%81%8A%E8%BF%99%E4%BA%9B%E5%B9%B4%E7%9A%84%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C-lsgan-wgan-cgan-info/" target="_blank" rel="noopener">独家 | GAN大盘点，聊聊这些年的生成对抗网络 : LSGAN, WGAN, CGAN, infoGAN, EBGAN, BEGAN, VAE</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 生成对抗网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Wasserstein GAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu的一些基本用法</title>
      <link href="/2019/05/25/Ubuntu-use/"/>
      <url>/2019/05/25/Ubuntu-use/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>总结一些Ubuntu的简单用法.</strong><br><a id="more"></a></p></blockquote><h2 id="1-相关简单操作"><a href="#1-相关简单操作" class="headerlink" title="1. 相关简单操作"></a>1. 相关简单操作</h2><blockquote><p>1.下载软件：<br>&#160; &#160; &#160; <strong>sudo apt-get install xxx(软件名)</strong></p><p>2.返回上一级目录：<br>&#160; &#160; &#160; <strong>cd ..</strong><br>&#160; &#160; &#160; 如果要返回上上一级目录：<br>&#160; &#160; &#160; <strong>cd ../../</strong></p><p> 3.浏览某个文件夹下面的文件：<br>&#160; &#160; &#160; <strong>ls</strong>,其中文件夹是<strong>蓝色</strong>的，文件是<strong>白色</strong>的<br>&#160; &#160; &#160; 如果要显示文件或者文件夹的全部信息，则：<br>&#160; &#160; &#160; <strong>ls -l</strong><br>&#160; &#160; &#160;其中<strong>-rw-rw-r—</strong>代表文件的权限</p><p> 4.创建文件：<br>&#160; &#160; &#160; <strong>touch file1 file2</strong> ，这里同时创建多个文件</p><p>5.复制文件：<br>&#160; &#160; &#160;<strong>cp oldfile newfile </strong><br>&#160; &#160; &#160;如果上面的语句重复执行的话会将新之前创建好的<strong>newfile</strong>给复写掉，为了避免这种情况，可以使用：<br>&#160; &#160; &#160;<strong>cp -i oldfile newfile</strong>，执行之后它会提示你是否<strong>overwrite</strong>，你可以选择<strong>Yes</strong>、<strong>Y</strong>、<strong>y</strong>或者<strong>yes</strong>，如果选择<strong>no</strong>或者回车，则代表不复写<br>&#160; &#160; &#160;如果你要选择将一个文件夹复制到另一个文件夹：<br>&#160; &#160; &#160;<strong>cp -R folder1 folder2</strong>，其中<strong>R</strong>代表递归，也就是一次次将<strong>folder1</strong>文件夹中的文件复制到<strong>folder2</strong>这个文件夹中去，另一个需要注意的语句是：<br>&#160; &#160; &#160;<strong>cp file* folder1/</strong>，代表将所有以<strong>file</strong>开头的文件都复制到<strong>folder1</strong>文件夹中去，相应的如果是以某个名字结尾的文件则：<strong>*name</strong></p><p> 6.剪切文件：<br>&#160; &#160; &#160;<strong>mv file2 folder2/</strong><br>&#160; &#160; &#160;除此之外，还可以通过<strong>mv</strong>修改文件名字：<strong>mv file3 xxxxx</strong></p><p>  7.创建文件夹：<br>&#160; &#160; &#160;<strong>mkdir folder3</strong></p><p>   8.移除文件夹(空的)：<br>&#160; &#160; &#160;<strong>rmdir folder3/f3</strong>，需要注意的是如果<strong>f3</strong>文件夹中还有文件的话是不能移除这个文件夹的</p><p>   9.删除文件：<br>&#160; &#160; &#160;<strong>rm -i file1</strong>，其中<strong>-i</strong>是因为如果使用<strong>rm</strong>语句删除文件是不会有提示的，所以避免删除了重要文件，需要加上<strong>-i</strong>以给出提示；除此之外，如果你要删除多个文件的时候可以使用<strong>rm -I f1 f2 f3</strong>代表的意思是如果删除的文件小于等于三个就不给提示，否则就要给出提示；如果<strong>rm -r folder3</strong>代表删除包含文件的文件夹</p><p>   10.编辑文件：<br>&#160; &#160; &#160;<strong>①nano filename</strong>编辑文件，其中<strong>ctrl + 某个提示键</strong>就是<strong>nano</strong>中的操作符<br>&#160; &#160; &#160;<strong>②cat filename</strong>显示文件中的内容，如果使用<strong>cat filename &gt; file2</strong>代表将<strong>filename</strong>这个文件的内容放在<strong>file2</strong>中，如果没有后面这个文件，则它会帮你创建一个这个名字的文件；<strong>cat file1 file2 &gt; file3</strong>将前两个文件的内容放入到第三个文件中，例如：数据合并的时候使用；如果<strong>cat file3 &gt;&gt; file2</strong>代表将<strong>file3</strong>的内容加到<strong>file2</strong>中</p><p>   11.<strong>Linux</strong>文件权限：<br>   <img src= "/img/loading.gif" data-src="/2019/05/25/Ubuntu-use/a.png" alt><br>   [谁]<br>&#160; &#160; &#160;u: 对于 User 修改<br>&#160; &#160; &#160;g: 对于 Group 修改<br>&#160; &#160; &#160;o: 对于 Others 修改<br>&#160; &#160; &#160;a: (all) 对于所有人修改<br>[怎么修改]<br>&#160; &#160; &#160;+, -, =: 作用的形式, 加上, 减掉, 等于某些权限<br>&#160; &#160; &#160;r, w, x 或者多个权限一起, 比如 rx<br>[哪个文件]<br>&#160; &#160; &#160;施加操作的文件, 可以为多个</p><ul><li><strong>Type</strong>: 很多种 (最常见的是 <strong>-</strong> 为文件, <strong>d</strong> 为文件夹, 其他的还有<strong>l, n …</strong> 这种东西,真正自己遇到了, 网上再搜就好, 一次性说太多记不住的).</li><li><strong>User</strong>: 后面跟着的三个空是使用 <strong>User</strong> 的身份能对这个做什么处理 (<strong>r</strong>能读; <strong>w</strong> 能写; <strong>x</strong> 能执行; <strong>-</strong> 不能完成某个操作).</li><li><strong>Group</strong>: 一个 <strong>Group</strong> 里可能有一个或多个 <strong>user</strong>, 这些权限的样式和 <strong>User</strong> 一样.<br> <strong>Others</strong>: 除了 <strong>User</strong> 和 <strong>Group</strong> 以外人的权限.<br>&#160; &#160; &#160;如果有朋友对 <strong>User</strong>, <strong>group</strong>, <strong>others</strong> 这几个没什么概念的话, 我这里补充一下. <strong>User</strong> 一般就是指你, 这个正在使用电脑的人. <strong>Group</strong> 是一个 <strong>User</strong> 的集合, 最开始创建新 <strong>User</strong> 的时候, 他也为这个 <strong>User</strong> 创建了一个和 <strong>User</strong> 一样名字的 <strong>Group</strong>, 这个新 <strong>Group</strong> 里只有这个 <strong>User</strong>. 一般来说, 像一个企业部门的电脑, 都可以放在一个 <strong>Group</strong> 里, 分享了一些共享文件和权限. <strong>Others</strong> 就是除了上面提到的 <strong>User</strong> 和 <strong>Group</strong> 以外的人.<br>&#160; &#160; &#160;如果需要更改文件的权限，则形式如：<strong>chmod [谁][怎么修改] [哪个文件]</strong>，例如：<strong>chmod u+r t1.py</strong>这里代表增加可读权限<strong>r</strong>,如果使用<strong>chomd u-r t.py</strong>则代表减少<strong>t.py</strong>的可读权限，如果是其他人，则是<strong>o</strong>;如果想给所有人修改权限，则<strong>chmod a+r t.py</strong>；如果想给其中某两个人加上权限，则<strong>chmod ug+r t.py</strong></li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> Ubuntu </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Ubuntu </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>numpy的一维线性插值函数</title>
      <link href="/2019/05/25/linear-interpolation/"/>
      <url>/2019/05/25/linear-interpolation/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>Numpy中线性插值算法的总结.</strong><br><a id="more"></a></p><p>前言：<br>&#160; &#160; &#160;在用<strong>生成对抗网络</strong>生成二维数据点的时候遇到代码里的一个问题，就是<strong>numpy</strong>中的一维线性插值函数<strong>interp</strong>到底是怎么用的，在这个上面费了点功夫，因此现将其用法给出。<br>&#160; &#160; &#160;在<strong>生成对抗网络</strong>的二维样本生成的例子中，涉及了一维线性插值，代码里使用的是：</p><pre><code>numpy.interp(x, xp, fp, left=None, right=None, period=None)</code></pre><p>上网查了百度和谷歌发现都没有具体的中文的解释，只有官方的英文解释：<br>$One-dimensional$ $linear$ $interpolation.$ $Returns$ $the$ $one-dimensional$ $piecewise$ $linear$ $interpolant$ $to$ $a$ $function$ $with$ $given$ $values$ $at$ $discrete$ $data-points.$<br>官方给出的例子如下：<br>```</p><blockquote><blockquote><p>xp = [1, 2, 3]<br>fp = [3, 2, 0]<br>np.interp(2.5, xp, fp)<br>1.0<br>np.interp([0, 1, 1.5, 2.72, 3.14], xp, fp)<br>array([ 3. ,  3. ,  2.5 ,  0.56,  0. ])<br>UNDEF = -99.0<br>np.interp(3.14, xp, fp, right=UNDEF)<br>-99.0</p></blockquote></blockquote></blockquote><p>Plot an interpolant to the sine function:</p><blockquote><blockquote><blockquote><p>x = np.linspace(0, 2<em>np.pi, 10)<br>y = np.sin(x)<br>xvals = np.linspace(0, 2</em>np.pi, 50)<br>yinterp = np.interp(xvals, x, y)<br>import matplotlib.pyplot as plt<br>plt.plot(x, y, ‘o’)<br>[<matplotlib.lines.Line2D object at 0x...>]<br>plt.plot(xvals, yinterp, ‘-x’)<br>[<matplotlib.lines.Line2D object at 0x...>]<br>plt.show()<br>```<br>其中对于第一例子，只要画出图像就很好理解了：<br><img src= "/img/loading.gif" data-src="/2019/05/25/linear-interpolation/a.png" alt><br>也就是说只要参数中的$2.5$是我们要插入的值，我们要做的是连接$(2,2)$和$(3,0)$这两个点，然后在$x=2.5$这里做垂线，那么相交的那个点(也就是$(2.5,1.0)$这个点)就是我们要插入的点了。</matplotlib.lines.Line2D></matplotlib.lines.Line2D></p></blockquote></blockquote></blockquote>]]></content>
      
      
      <categories>
          
          <category> Numpy </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 线性插值 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAN的一些小细节汇总</title>
      <link href="/2019/05/25/Generative-Adversarial-Nets/"/>
      <url>/2019/05/25/Generative-Adversarial-Nets/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>对生成对抗网络中的一些需要注意的小细节进行汇总.</strong><br><a id="more"></a></p></blockquote><h2 id="1-GAN需要注意的一些小细节"><a href="#1-GAN需要注意的一些小细节" class="headerlink" title="1. GAN需要注意的一些小细节"></a>1. GAN需要注意的一些小细节</h2><p><strong>1.1  问题：</strong></p><blockquote><p>① 为何<strong>Generator</strong>不自己学呢？为何非得要通过<strong>Discriminator</strong>才能学习如何生成东西？<br>② <strong>Discriminator</strong>这么厉害得能分辨图片真伪，为何不能自己去生成图像(而是自己像老师一样只会指导)？</p></blockquote><p><strong>1.2  update Generator</strong>的时候需要<strong>fix</strong>住<strong>Discriminator</strong>是因为，升级生成器是为了让判别器输出尽量高的值，如果不固定住判别器的话，可能只需要调节判别器的参数就可以让分数爆表，但是这是没有意义的，所以，需要固定住判别器，这样才能通过训练生成器的参数，让生成器尽量产生质量好的图片，才能达到目标。</p><p><strong>1.3  EBGAN</strong>假设就是某一张<strong>image</strong>它可以被<strong>reconstruction</strong>得越好，它的<strong>reconstruction error</strong>越低就代表它是一个<strong>high quality</strong>的<strong>image</strong>，反之，<strong>reconstruction error</strong>越高代表越难被<strong>reconstruction</strong>，代表是<strong>low quality</strong>。</p><p><strong>1.4  EBGAN</strong>的好处是:自编码器可以被真实数据预训练而不需要<strong>negative sample</strong>，对于一般的<strong>Discriminator</strong>(是<strong>binary classifier</strong>)是需要<strong>positive sample</strong>和<strong>negative sample</strong>(由生成器生成)的，所以预训练<strong>EBGAN</strong>的<strong>Discriminator</strong>(是自编码器)是不需要<strong>negative sample</strong>的，也就是预训练不需要生成器。所以一般的<strong>GAN</strong>的问题在于<strong>Discriminator</strong>无法预训练，所以一开始的<strong>Generator</strong>很弱，所以生成的<strong>negative sample</strong>也很弱，这也就只能<strong>learn</strong>出来很弱的<strong>Discriminator</strong>，而<strong>Discriminator</strong>只有等<strong>Generator</strong>变强以后它才能慢慢变强，所以一开始的<strong>Discriminator</strong>不会很强，需要<strong>train</strong>很久才慢慢变强；而<strong>EBGAN</strong>的<strong>Discriminator</strong>是<strong>Autoencoder</strong>，可以预训练，你只要给它<strong>positive sample</strong>，让它去<strong>minimize reconstruction error</strong>就好了，所以要使用<strong>EBGAN</strong>就需要预训练<strong>Autoencoder</strong>，这样你的<strong>Discriminator</strong>一开始就很强，那你的<strong>Generator</strong>一开始就能生成很好的<strong>image</strong></p><p><strong>1.5  maximize likelihood == minimize cross entropy</strong></p><hr><h2 id="2-GAN-evaluation"><a href="#2-GAN-evaluation" class="headerlink" title="2. GAN evaluation"></a>2. GAN evaluation</h2><p><strong>2.1</strong> 怎么衡量一个<strong>Generator</strong>？<br> <strong>①传统的方式：</strong></p><blockquote><p>算<strong>Generator</strong>产生<strong>data</strong>的<strong>likelihood</strong>，也就是说已经<strong>learn</strong>了一个<strong>Generator</strong>后，给它一些<strong>real</strong>的<strong>data</strong>(例如产生<strong>image</strong>，那就丢给<strong>Generator</strong>没有看过的<strong>real image</strong>), 然后计算<strong>Generator</strong>产生这些<strong>image</strong>的几率：<br>$Log$ $Likelihood : L = \frac{1}{N} \sum_{i} log P_G(x^i)$<br>算出<strong>Generator</strong> $P_G$产生$x^i$这张<strong>image</strong>的几率，然后将这些<strong>real data</strong>(也就是<strong>testing data</strong>)的<strong>image</strong>的<strong>likelihood</strong>都算出来求和做平均就得到了一个<strong>likelihood</strong>，它就代表一个<strong>Generator</strong>的好坏<br><img src= "/img/loading.gif" data-src="/2019/05/25/Generative-Adversarial-Nets/a.png" alt><br>但是有<strong>network</strong>组成的<strong>Generator</strong>，要算它的<strong>likelihood</strong>是有困难的，如果是一个简单的例子比如高斯混合模型倒是可以算出它产生这个<strong>image</strong>的几率，只是因为它很简单，而<strong>network</strong>却不行，因为<strong>network</strong>无法求出具体的某一笔<strong>data</strong>的几率。</p></blockquote><p>②方法二：<strong>Kernel Density Estimation</strong></p><blockquote><p><strong>步骤：</strong><br>a. 通过<strong>Generator</strong>产生很多很多的<strong>data</strong><br>b. 再用一个<strong>Gaussian distribution</strong>去逼近你产生的<strong>data</strong>，也就说假设让你的<strong>Generator</strong>产生一大堆的<strong>Vector</strong>出来(假设你是产生的<strong>image</strong>的话)，然后你把这些<strong>vector</strong>当做<strong>Gaussian mixture model</strong>的<strong>mean</strong>，而每一个<strong>mean</strong>它有一个固定的<strong>covariance</strong>，然后让这些<strong>Guassian</strong>叠在一起，你就得到了一个<strong>Gaussian mixture model</strong>，有了这个<strong>Gaussian mixture model</strong>以后，你就可以去计算这个<strong>Gaussian mixture model</strong>产生<strong>real data</strong>的几率，你就可以估测出这个<strong>Generator</strong>它产生出那些<strong>real data</strong>的<strong>likelihood</strong>是多少。</p><p><strong>比较大的问题：</strong><br>a. 通过<strong>Gaussian</strong>去<strong>fit</strong>那个<strong>Generator</strong>的时候到底要几个<strong>Gaussian</strong>呢？(不知道，一大难题)<br>b. 你不知道<strong>Generator</strong>要<strong>sample</strong>多少个点才估得准它的<strong>distribution</strong>，所以这招在实作上也是有问题的，文献上有人做这一招，结果怪怪的，比如<strong>model</strong>算出来的<strong>likelihood</strong>比<strong>real data</strong>还要大。<br><img src= "/img/loading.gif" data-src="/2019/05/25/Generative-Adversarial-Nets/b.png" alt></p></blockquote><p>③就算真的想出了一个方法计算出了<strong>likelihood</strong>，但是<strong>likelihood</strong>本身也未必代表了你的<strong>Generator</strong>的<strong>quality</strong>，因为有可能：</p><ul><li>a.<strong>低的likelihood却有高的quality( Low likelihood, high quality)</strong>, 比方说：你的<strong>Generator</strong>产生了很高质量的清晰的图(比如都是高清的凉宫春日图片), 但是比方说其他人物的图像却从来不会生成，而你的<strong>testing data</strong>就是其他人物的图像，那你这时算<strong>likelihood</strong>的话就会很小，因为它从来不会产生其他人物的图，但是你又不能说它做的不好，因为它产生的图都是<strong>high quality</strong>的，只是<strong>test</strong>算出来的<strong>likelihood</strong>很小而已。</li><li>b. <strong>高的likelihood却有低的quality( High likelihood, low quality)</strong>，假设你今天能计算<strong>likelihood</strong>(虽然前面说了计算<strong>likelihood</strong>很难，但是假设你今天想到了某个方法可以计算)，现在你有一个很强的<strong>Generator1</strong>，它的<strong>likelihood</strong>很高；现在有另一个<strong>Generator2</strong>，它有<strong>99%</strong>的几率产生<strong>random noise</strong>，它有<strong>1%</strong>的几率产生产生和<strong>Generator1</strong>一样高质量的图像，那么如果<strong>Generator1</strong>产生某张图片的几率为$P_G(x^i)$，那么<strong>Generator2</strong>产生某张图片的几率就是$\frac{P_G(x^i)}{100}$，那么：<blockquote><p><strong>Generator1</strong> : $L = \frac{1}{N} \sum_{i} log P_G(x^i)$<br><strong>Generator2</strong>: $L = \frac{1}{N} \sum_{i} log \frac{P_G(x^i)}{100} = -log 100 + \frac{1}{N} \sum{i} log P_G(x^i)$<br>其中你会发现$-log 100$才$-4.6$而已，也就是两个生成器的<strong>likelihood</strong>相差不大，没啥差别，但是你看<strong>G1</strong>和<strong>G2</strong>比较的话，你会觉得<strong>G1</strong>比<strong>G2</strong>好<strong>100</strong>倍的，只是你看不出来而已，所以<strong>likelihood</strong>跟真正的<strong>Generator</strong>的能力未必是有关系的</p></blockquote></li></ul><p>④<strong>Objective Evaluation</strong></p><blockquote><p><strong>原则1：</strong><br>文献上常常看到的一种客观的<strong>evaluation</strong>的方法是拿一个已经<strong>train</strong>好的<strong>classifier</strong>来评价你现在产生出来的<strong>object</strong>，假设你今天产生出来的<strong>object</strong>是图像的话，那你就拿一个图像的<strong>classifier</strong>来判断这个<strong>object</strong>的好坏。<br><img src= "/img/loading.gif" data-src="/2019/05/25/Generative-Adversarial-Nets/c.png" alt></p><p><strong>原则2：</strong><br>如果<strong>classifier</strong>能分辨你产生的图片是哪一类，则说明你产生的图像是好的，除此之外，你还需要产生一把图像，丢给<strong>classifier</strong>，让它各自产生分布，然后取平均，如果这个平均后的<strong>distribution</strong>很<strong>uniform</strong>的话，那就意味着每一种不同的<strong>class</strong>都有被产生，代表你产生的<strong>output</strong>是比较<strong>diverse</strong>的。如果平均完之后发现某个<strong>class</strong>的分数很高，则代表你的<strong>model</strong>出现了<strong>model Dropping</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/Generative-Adversarial-Nets/d.png" alt><br>所以说好的<strong>Generator</strong>它产生的单一的图片丢到<strong>Classfier</strong>中某个<strong>Class</strong>越大越好(代表分类器认定生成的图像为真实图像，这里对应<strong>原则1</strong>)；然后把所有的<strong>Output</strong>丢到<strong>Classfier</strong>中，产生一堆的<strong>distribution</strong>，然后把所有的<strong>distribution</strong>做平均，它越<strong>uniform</strong>越好。</p><hr><p>有了上面这些原则之后和良好<strong>Generator</strong>的标准之后，你就可以定出一个<strong>score</strong>，一个常用的<strong>score</strong>叫做<strong>Inception Score</strong>，把上面两件事情考虑进去(<strong>Inception</strong>代表用的是卷积中的<strong>Inception Network</strong>来评估的)。</p><p><strong>Inception Score = </strong>$\sum_x \sum_y P(y|x)logP(y|x) - \sum P(y)logP(y)$<br>其中第一项$\sum \sum P(y|x)logP(y|x)$求和所有$x$，把每一个$x$丢到<strong>Classfier</strong>算出它的<strong>distribution</strong>，然后计算<strong>negative entropy of P(y|x)</strong>，其中<strong>negative entropy</strong>就是计算这个<strong>distribution</strong>够不够<strong>shape(?)</strong>，越<strong>shape(?)</strong>代表image越好。<br>同时$ - \sum P(y)logP(y)$就是把所有的<strong>distribution</strong>平均起来，如果所有平均的结果的<strong>entropy</strong>越大也代表越好。<br><img src= "/img/loading.gif" data-src="/2019/05/25/Generative-Adversarial-Nets/e.png" alt></p></blockquote><p>⑤<strong>需要注意的：</strong></p><blockquote><p>有时候就算你<strong>train</strong>出来的结果非常的清晰也并不代表结果是好的，因为你的<strong>Generator</strong>有可能是硬记住你的<strong>train data</strong>里面的某几张图像而已。那怎么知道你现在的<strong>GAN</strong>产生出来的东西是不是你的<strong>database</strong>里面已经现存的东西呢？<br><img src= "/img/loading.gif" data-src="/2019/05/25/Generative-Adversarial-Nets/f.png" alt><br><strong>Mode Dropping：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/Generative-Adversarial-Nets/g.png" alt></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生成对抗网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MNIST_SoftMax源码解析</title>
      <link href="/2019/05/25/mnist-softmax-xla/"/>
      <url>/2019/05/25/mnist-softmax-xla/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>TensorFlow官方mnist-softmax源码解析.</strong><br><a id="more"></a></p></blockquote><h2 id="1-主要知识点"><a href="#1-主要知识点" class="headerlink" title="1. 主要知识点"></a>1. 主要知识点</h2><p><img src= "/img/loading.gif" data-src="/2019/05/25/mnist-softmax-xla/1558795005992.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/mnist-softmax-xla/1558795012452.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/mnist-softmax-xla/1558795020424.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/mnist-softmax-xla/1558795025751.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/mnist-softmax-xla/1558795030917.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/mnist-softmax-xla/1558795036535.png" alt="Alt text"></p><blockquote><p>注意：$FLAGS$, $unparsed$ = $parser$.$parse$_$known$_$args()$与$parser$.$parser$_$args()$是一样的，其中FLAGS用于存放解析了的参数，而unparsed用于存放无法解析的参数，例如你如果添加了一些非法的参数使之无法解析。<br><img src= "/img/loading.gif" data-src="/2019/05/25/mnist-softmax-xla/1558795042166.png" alt="Alt text"></p><p>注意；如上图左边显示的，$FLAGS$成功解析了定义的参数，而$unparsed$显示空列表表明没有未成功解析的参数。<br><img src= "/img/loading.gif" data-src="/2019/05/25/mnist-softmax-xla/1558795051014.png" alt="Alt text"></p><p>注意：$argv[0]$代表$argvalue$</p></blockquote><h2 id="2-解析主函数做的事情"><a href="#2-解析主函数做的事情" class="headerlink" title="2. 解析主函数做的事情"></a>2. 解析主函数做的事情</h2><p><img src= "/img/loading.gif" data-src="/2019/05/25/mnist-softmax-xla/1558795056097.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/mnist-softmax-xla/1558795061662.png" alt="Alt text"></p><h3 id="3-启动会话前设置参数配置"><a href="#3-启动会话前设置参数配置" class="headerlink" title="3. 启动会话前设置参数配置"></a>3. 启动会话前设置参数配置</h3><p><img src= "/img/loading.gif" data-src="/2019/05/25/mnist-softmax-xla/1558795066723.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/mnist-softmax-xla/1558795070911.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/mnist-softmax-xla/1558795075581.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/mnist-softmax-xla/1558795080452.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/mnist-softmax-xla/1558795085831.png" alt="Alt text"></p><blockquote><p>$JIT$：$Just$ $in$ $time$————即时<br><img src= "/img/loading.gif" data-src="/2019/05/25/mnist-softmax-xla/1558795090746.png" alt="Alt text"></p></blockquote><p><img src= "/img/loading.gif" data-src="/2019/05/25/mnist-softmax-xla/1558795096936.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/mnist-softmax-xla/1558795102434.png" alt="Alt text"></p><blockquote><ul><li><strong>run_metadata.step_stats</strong>将其传入<strong>timeline</strong>中，就可以将信息写入<strong>json</strong>文件</li><li><strong>tf.RunOptions.FULL_TRACE</strong>代表追踪运行时的所有状态，也就是说一旦<strong>options</strong>将<strong>trace_level</strong>打开之后，运行时的信息就会被收集到<strong>RunMetadata</strong>里面返回给变量<strong>run_metadata</strong>。<br><img src= "/img/loading.gif" data-src="/2019/05/25/mnist-softmax-xla/1558795111471.png" alt="Alt text"></li></ul></blockquote><p><img src= "/img/loading.gif" data-src="/2019/05/25/mnist-softmax-xla/1558795117051.png" alt="Alt text"></p>]]></content>
      
      
      <categories>
          
          <category> TensorFlow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mnist </tag>
            
            <tag> softmax </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>XMM-Newton EPIC数据处理过程</title>
      <link href="/2019/05/25/xmm-newton-EPIC/"/>
      <url>/2019/05/25/xmm-newton-EPIC/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>XMM_Newton处理EPIC数据的过程以及相应脚本.</strong><br><a id="more"></a></p></blockquote><h2 id="1-运行环境以及相关简单情况"><a href="#1-运行环境以及相关简单情况" class="headerlink" title="1. 运行环境以及相关简单情况"></a>1. 运行环境以及相关简单情况</h2><blockquote><ol><li><strong>运行环境</strong>: <strong>Ubuntu 18.04</strong></li><li><strong>运行软件</strong>: <strong>Heasoft</strong> + <strong>SAS(XMM-Newton科学分析软件——$Science$ $Analysis$ $Software$)</strong></li><li><strong>相关文献与网址</strong>: </li></ol><ul><li>相关文献①：《<strong>活动星系核吸收盘模型与X射线观测研究 第二章</strong>》</li><li>相关文献②：《<strong>AN X-RAY PERIODCITY OF ~1.8 HOURS IN A NARROW-LINE SEYFERT 1 GALAXY MRK 766</strong>》</li><li>相关网址①：<a href="https://heasarc.gsfc.nasa.gov/docs/xmm/abc/node7.html" target="_blank" rel="noopener">XMM-Newton Analysis</a></li><li>相关网址②：<a href="https://www.cosmos.esa.int/web/xmm-newton/sas-threads" target="_blank" rel="noopener">XMM-Newton science operation center</a></li></ul></blockquote><h2 id="2-数据处理过程"><a href="#2-数据处理过程" class="headerlink" title="2. 数据处理过程"></a>2. 数据处理过程</h2><h3 id="2-1-处理数据前的操作"><a href="#2-1-处理数据前的操作" class="headerlink" title="2.1 处理数据前的操作"></a>2.1 处理数据前的操作</h3><blockquote><p><strong>具体操作过程如下:</strong><br>建立一个文件夹目录将某个源的某次观测数据存放其中，在该目录下分别创建以下几个文件夹：</p><ul><li><strong>odf: </strong> 用于存放下载的数据;</li><li><strong>work:</strong> 用于存放分析<strong>EPIC MOS</strong>数据时产生的文件;</li><li><strong>workpn:</strong> 存放分析<strong>EPIC pn</strong>数据时产生的文件.</li></ul><p>除此之外还要在数据文件夹下建立一个<strong>ccf</strong>文件夹用于存放<strong>.CCF</strong>文件. 如果还想处理<strong>RGS</strong>和<strong>OM</strong>数据则相应类似的创建<strong>rgs、om</strong>文件夹. </p></blockquote><h3 id="2-2-EPIC-pn数据处理"><a href="#2-2-EPIC-pn数据处理" class="headerlink" title="2.2 EPIC pn数据处理"></a>2.2 EPIC pn数据处理</h3><blockquote><p>将得到的数据放入<strong>odf</strong>文件夹中进行解压(确保<strong>ccf</strong>文件夹以放入<strong>.CCF</strong>文件以及<strong>work、workpn</strong>文件夹都已经创建)，首先是在<strong>odf</strong>文件夹下对数据进行初步处理(如果你的<strong>heasoft</strong>和<strong>sas</strong>以及安装完毕，则可以开始下面的步骤): </p><ol><li>开启终端：<code>Ctrl + Alt + T</code></li><li>进入<strong>odf</strong>文件夹：<code>cd ~/0304030601/odf/</code></li><li>初始化软件(这两个命令依次执行)：<code>heainit</code>；<code>sas</code></li><li>指定<strong>ODF</strong>的路径：<code>export SAS_ODF=~/0304030601/odf/</code></li><li>指定<strong>CCF(Current Calibration File)的路径</strong>(依次执行)：<br><code>export SAS_CCFPATH=~/ccf</code>；<br><code>export SAS_CCF=$SAS_CCFPATH</code></li><li>创建<strong>CIF</strong>文件(<strong>Calibration Index File</strong>)：<code>cifbuild</code>，运行完后会产生一个名字为<strong>ccf.cif</strong>的文件</li><li>设定<strong>CCF</strong>为<strong>CIF</strong>文件<strong>ccf.cif</strong>：<br><code>export SAS_CCF=~/0304030601/odf/ccf.cif</code></li><li>创建<strong>ODF</strong>里的<strong>summary</strong>文件：<br><code>odfingest outdir=$SAS_ODF odfdir=$SAS_ODF</code>，这个命令将产生一个以<strong>…SUM.SAS</strong>结尾的文件，包含了仪器信息和定标信息等。</li><li>进入<strong>workpn</strong>文件夹(<strong>MOS数据处理进入work文件夹</strong>)：<br><code>cd ~/0304030601/workpn</code></li><li>指定路径：<br><code>export SAS_ODF=~/0304030601/odf/</code><br><code>export SAS_CCF=~/0304030601/odf/ccf.cif</code><br>需要注意的是每次进入<strong>workpn</strong>目录下工作时都要指定<strong>odf</strong>和<strong>CCF</strong>的路径.</li><li>产生事例文件(<strong>events file</strong>)：需要注意的是<strong>Out-of-time</strong>事例对<strong>pn</strong>能谱和图像有影响，但是对于<strong>MOS</strong>的观测数据不需要考虑<strong>OoT</strong>事例的影响。要扣除<strong>OoT</strong>事例对<strong>pn</strong>的影响，需要事先产生观测数据和<strong>OoT</strong>两个文件，运行以下命令：<br><code>epchain withoutoftime=Y</code><br><code>epchain</code><br>前一个命令产生<strong>OoT</strong>事例文件。后一个命令产生观测数据事例文件，这两个命令会产生一堆命名很长的<strong>.FIT</strong>文件，其中对于<strong>pn</strong>我们需要名字为<strong>PIEVLI</strong>的<strong>.FIT</strong>文件，而<strong>MOS</strong>数据则需要<strong>MIEVLI</strong>的数据。</li><li>选取好时间段(<strong>GTI</strong>)，即去掉背景耀存在的时间段(时间并 <strong>timebinsize=100</strong>)：<br><code>evselect table=P0304030601PNS003PIEVLI0000.FIT withrateset=Y rateset=rateEPIC.fits maketimecolumn=Y timebinsize=100 timecolumn=TIME expression=&#39;#XMMEA_EP &amp;&amp; (PI&gt;10000&amp;&amp;PI&lt;12000) &amp;&amp; (PATTERN==0)&#39;</code><br>其中<strong>PI</strong>是能量，以<strong>eV</strong>为单位。对于<strong>MOS</strong>的数据，将 <strong>#XMMEA_EP</strong> 换为 <strong>#XMMEA_EM</strong>.</li><li>画出曲线：<code>dsplot table=rateEPIC1.fits x=TIME y=COUNTS &amp;</code></li><li>接下来选取判断背景耀发存在时对应的光子计数阈值，一般建议对于<strong>pn</strong>取光子小于等于 $1.0$ $cts/s$，对于<strong>MOS</strong>取光子计数率小于等于 $0.35$ $cts/s$(也可根据需要进行调整)，因为取得时间并 <strong>timebinsize</strong>为$100$ $s$，因此有如下：<br><code>tabgtigen table=rateEPIC.fits expression=&#39;COUNTS&lt;=100&#39; gtiset=EPICgti.fits</code><br>这样便生出了<strong>gti.fits</strong>文件了.</li><li>检验背景耀发是否已被出掉：<br><code>evselect table=P0304030601PNS003PIEVLI0000.FIT withrateset=Y rateset=ra_new.fits timecolumn=TIME maketimecolumn=Y timebinsize=100 expression=&#39;gti(EPICgti.fits,TIME) &amp;&amp; #XMMEA_EP &amp;&amp; (PI&gt;10000) &amp;&amp; (PATTERN==0)&#39;</code><br>需要注意的是，对于上面的命令行中<code>PATTERN==0</code>以及<code>PI&gt;10000</code>,对于不同情况都是不需要更改的，但是下面的命令行中对于不同情况，这两个值就需要改变了。</li><li>加入所需条件来筛选事例，例如光子能量范围在$0.2-10$ $keV$：<br><code>evselect table=P0304030601PNS003PIEVLI0000.FIT withfilteredset=Y filteredset=EPICclean.fits destruct=Y keepfilteroutput=T expression=&#39;gti(EPICgti.fits,TIME) &amp;&amp; (PI in [200:10000]) &amp;&amp; (PATTERN&lt;=4)&#39;</code><br>其中对于<strong>pn</strong>来说<code>(PATTERN&lt;=4)</code>,对于<strong>MOS</strong>来说<code>(PATTERN&lt;=12)</code>.</li><li>用<code>EPICclean.fits</code>成像：<br><code>evselect table=EPICclean.fits imagebinning=binSize imageset=image.fits withimageset=yes xcolumn=X ycolumn=Y ximagebinsize=80 yimagebinsize=80</code><br><code>ds9 image.fits  &amp;</code><br>记住，在选择源和背景区域的时候色阶要选择指数，选择的区域要根据要求来，尤其是背景区域。</li><li>生成源的光变曲线：<br><code>evselect table=EPICclean.fits expression=&#39;((X,Y) IN circle(25988.677,28010.001,800))&#39; withrateset=yes rateset=&quot;PN_source_lightcurve_raw.fits&quot; timebinsize=100 maketimecolumn=yes makeratecolumn=yes</code></li><li>生成背景的光变曲线：<br><code>evselect table=EPICclean.fits expression=&#39;((X,Y) IN circle(26890.776,24410.045,800))&#39; withrateset=yes rateset=&quot;PN_light_curve_background_raw.fits&quot; timebinsize=100 maketimecolumn=yes makeratecolumn=yes</code></li><li>修正光变曲线：<br><code>epiclccorr srctslist=PN_source_lightcurve_raw.fits eventlist=EPICclean.fits outset=PN_lccorr.fits bkgtslist=PN_light_curve_background_raw.fits withbkgset=yes applyabsolutecorrections=yes</code></li><li>对修正的光变曲线画图：<br><code>dsplot table=PN_lccorr.fits withx=yes x=TIME withy=yes y=RATE</code></li><li>整个<strong>pn</strong>生成光变曲线的命令行就是这些.</li></ol></blockquote><h3 id="2-3-EPIC-MOS数据处理"><a href="#2-3-EPIC-MOS数据处理" class="headerlink" title="2.3 EPIC MOS数据处理"></a>2.3 EPIC MOS数据处理</h3><blockquote><p>需要注意的是<strong>pn</strong>的操作和<strong>mos</strong>的操作很类似，所以下面直接上命令行：<br><strong>MOS1数据处理(MOS2与之基本一致，除了个别文件名或者参数不一样)</strong>：</p><p><code>1. heainit</code></p><p><code>2. sas</code></p><p><code>3. cd ~/0304030601/odf/</code></p><p><code>4. export SAS_ODF=~/0304030601/odf/</code></p><p><code>5. export SAS_CCFPATH=~/ccf</code></p><p><code>6. export SAS_CCF=$SAS_CCFPATH</code></p><p><code>7. cifbuild</code></p><p><code>8. export SAS_CCF=~/0304030601/odf/ccf.cif</code></p><p><code>9. odfingest outdir=$SAS_ODF odfdir=$SAS_ODF</code></p><p><code>10. cd ~/0304030601/work/</code></p><p><code>11. export SAS_ODF=~/0304030601/odf/</code></p><p><code>12. export SAS_CCF=~/0304030601/odf/ccf.cif</code></p><p><code>13. emchain</code></p><p><code>14. evselect table=P0304030601M1S001MIEVLI0000.FIT withrateset=Y rateset=rateEPIC1.fits maketimecolumn=Y timebinsize=100 makeratecolumn=Y expression=&#39;#XMMEA_EM &amp;&amp; (PI&gt;10000) &amp;&amp; (PATTERN==0)&#39;</code></p><p><code>15. dsplot table=rateEPIC1.fits x=TIME y=RATE</code></p><p><code>16. tabgtigen table=rateEPIC1.fits expression=&#39;RATE&lt;=3.5&#39; gtiset=EPICgti1.fits</code></p><p><code>17. evselect table=P0304030601M1S001MIEVLI0000.FIT withfilteredset=Y filteredset=EPICclean1.fits destruct=Y keepfilteroutput=T expression=&#39;#XMMEA_EM &amp;&amp; gti(EPICgti1.fits,TIME) &amp;&amp; (PI&gt;150)&#39;</code></p><p><code>18. evselect table=EPICclean1.fits imagebinning=binSize imageset=PNimage1.img withimageset=yes xcolumn=X ycolumn=Y ximagebinsize=80 yimagebinsize=80</code></p><p><code>19. evselect table=EPICclean1.fits energycolumn=PI expression=&#39;#XMMEA_EM &amp;&amp; (PATTERN&lt;=12) &amp;&amp; (PI in [200:10000]) &amp;&amp; ((X,Y) IN circle(25988.677,28010.001,800))&#39; withrateset=yes rateset=&quot;MOS1_source_lightcurve_raw.fits&quot; timebinsize=100 maketimecolumn=yes makeratecolumn=yes</code></p><p><code>20. evselect table=EPICclean1.fits energycolumn=PI expression=&#39;#XMMEA_EM &amp;&amp; (PATTERN&lt;=12) &amp;&amp; (PI in [200:10000]) &amp;&amp; ((X,Y) IN circle(25541.875,24565.094,800))&#39; withrateset=yes rateset=&quot;MOS1_light_curve_background_raw.fits&quot; timebinsize=100 maketimecolumn=yes makeratecolumn=yes</code></p><p> <code>21. epiclccorr srctslist=MOS1_source_lightcurve_raw.fits eventlist=EPICclean1.fits outset=MOS1_lccorr.fits bkgtslist=MOS1_light_curve_background_raw.fits withbkgset=yes applyabsolutecorrections=yes</code></p><p>  <code>22. dsplot table=MOS1_lccorr.fits withx=yes x=TIME withy=yes y=RATE</code></p><hr></blockquote><h2 id="3-pn-mos1-mos2三者合并的光变曲线"><a href="#3-pn-mos1-mos2三者合并的光变曲线" class="headerlink" title="3. pn + mos1 + mos2三者合并的光变曲线"></a>3. pn + mos1 + mos2三者合并的光变曲线</h2><blockquote><p>对于三者合并得到光变曲线的过程，其实就是将三者的<strong>RATE</strong>和<strong>YERROR</strong>进行合并，其中对于横坐标<strong>TIME</strong>，三者是一致的，只是如果要将区间设定为[0,100000]之间，则需要将三者所有的横坐标都减去第一个横坐标即可；而数据的导出有两种方式，一种是在<strong>Ubuntu</strong>的命令行中通过<code>fv PN_lcccorr.fits</code>方式从<strong>select</strong>选项中导出<strong>.txt</strong>文件可得到数据，还有一种方式是不需要导出数据，直接利用<strong>python</strong>的<strong>astropy.io</strong>下的<strong>.fits</strong>包可以直接导出，免去导出<strong>.txt</strong>文档的麻烦，这两种方式在下面代码中都包含了:<br>```<br>import numpy as np<br>import matplotlib.pyplot as plt<br>import pandas as pd<br>from astropy.io import fits # 利用python的此包可直接读取.fits文件<br>import seaborn as sns<br>sns.set_style(‘ticks’)</p></blockquote><h1 id="数据读取"><a href="#数据读取" class="headerlink" title="数据读取"></a>数据读取</h1><p>def data_reading(data_path,flag=2):</p><pre><code># flag标记用于确认读取数据的方式，如果为1，则 Pandas + .txt ;如果为2，则  astropy + .fits# 读取数据(方式1,读取由fv命令生成的图像所导出的.txt文档,利用Pandas读取):&#39;&#39;&#39;1. print(data.iloc[:,0])2. print(data.loc[:,&#39;TIME&#39;])    注意:iloc主要使用数字来索引数据，而不能使用字符型的标签来索引数据。    而loc则刚好相反，只能使用字符型标签来索引数据，不能使用数字来索引数据，    不过有特殊情况，当数据框dataframe的行标签或者列标签为数字，loc就可以来其来索引。    上面那个例子中，iloc直接通过数字来进行索引，得到所有行，第0列的数据；而loc中由于    数据的行编号是数字，所以前一个参数可以使用数字进行索引，但是由于列索引不再是数字，而是    字符型标签，所以想要索引同样的第0列时就只能使用相应列的列字符标签才行，否则会报错。https://blog.csdn.net/zaq15csdn/article/details/81255269?utm_source=blogxgwz0(重要)&#39;&#39;&#39;if (flag==1):    data = pd.read_csv(&#39;data/PN_lccorr_t1.txt&#39;,names=[&#39;TIME&#39;,&#39;RATE&#39;,&#39;YERROR&#39;,&#39;UNKNOWN&#39;])    data = np.array(data).reshape(-1,4)    data[:,0] = data[:,0] - data[:,0][0] #让x轴TIME的范围在(0,100000)之间else:    # 读取数据(方式2,利用astropy的fits包可直接读取.fits文件,避免画图再导出):    FITS_original_data=fits.open(data_path)    data = FITS_original_data[1].data #利用FITS_data.info()可得到数据是表格类型,且第二个(index=1)HDU类型才有数据    data_TIME = np.array(data.field(0)).reshape(-1,1) #.field(index_num)可获得第index_num列数据    data_RATE = np.array(data.field(1)).reshape(-1,1) #此处得到TIME、RATE、YERROR这三列数据进行堆叠    data_YERROR = np.array(data.field(2)).reshape(-1,1)    data = np.hstack((data_TIME,data_RATE,data_YERROR))    data[:,0] = data[:,0] - data[:,0][0] #让x轴TIME的范围在(0,100000)之间    FITS_original_data.close() # 及时关闭HDUList对象有助于减少内存消耗，在文件很大很多时需要格外注意。return data</code></pre><h1 id="数据组合与画图"><a href="#数据组合与画图" class="headerlink" title="数据组合与画图"></a>数据组合与画图</h1><p>def light_curve_combined():<br>    PN_data = data_reading(‘data/PN_lccorr.fits’, flag=2)<br>    MOS1_data = data_reading(‘data/MOS1_lccorr.fits’, flag=2)<br>    MOS2_data = data_reading(‘data/MOS2_lccorr.fits’, flag=2)</p><pre><code>np.nan_to_num(MOS1_data, 0)np.nan_to_num(MOS2_data, 0)data = np.zeros((PN_data.shape[0],3))data[:, 0] = PN_data[:, 0]data[:, 1] = PN_data[:PN_data.shape[0], 1] + MOS1_data[:PN_data.shape[0], 1] + MOS2_data[:PN_data.shape[0], 1]data[:, 2] = PN_data[:PN_data.shape[0], 2] + MOS1_data[:PN_data.shape[0], 2] + MOS2_data[:PN_data.shape[0], 2]# 对数据进行画图plt.errorbar(data[:, 0], data[:, 1], yerr=data[:, 2])plt.plot(data[:, 0], data[:, 1])plt.xlabel(&#39;TIME(s)&#39;)plt.ylabel(&#39;Count rate(counts/s)&#39;)plt.grid()plt.xlim((0,100000))plt.show()</code></pre><p>light_curve_combined()<br>```</p>]]></content>
      
      
      <categories>
          
          <category> 天体物理学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> XMM_Newton </tag>
            
            <tag> 天体物理学 </tag>
            
            <tag> EPIC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python正则表达式</title>
      <link href="/2019/05/25/regular-expression/"/>
      <url>/2019/05/25/regular-expression/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>python中正则表达式的使用方法总结.</strong><br><a id="more"></a></p></blockquote><pre><code>import re# 1.表示字符和表示数量#使用match方法进行匹配: result = re.match(正则表达式，要匹配的字符串)pattern = &quot;itcast&quot;s = &quot;1itcastitheima&quot;# result = re.match(&#39;\w\W&#39;,s) #从左到右进行匹配，如果一开始就规则与内容不一致则停止工作,不再往下进行匹配# print(result.group())# group()方法返回匹配的部分#[^345678]的^号代表对方括号中345678的取反(当然，也可以使用[^3^4^5^6^7^8]，两者等价)，也就是除了345678之外的任意一个都满足result1 = re.match(&#39;1[^345678]&#39;,&#39;19&#39;) #这里代表第二位是除了345678之外的任意result2 = re.match(&#39;1[a-z5-9]&#39;,&#39;17&#39;) #代表第二位是a-z或者5-9的字符#\d == [0-9]; \D == [^0-9]; \w == [a-zA-Z0-9_]; \W == [^a-zA-Z0-9_];也就是说方括号的方式和等号前的方式是等价的result3 = re.match(&#39;\d*&#39;,&#39;12abc&#39;) # \d*代表匹配0个或者多个数字，等价于None或者\d\d\d\d\d....，而不是代表匹配多个同样的数字出现多次result4 = re.match(&#39;\d+&#39;,&#39;132xsx&#39;) # \d+代表匹配1至少1个或者或者多个数字result5 = re.match(&#39;\d?&#39;,&#39;12abc&#39;) # \d?代表匹配0次数字或者1次数字，即要么1次，要么没有，多个数字也最多匹配到第一个数字result6 = re.match(&#39;\d*[a-z]&#39;,&#39;123abc&#39;) # \d* 或者\d+也都可以，只要不是\d?就能匹配&quot;123abc&quot;result7 = re.match(&#39;\d{3}[a-z]&#39;,&#39;1234acbss&#39;) # \d{3}[a-z]代表匹配前面的数字要出现3次(等价于\d\d\d[a-z])，后面是a-z的字符.result8 = re.match(&#39;\d{3,}[a-z]&#39;,&#39;12776xasx&#39;) # \d{3,}[a-z]代表前面数字匹配的个数是至少要有3个(&gt;=3)，其中\d{1,} == \d+; \d{0,} == \d*result9 = re.match(&#39;\d{3,5}[a-z]&#39;,&#39;1234xasx&#39;) # \d{3,5}代表数字出现3次到5次之间都行result10 = re.match(&#39;1[35678]\d{9}&#39;,&#39;17289890781xasx&#39;) # 匹配电话号码(暂时不考虑边界)print(result10.group())# 2.原始字符串s1 = r&quot;\\nabc&quot; #假使我们的例子中某个字符串就是\nabc，那么为了避免解释器将其中的\n转义为换行，则需要再加上一个\s2 = r&#39;\nabc&#39; #加上r可以避免\n被转义，其中r是英文字母raw的缩写，代表原始格式(也就是输入字符串是什么样子的，输出的时候就是什么样子的)# 其中s1和s2的表达式一样的（通常在写正则的时候，规则处都要加上r，避免一些内容被转义掉）result = re.match(r&quot;\\nabc&quot;,s2)print(result.group())# 3.表示边界(需要注意的是，^符号在[]中代表取反，但是不在[]中的时候代表以某个部分开头，而$代表以某个部分结尾)#需要注意的是在Ubuntu下的vim中A表示光标进入尾部且进入编辑模式，I表示进入头部且进入编辑模式；# 若不进入编辑模式，则shift+4($)就直接让光标进入尾部，相应的shift+6(^)则在不进入编辑模式的情况下进入头部。result1 = re.match(r&quot;1[35678]\d{9}$&quot;,&quot;15198168018&quot;).group() # r&quot;1[35678]\d{9}$&quot;代表匹配电话号码，且以9个数字结尾,多1位都无法匹配result2 = re.match(r&quot;^P\d+EIVEL\b&quot;,&#39;P080978EIVEL&#39;).group() # r&quot;^P\d+EIVEL&quot;代表匹配以P开头，一个或者多个数字在中间(\d+)，并紧接着出现EIVEL作为结尾(\b)的内容result3 = re.match(r&quot;^P\d+\s\bEIVEL\b&quot;,&#39;P080978 EIVEL RS&#39;).group() # \b这些的只是包含边界信息，不包含字符result4 = re.match(r&quot;^P.+\bEIVEL\b&quot;,&#39;P080978 EIVEL RS&#39;).group() # result3和resul4实质都是一样的，注意.代表匹配任意1个字符（除了\n），.+就是匹配任意多个字符result5 = re.match(r&quot;^P.+EIVEL\d{4}&quot;,&#39;P080978EIVEL0000&#39;).group() #匹配开头是P,中间EIVEL的内容，其中不能以EIVEL结尾(也就是EIVEL后面得有字符)。print(result5)# 4.匹配分组# | 用于匹配左右两边任意一个表达式:result = re.match(r&quot;[1-9]?\d?$|100$&quot;,&#39;0&#39;).group() #匹配0-100之间的数字#(.*)代表匹配0个或者多个内容，而group(1)中的1代表正则表达式中出现的第一组括号的内容，如果为2则是第二组括号的内容# 需要注意的是group()中是不传值的时候等价于group(0)，也就是给出全部匹配的内容result2 = re.match(r&quot;&lt;h1&gt;(.*)&lt;/h1&gt;&quot;,&quot;&lt;h1&gt;匹配分组&lt;/h1&gt;&quot;).group(1)# groups()代表一次性将多个括号的内容以元祖的方式呈现出现:(&#39;&lt;h1&gt;&#39;, &#39;&lt;/h1&gt;&#39;),其中groups()[0] == group(1)result3 = re.match(r&quot;(&lt;h1&gt;).*(&lt;/h1&gt;)&quot;,&quot;&lt;h1&gt;匹配分组&lt;/h1&gt;&quot;).groups()s = &quot;&lt;html&gt;&lt;h1&gt;itcast&lt;/h1&gt;&lt;/html&gt;&quot;#如果需要校验拿到的文本是否格式正确的时候，需要对于重要的内容使用()给括起来#而且\num代表拿到第num个()所拿到的内容，所以\2所在的尖括号的内容得和第二个括号的内容一致，相应的，\1所在尖括号的内容得和第一个括号的一致result4 = re.match(r&quot;&lt;(.+)&gt;&lt;(.+)&gt;.+&lt;/\2&gt;&lt;/\1&gt;&quot;,s)#匹配邮箱账号# (\w+)代表邮箱号前面的账号，需要被我们提取出来，所以加上()# (这里使用括号把163|126|gmail|qq给括起来是因为，# 这个时候163|126|gmail|qq和前面的内容不再是各自独立的某个情况了，(前面匹配0到100的例子中|左右各自都是一种独立的情况，而这里不是)# 这里163|126|gmail|qq仅仅是整个正则表达式的某个部分而已，所以需要使用括号将其作为一个分组，# 而在这个分组里这4种情况才是各自独立的情况)(这里\.是因为.不是正则表达式中的标识符，而仅仅是一个邮箱号的某个组成部分，所以需要加上\进行转义)result5 = re.match(r&quot;(\w+)@(163|126|gmail|qq)\.(com|cn|net)$&quot;,&#39;1786957287@qq.com&#39;)#给用于提取内容的括号分组起名字#需要注意的是，如果在某个正则表达式中()分组特别多的时候，为了避免混淆，这个时候给各个括号分组取不同的名字，例如：#在&lt;(?P&lt;name&gt;.+)&gt;中(?P&lt;name&gt;)实际上是不属于正则表达式的部分的，而是用于这次括号分组的名字的信息#而在取用对应的括号分组的时候，使用(?P=name)的方式就能取用对应的括号分组result6 = re.match(r&quot;&lt;(?P&lt;key1&gt;.+)&gt;&lt;(?P&lt;key2&gt;.+)&gt;.+&lt;/(?P=key2)&gt;&lt;/(?P=key1)&gt;&quot;,s)# print(result6.groups())# 5.re模块的高级用法(search,findall)s = &quot;&lt;html&gt;&lt;h1&gt;itcast&lt;/h1&gt;&lt;/html&gt;&quot;# search方法代表的是从整个字符串s中从左向右开始去找，如果遇到第一个&lt;不是要查找的itcast中的i,# 则继续沿着第一个&lt;往下走，直到匹配了正则表达式为止。result = re.search(r&quot;^itcast$&quot;,s) #这里加上^和$代表必须要以i开头，以t结尾的情况才能行。# 需要注意的是search从左向右找到了第一个匹配的内容后，search就结束了.s2 = &quot;itcast&lt;/h1&gt;&lt;/html&gt;itheima&lt;/h1&gt;&quot;result2 = re.search(r&quot;\w+&lt;/h1&gt;&quot;,s2)# 相应的如果你要把所有符合匹配条件的内容都找到，则需要使用findall,且对于的result3没有.group()方法，result3此时就是一个列表类型了result3 = re.findall(r&quot;\w+&lt;/h1&gt;&quot;,s2)# print(result3)# 在vim中需要批量替换的时候方法是:  :row_num1,row_num2s/替换前的词/替换后的词/g   其中g代表替换全部# 在正则表达式中使用sub进行批量替换(需要替换的部分,替换的内容(可以是一个函数),需要处理的整个内容)result4 = re.sub(r&quot;php&quot;,&quot;python&quot;,&quot;itcast python cpp php python php&quot;)# print(result4)# 需要注意的是在python中真正的注释是#号后面的内容，当解释器经过#的注释时直接略过，注释的内容也不会对内容产生影响# 而&quot;&quot;&quot;xxxxxx&quot;&quot;&quot;并非真正的注释，只不过可以当成注释来使用而已，三引号只不过是字符串的一种特殊形式而已，可以将三引号之间# 字符串的格式给保留下来，实际在使用的时候是会对内容有影响的，如果三引号中间的内容过大一样会引起程序的崩溃，这点是需要和真正的#注释相区分的。# sub例题：s3 = &quot;&quot;&quot;&lt;div&gt;        &lt;p&gt;岗位职责：&lt;/p&gt;&lt;p&gt;完成推荐算法、数据统计、接口、后台等服务器端相关工作&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;必备要求：&lt;/p&gt;&lt;p&gt;良好的自我驱动力和职业素养，工作积极主动、结果导向&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br&gt;&lt;/p&gt;&lt;p&gt;技术要求：&lt;/p&gt;&lt;p&gt;1、一年以上 Python 开发经验，掌握面向对象分析和设计，了解设计模式&lt;/p&gt;&lt;p&gt;2、掌握HTTP协议，熟悉MVC、MVVM等概念以及相关WEB开发框架&lt;/p&gt;&lt;p&gt;3、掌握关系数据库开发设计，掌握 SQL，熟练使用 MySQL/PostgreSQL 中的一种&lt;br&gt;&lt;/p&gt;&lt;p&gt;4、掌握NoSQL、MQ，熟练使用对应技术解决方案&lt;/p&gt;&lt;p&gt;5、熟悉 Javascript/CSS/HTML5，JQuery、React、Vue.js&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br&gt;&lt;/p&gt;&lt;p&gt;加分项：&lt;/p&gt;&lt;p&gt;大数据，数理统计，机器学习，sklearn，高性能，大并发。&lt;/p&gt;        &lt;/div&gt;&quot;&quot;&quot; # 这里题要求将所有&lt;&gt;去掉result5 = re.sub(r&quot;&lt;/?\w+&gt;&quot;,&quot;&quot;,s3) # r&quot;&lt;/?\w+&gt;&quot;代表去掉所有&lt;&gt;，其中/?代表有反斜杠/的&lt;/&gt;可能有，也可能没有# split根据匹配进行字符串分割s4 = &quot;itcast:php,python,cpp-java&quot;result6 = re.split(r&quot;:|,|-&quot;,s4)# print(result6)# 6.贪婪模式(一般情况下你所提取到的内容比你所期望的要多，问题一般是出在了贪婪模式上)s5 = &quot;This is a number 234-235-22-423&quot;r=re.match(&quot;.+(\d+-\d+-\d+-\d+)&quot;,s5)print(r.group(1))#从贪婪模式到非贪婪模式只需要加上一个?,不过需要注意的是这里加上一个?并非将所有贪婪模式全部关闭，它只关闭它前面所修饰的那个数量描述符(+)#?号前关闭的贪婪模式到哪里截止呢？还需要根据后面一个正则条件来决定r=re.match(&quot;(.+?)(\d+-\d+-\d+-\d+)&quot;,s5)print(r.group(2))</code></pre>]]></content>
      
      
      <categories>
          
          <category> Python算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 正则表达式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python数据结构与算法(4)——树与二叉树</title>
      <link href="/2019/05/25/python-data-structrue-4/"/>
      <url>/2019/05/25/python-data-structrue-4/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>python数据结构——二叉树.</strong><br><a id="more"></a></p></blockquote><pre><code>&#39;&#39;&#39;14. 数据结构：二叉树&#39;&#39;&#39;class Node(object):    def __init__(self,item):        self.elem = item        self.lchild = None        self.rchild = Noneclass Tree(object):    &quot;&quot;&quot;二叉树: 使用队列实现&quot;&quot;&quot;    def __init__(self):        self.root = None    def add(self,item):        node = Node(item)        if self.root is None:            self.root = node            return        queue = [self.root] #使用队列实现二叉树，这里为了方便直接使用顺序表中的[]实现，只是在实现的过程中只是用队列能够用的功能        while queue: # 如果队列为空，则退出循环            cur_node = queue.pop(0) #每次将数据写入队列的时候是从尾部写入(append)，读取的时候从头读取(pop(0))，也就是队列的先进先出            if cur_node.lchild is None:                cur_node.lchild = node                return            else:                queue.append(cur_node.lchild)            if cur_node.rchild is None:                cur_node.rchild = node                return            else:                queue.append(cur_node.rchild)    def breadth_travel(self):        &#39;&#39;&#39;广度遍历(层次遍历)&#39;&#39;&#39;        if self.root is None:            return        queue = [self.root]        while queue:            cur_node = queue.pop(0)            print(cur_node.elem,end=&#39; &#39;)            if cur_node.lchild is not None:                queue.append(cur_node.lchild)            if cur_node.rchild is not None:                queue.append(cur_node.rchild)    def preorder(self, root):        &quot;&quot;&quot;递归实现先序遍历&quot;&quot;&quot;        if root == None:            return        print(root.elem,end=&#39; &#39;)        self.preorder(root.lchild)        self.preorder(root.rchild)    def inorder(self, root):        &quot;&quot;&quot;递归实现中序遍历&quot;&quot;&quot;        if root == None:            return        self.inorder(root.lchild)        print(root.elem,end=&#39; &#39;)        self.inorder(root.rchild)    def postorder(self, root):        &quot;&quot;&quot;递归实现后续遍历&quot;&quot;&quot;        if root == None:            return        self.postorder(root.lchild)        self.postorder(root.rchild)        print(root.elem,end=&#39; &#39;)if __name__ == &quot;__main__&quot;:    # 二叉树    tree = Tree()    tree.add(0)    tree.add(1)    tree.add(2)    tree.add(3)    tree.add(4)    tree.add(5)    tree.add(6)    tree.add(7)    tree.add(8)    tree.add(9)    tree.breadth_travel()    print(&#39; &#39;)    tree.preorder(tree.root)    print(&#39; &#39;)    tree.inorder(tree.root)    print(&#39; &#39;)    tree.postorder(tree.root)</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 二叉树 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python数据结构与算法(3)——排序与查找算法</title>
      <link href="/2019/05/25/python-data-structrue-3/"/>
      <url>/2019/05/25/python-data-structrue-3/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>python数据结构——排序算法和查找算法.</strong><br><a id="more"></a></p></blockquote><p><img src= "/img/loading.gif" data-src="/2019/05/25/python-data-structrue-3/a.png" alt></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/python-data-structrue-3/b.png" alt></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/python-data-structrue-3/c.png" alt></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/python-data-structrue-3/d.png" alt></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/python-data-structrue-3/e.png" alt></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/python-data-structrue-3/f.png" alt></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/python-data-structrue-3/g.png" alt></p><pre><code>&#39;&#39;&#39;7. 数据结构：排序算法(1)——冒泡排序&#39;&#39;&#39;def bubble_sort(alist):    &quot;&quot;&quot;冒泡排序,最坏时间复杂度O(n²),冒泡排序是稳定的&quot;&quot;&quot;    n = len(alist) # 列表元素的个数    for j in range(0,n-1): # 控制下面的循环执行多少次        count = 0 # 需要考虑最优的情况(也就是整个数据本身是有序的情况)        for i in range(0,n-1-j): # 控制一次将大的数字放在最后            if alist[i] &gt; alist[i+1]: # 如果前一个数大于后一个数，则需要交换                alist[i],alist[i+1] = alist[i+1],alist[i]                count += 1        if count == 0:            # 对冒泡排序进行优化，count用于记录数字之间的交换次数，如果遍历完一次之后发现一次都没有交换，            # 则表明数据本身是有序的，则可以不用进行下一次遍历了，直接return结束，这样的话就将冒泡排序            # 本身的最坏时间复杂度O(n²)转化为O(n)了.            return&#39;&#39;&#39;8. 数据结构：排序算法(2)——选择排序&#39;&#39;&#39;def select_sort(alist):    &quot;&quot;&quot;选择排序,最优和最坏时间复杂度都是O(n²),    选择排序的思想就是将整个数据分成两部分(有序的序列放前面，无序的序列放后面),    对于无序的序列，在其中找到(本次无序序列的子序列中)最小的那个，放入前面有序的序列中去.    选择排序在选择升序的时候(每次选择最大的情况)是不稳定的.&quot;&quot;&quot;    n = len(alist)    for j in range(n-1): # j:0 ~ n-2        min_index = j  # 假设一开始最小值为下标为0的数字        for i in range(j+1,n): # 这个循环执行完之后在无序序列中找到最小值的下标            if alist[min_index] &gt; alist[i]:                min_index = i        alist[j],alist[min_index] = alist[min_index],alist[j] # 根据本次最小值下标进行交互，将本次最小值放入前面有序序列&#39;&#39;&#39;9. 数据结构：排序算法(3)——插入排序&#39;&#39;&#39;def insert_sort(alist):    &#39;&#39;&#39;插入排序,最坏时间复杂度O(n²),最优时间复杂度O(n),其稳定性为稳定的&#39;&#39;&#39;    n = len(alist)    for j in range(1,n): # 从右边的无序序列中取出多少个元素执行下面的过程        i = j # i代表内层循环的起始值        while i&gt;0: # 执行从右边的无序序列中取出第一个元素，即i位置的元素，然后将其插入到前面的有序序列中            if alist[i] &lt; alist[i-1]:                alist[i],alist[i-1] = alist[i-1],alist[i]                i -= 1            else: # 对插入算法的优化，使得如果整个序列为有序的，则其变为最优时间复杂度                break&#39;&#39;&#39;10. 数据结构：排序算法(4)——希尔排序&#39;&#39;&#39;def shell_sort(alist):    &#39;&#39;&#39;希尔排序: 插入排序升级版,其最坏时间复杂度为O(n²),最优时间复杂度要根据gap的取值来决定,    gap最优值要根据数学公式来推导得到,对不同的数据其最优值会有不同. 其稳定性为不稳定.&#39;&#39;&#39;    n = len(alist)    gap = n // 2 # gap按照数据长度折半取    # 控制gap的长度变化，每次折半gap,也即每一个gap产生的多个子序列在下面的循环中排序完毕一次之后，    # gap折半，然后重复下面循环的步骤，直到gap=1排完才结束    while gap &gt;= 1:        for j in range(gap,n): # 从gap开始，意味着从竖线后面开始，这样的话就可以一个循环就将所有子序列全部排序完成            i = j            while i &gt; 0:                if alist[i] &lt; alist[i-gap]:# 对于插入排序来说的话，如果gap=1，则希尔排序退化成插入排序                    alist[i],alist[i-gap] = alist[i-gap],alist[i]                    i -= gap                else:                    break        gap //= 2 # 缩短gap步长&#39;&#39;&#39;11. 数据结构：排序算法(5)——快速排序&#39;&#39;&#39;def quick_sort(alist,first_index,last_index):    &#39;&#39;&#39;快速排序:    1. 找出序列中的第一个值，然后根据low和high游标的移动去判断第一个值应该位于整个序列中的哪个位置       在low和high移动的过程中不断的用两个游标所指向的数字去确定剩下的序列中左边的都是比第一个值小的，       右边的都是比第一个值大的，这样两个游标才能不断往中间靠拢，否则与上面条件相反则挺住，当两个游标都       停住但是都没有重合到一个数字的时候就将让两个游标挺住的各自两个数字交换顺序，然后继续上面的判断条件       往中间靠拢，直至两个游标重合的时候，这个时候两个游标所指向的地方就是第一个数字应处于的地方.这样一番下来       得到第一个数字左边的数字都比第一个数字小(此时不一定有序,但是都比第一个数字小),右边的数字都比第一个数字大    2. 通过上面操作，第一个数字将整个数据分成了左右两边两个部分，然后左右两边相应的再用上面的方式去做，直到整个       数据都是有序的为止，反正每次划分之后，划分点出的数字，左边都比它要小，右边都比它要大    3. 最优时间复杂度O(n*log₂n),最坏时间复杂度为O(n²),稳定性为不稳定&#39;&#39;&#39;    if first_index &gt;= last_index: # 用于结束递归的条件(也就是传入的数据只有一个的时候就没必要快排了)        return    mid_value = alist[first_index]    low = first_index    high = last_index    while low &lt; high:# 下面的过程交替执行        # high游标的左移(这里的等号可以放在第一个while中，也可以放在第二个while中)        # 这种只在一个while中出现=的情况是因为快排的一个思想就是将相同的元素尽量放在一边        # 也就是要么都放在high这边，要么就是都放在low那边(这样分割线更清晰点)，所以两个while只有一个等号        while low &lt; high and (alist[high] &gt;= mid_value): # 当两个游标重合的时候，游标就不需要再走动了            high -= 1        alist[low] = alist[high] # 退出循环执行到这一步说明high指向的数字比mid_value还小，此时将high所指的放在low的空位上        # low游标的右移        while low &lt; high and (alist[low] &lt; mid_value):            low += 1        alist[high] = alist[low] # 退出循环执行到这一步说明low指向的数字比mid_value还da，此时将low所指的放在high的空位上    # 从整个循环退出时，low=high    alist[low] = mid_value    # 第一次循环完毕之后，分为左右两边，左右两边也可以递归进行上面的划分(需要注意的是不能使用切片，因为切片会得到新的列表)    # 对low左边的列表进行排序    quick_sort(alist,first_index,low-1)    # 对low右边的列表进行排序    quick_sort(alist,low+1,last_index)&#39;&#39;&#39;12. 数据结构：排序算法(6)——归并排序&#39;&#39;&#39;def merge_sort(alist):    &#39;&#39;&#39;归并排序,最优时间复杂度和最坏时间复杂度都是O(nlog₂n),稳定性是稳定的    需要注意的是，归并排序在时间上是小的，但是在空间上是花费大的(额外开销)&#39;&#39;&#39;    n = len(alist)    if n &lt;= 1:        return alist    mid = n // 2    # 接收的left和right代表的是接收采用归并排序后形成的新的有序的列表    left_li = merge_sort(alist[:mid])    right_li = merge_sort(alist[mid:])    # 将两个有序的子序列(left_li和right_li)合并成一个新的有序的序列    left_pointer,right_pointer = 0,0    result = []    while left_pointer &lt; len(left_li) and right_pointer &lt; len(right_li):        if left_li[left_pointer] &lt;= right_li[right_pointer]:            result.append(left_li[left_pointer])            left_pointer += 1        else:            result.append(right_li[right_pointer])            right_pointer += 1    result += left_li[left_pointer:]    result += right_li[right_pointer:]    return result&#39;&#39;&#39;13. 数据结构：搜索算法——二分查找(要求: 只能应用于有序的顺序表上)最优时间复杂度O(1)最坏时间复杂度O(logn)&#39;&#39;&#39;def binary_search_recursion(alist,item):    &#39;&#39;&#39;二分查找,递归版本&#39;&#39;&#39;    n = len(alist)    if n &gt; 0:        mid = n // 2        if alist[mid] == item:            return True        elif item &lt; alist[mid]:            return binary_search(alist[:mid],item)        else:            return binary_search(alist[mid+1:],item)    return Falsedef binary_search_unrecursion(alist,item):    &#39;&#39;&#39;二分查找,非递归版本&#39;&#39;&#39;    n = len(alist)    first = 0    last = n-1    while first &lt;= last:        mid = (first+last) // 2        if alist[mid] == item:            return True        elif item &lt; alist[mid]:            last = mid - 1        else:            first = mid + 1    return Falseif __name__ == &quot;__main__&quot;:    &#39;&#39;&#39;    必须要掌握的排序: 快速排序(快排的时间复杂度更趋近与O(nlogn))    &#39;&#39;&#39;    # 冒泡排序    &#39;&#39;&#39;    li = [54, 26, 93, 17, 77, 31, 44, 55, 20]    li2 = [1,2,3,4,5,6]    bubble_sort(li2)    print(li2)    &#39;&#39;&#39;    # 选择排序    &#39;&#39;&#39;    li = [54, 26, 93, 17, 77, 31, 44, 55, 20]    select_sort(li)    print(li)    &#39;&#39;&#39;    # 选择排序    &#39;&#39;&#39;    li = [54, 26, 93, 17, 77, 31, 44, 55, 20]    insert_sort(li)    print(li)    &#39;&#39;&#39;    # 希尔排序    &#39;&#39;&#39;    li = [54, 26, 93, 17, 77, 31, 44, 55, 20]    shell_sort(li)    print(li)    &#39;&#39;&#39;    # 快速排序    &#39;&#39;&#39;    li = [54, 26, 93, 17, 77, 31, 44, 55, 20]    quick_sort(li,0,len(li)-1)    print(li)    &#39;&#39;&#39;    # 归并排序    &#39;&#39;&#39;    li = [54, 26, 93, 17, 77, 31, 44, 55, 20]    sorted_li = merge_sort(li)    print(sorted_li)    &#39;&#39;&#39;    # 二分查找    li = [17,20,26,31,44,54,55,77,93]    print(binary_search_unrecursion(li,55))    print(binary_search_unrecursion(li,100))</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 排序 </tag>
            
            <tag> 查找 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python数据结构与算法(2)——栈与队列</title>
      <link href="/2019/05/25/python-data-structrue-2/"/>
      <url>/2019/05/25/python-data-structrue-2/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>python数据结构——栈和队列.</strong><br><a id="more"></a></p></blockquote><pre><code>&#39;&#39;&#39;4. 数据结构：栈(LIFO——Last In First Out)(线性表——顺序表和链表解决的是数据怎么存放的问题，栈和队列可以使用顺序表或者链表中的一种实现，因此栈实际描述的是数据如何操作的问题。栈可以用于做成四则运算，队列可以用于树的遍历)在此实现栈的容器使用顺序表(列表)&#39;&#39;&#39;class Stack(object):    def __init__(self):        self.__list = []    def push(self,item):        &#39;&#39;&#39;添加一个新的元素item到栈顶        #选择从顺序表(列表)的尾部取压栈是因为顺序表的尾部插入元素的时间复杂度为O(1).        如果选择链表则选择头部插入，同样是因为时间复杂度的缘故&#39;&#39;&#39;        self.__list.append(item)    def pop(self):        &#39;&#39;&#39;弹出栈顶元素&#39;&#39;&#39;        return self.__list.pop()    def peek(self):        &#39;&#39;&#39;返回栈顶元素&#39;&#39;&#39;        if self.__list:            return self.__list[-1]        else:            return None    def is_empty(self):        &#39;&#39;&#39;判断栈是否为空&#39;&#39;&#39;        return self.__list == []        return not self.__list    def size(self):        &#39;&#39;&#39;返回栈的元素个数&#39;&#39;&#39;        return len(self.__list)&#39;&#39;&#39;if __name__ == &quot;__main__&quot;:    s = Stack()    s.push(1)    s.push(2)    s.push(3)    s.push(4)    print(s.pop())    print(s.pop())    print(s.pop())    print(s.pop())&#39;&#39;&#39;&#39;&#39;&#39;5. 数据结构：队列(queue)&#39;&#39;&#39;class Queue(object):    def __init__(self):        self.__list = [] #[]代表的是保存队列元素的容器，可以是顺序表(列表),也可以是链表    def enqueue(self,item):        &#39;&#39;&#39;往队列中添加一个item元素,O(1),到底从尾部还是头部添加(弹出)元素是要根据你的具体操作的频繁程度来看的&#39;&#39;&#39;        self.__list.append(item)    def dequeue(self):        &#39;&#39;&#39;从队列头部删除一个元素,O(n)&#39;&#39;&#39;        return self.__list.pop(0)    def is_empty(self):        &#39;&#39;&#39;判断一个队列是否为空&#39;&#39;&#39;        return self.__list == []    def size(self):        &#39;&#39;&#39;返回队列的大小&#39;&#39;&#39;        return len(self.__list)&#39;&#39;&#39;if __name__ == &quot;__main__&quot;:    q = Queue()    q.enqueue(1)    q.enqueue(2)    q.enqueue(3)    q.enqueue(4)    print(q.dequeue())    print(q.dequeue())    print(q.dequeue())    print(q.dequeue())&#39;&#39;&#39;&#39;&#39;&#39;6. 数据结构：双端队列(Deque)&#39;&#39;&#39;class Deque(object):    def __init__(self):        self.items = [] #[]代表的是保存队列元素的容器，可以是顺序表(列表),也可以是链表    def add_front(self, item):        &quot;&quot;&quot;在队头添加元素&quot;&quot;&quot;        self.items.insert(0, item)    def add_rear(self, item):        &quot;&quot;&quot;在队尾添加元素&quot;&quot;&quot;        self.items.append(item)    def remove_front(self):        &quot;&quot;&quot;从队头删除元素&quot;&quot;&quot;        return self.items.pop(0)    def remove_rear(self):        &quot;&quot;&quot;从队尾删除元素&quot;&quot;&quot;        return self.items.pop()    def is_empty(self):        &#39;&#39;&#39;判断一个队列是否为空&#39;&#39;&#39;        return self.items == []    def size(self):        &#39;&#39;&#39;返回队列的大小&#39;&#39;&#39;        return len(self.items)if __name__ == &quot;__main__&quot;:    deque = Deque()    deque.add_front(1)    deque.add_front(2)    deque.add_rear(3)    deque.add_rear(4)    print(deque.size())    print(deque.remove_front())    print(deque.remove_front())    print(deque.remove_rear())    print(deque.remove_rear())</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 栈 </tag>
            
            <tag> 队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python数据结构与算法(1)——链表</title>
      <link href="/2019/05/25/python-data-structrue-1/"/>
      <url>/2019/05/25/python-data-structrue-1/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>python数据结构——链表实现.</strong><br><a id="more"></a></p></blockquote><pre><code>&#39;&#39;&#39;抽象数据类型(Abstract Data Type)：    抽象数据类型(ADT)的含义是指一个数学模型以及定义在此数学模型上的一组操作。    即把数据类型和数据类型上的运算捆在一起，进行封装。    引入抽象数据类型的目的是把数据类型的表示和数据类型上运算的实现    与这些数据类型和运算在程序中的引用隔开，使它们相互独立。&#39;&#39;&#39;&#39;&#39;&#39;1. 数据结构：单向链表(头结点 + 尾节点)&#39;&#39;&#39;class Node(object):    &#39;&#39;&#39;节点: elem + next&#39;&#39;&#39;    def __init__(self,elem):        self.elem = elem        self.next = None # 节点指向的下一个节点地址暂时未知,所以置为Noneclass SingleLinkList(object):    &#39;&#39;&#39;单向链表&#39;&#39;&#39;    def __init__(self,node=None):        # 头结点做成私有属性        self.__head = node #这里代表新建节点的时候，让链表对象的头节点指向这个新建的节点    def is_empty(self):        &#39;&#39;&#39;判断链表是否为空&#39;&#39;&#39;        return self.__head == None    def length(self):        &#39;&#39;&#39;判断链表长度: 此处需要一个辅助的用于遍历整个链表的东西，也就是游标(cur)，使用它不断后移来遍历整个链表的元素&#39;&#39;&#39;        cur = self.__head        count = 0 #用于就来数量        while cur != None:            count += 1            cur = cur.next        return count    def travel(self):        &#39;&#39;&#39;遍历整个链表&#39;&#39;&#39;        cur = self.__head        while cur != None:            print(cur.elem,end=&#39; &#39;)            cur = cur.next        print(&#39;&#39;)    def add(self,item):        &#39;&#39;&#39;链表头部添加元素,头插法(时间复杂度是O(1))&#39;&#39;&#39;        node = Node(item)        node.next = self.__head        self.__head = node    def append(self,item):        &#39;&#39;&#39;链表尾部添加元素, 尾插法(时间复杂度为O(n))&#39;&#39;&#39;        node = Node(item)        if self.is_empty():            self.__head = node        else:            cur = self.__head # 用于遍历到尾部节点            while cur.next != None:                cur = cur.next            cur.next = node    def insert(self,pos,item):        &#39;&#39;&#39;指定位置添加元素        :param pos 从0开始        &#39;&#39;&#39;        if pos &lt;= 0:            self.add(item)        elif pos &gt; (self.length()-1):            self.append(item)        else:            pre = self.__head            count = 0            while count &lt; (pos-1): #当循环退出之后，pre指向(pos-1)这个位置                count += 1                pre = pre.next            node = Node(item)            node.next = pre.next            pre.next = node    def remove(self,item):        &#39;&#39;&#39;删除节点&#39;&#39;&#39;        cur = self.__head        pre = None        while cur != None:            if cur.elem == item:                # 先判断是否为头结点                if cur == self.__head:                    self.__head = cur.next                else:                    pre.next = cur.next                break            else:                pre = cur                cur = cur.next    def search(self,item):        &#39;&#39;&#39;查找节点是否存在&#39;&#39;&#39;        cur = self.__head        while cur != None:            if cur.elem == item:                return True            else:                cur = cur.next        return Falseif __name__ == &quot;__main__&quot;:    ll = SingleLinkList()    print(ll.is_empty())    print(ll.length())    ll.append(1)    print(ll.is_empty())    print(ll.length())    ll.append(2)    ll.add(8)    ll.append(3)    ll.append(4)    ll.append(5)    ll.append(6)    ll.insert(-1,9)    ll.insert(3,100)    ll.insert(10,200)    ll.travel()    ll.remove(100)    ll.travel()    ll.remove(9)    ll.travel()    ll.remove(200)    ll.travel()&#39;&#39;&#39;2. 数据结构：双向链表&#39;&#39;&#39;class Node(object):    &#39;&#39;&#39;节点: elem + next&#39;&#39;&#39;    def __init__(self,elem):        self.elem = elem        self.next = None # 节点指向的下一个节点地址暂时未知,所以置为None        self.prev = Noneclass DoubleLinkList(object):    &#39;&#39;&#39;双向链表&#39;&#39;&#39;    #继承单向链表(SingleLinkList),所以前面的几个方法（包括search方法）可以直接继承    def __init__(self,node=None):        # 头结点做成私有属性        self.__head = node #这里代表新建节点的时候，让链表对象的头节点指向这个新建的节点    def is_empty(self):        &#39;&#39;&#39;判断链表是否为空&#39;&#39;&#39;        return self.__head == None    def length(self):        &#39;&#39;&#39;判断链表长度: 此处需要一个辅助的用于遍历整个链表的东西，也就是游标(cur)，使用它不断后移来遍历整个链表的元素&#39;&#39;&#39;        cur = self.__head        count = 0 #用于就来数量        while cur != None:            count += 1            cur = cur.next        return count    def travel(self):        &#39;&#39;&#39;遍历整个链表&#39;&#39;&#39;        cur = self.__head        while cur != None:            print(cur.elem,end=&#39; &#39;)            cur = cur.next        print(&#39;&#39;)    def add(self,item):        &#39;&#39;&#39;链表头部添加元素,头插法(时间复杂度是O(1))&#39;&#39;&#39;        node = Node(item)        node.next = self.__head        self.__head.prev = node # node.next.prev = node        self.__head = node    def append(self,item):        &#39;&#39;&#39;链表尾部添加元素, 尾插法&#39;&#39;&#39;        node = Node(item)        if self.is_empty():            self.__head = node            print(&#39;xxxxxxx&#39;)        else:            cur = self.__head # 用于遍历到尾部节点            while cur.next != None:                cur = cur.next            cur.next = node            node.prev = cur    def insert(self,pos,item):        &#39;&#39;&#39;指定位置添加元素        :param pos 从0开始        &#39;&#39;&#39;        if pos &lt;= 0:            self.add(item)        elif pos &gt; (self.length()-1):            self.append(item)        else:            cur = self.__head            count = 0            while count &lt; pos:                count += 1                cur = cur.next            node = Node(item)            node.next = cur            node.prev = cur.prev            cur.prev.next = node            cur.prev = node    def remove(self,item):        &#39;&#39;&#39;删除节点&#39;&#39;&#39;        cur = self.__head        while cur != None:            if cur.elem == item:                # 先判断是否为头结点                if cur == self.__head:                    self.__head = cur.next                    if cur.next:                        # 判断链表是否只有一个节点                        cur.next.prev = None                else:                    cur.prev.next = cur.next                    if cur.next:                        cur.next.prev = cur.prev                break            else:                cur = cur.next    def search(self,item):        &#39;&#39;&#39;查找节点是否存在&#39;&#39;&#39;        cur = self.__head        while cur != None:            if cur.elem == item:                return True            else:                cur = cur.next        return Falseif __name__ == &quot;__main__&quot;:    dll = DoubleLinkList()    print(dll.is_empty())    print(dll.length())    dll.append(1)    print(dll.is_empty())    print(dll.length())    dll.append(2)    dll.add(8)    dll.append(3)    dll.append(4)    dll.append(5)    dll.append(6)    dll.insert(-1,9)    dll.insert(3,100)    dll.insert(10,200)    dll.travel()    dll.remove(100)    dll.travel()    dll.remove(9)    dll.travel()    dll.remove(200)    dll.travel()&#39;&#39;&#39;3. 数据结构：单向循环链表&#39;&#39;&#39;class Node(object):    &#39;&#39;&#39;节点: elem + next&#39;&#39;&#39;    def __init__(self,elem):        self.elem = elem        self.next = None # 节点指向的下一个节点地址暂时未知,所以置为Noneclass SingleCycleLinkList(object):    &#39;&#39;&#39;单向循环链表&#39;&#39;&#39;    def __init__(self,node=None):        # 头结点做成私有属性        self.__head = node #这里代表新建节点的时候，让链表对象的头节点指向这个新建的节点        if node:            node.next = node    def is_empty(self):        &#39;&#39;&#39;判断链表是否为空&#39;&#39;&#39;        return self.__head == None    def length(self):        &#39;&#39;&#39;判断链表长度: 此处需要一个辅助的用于遍历整个链表的东西，也就是游标(cur)，使用它不断后移来遍历整个链表的元素&#39;&#39;&#39;        if self.is_empty():            return 0        cur = self.__head        count = 1 #用于就来数量        while cur.next != self.__head:            count += 1            cur = cur.next        return count    def travel(self):        &#39;&#39;&#39;遍历整个链表&#39;&#39;&#39;        if self.is_empty():            return        cur = self.__head        while cur.next != self.__head:            print(cur.elem,end=&#39; &#39;)            cur = cur.next        # 退出循环，cur指向尾节点，但尾节点的元素并未打印（对于只有一个节点的时候也是可以完成的）。        print(cur.elem)    def add(self,item):        &#39;&#39;&#39;链表头部添加元素,头插法(时间复杂度是O(1))&#39;&#39;&#39;        node = Node(item)        if self.is_empty():            self.__head = node            node.next = node        else:            cur = self.__head            while cur.next != self.__head:                cur = cur.next            # 退出循环，cur指向尾节点            node.next = self.__head            self.__head = node            cur.next = node # cur.next = self.__head    def append(self,item):        &#39;&#39;&#39;链表尾部添加元素, 尾插法(时间复杂度为O(n))&#39;&#39;&#39;        node = Node(item)        if self.is_empty():            self.__head = node            node.next = node        else:            cur = self.__head # 用于遍历到尾部节点            while cur.next != self.__head:                cur = cur.next            cur.next = node            node.next = self.__head    def insert(self,pos,item):        &#39;&#39;&#39;指定位置添加元素        :param pos 从0开始        &#39;&#39;&#39;        if pos &lt;= 0:            self.add(item)        elif pos &gt; (self.length()-1):            self.append(item)        else:            pre = self.__head            count = 0            while count &lt; (pos-1): #当循环退出之后，pre指向(pos-1)这个位置                count += 1                pre = pre.next            node = Node(item)            node.next = pre.next            pre.next = node    def remove(self,item):        &#39;&#39;&#39;删除节点&#39;&#39;&#39;        if self.is_empty():            return        cur = self.__head        pre = None        while cur.next != self.__head:            if cur.elem == item:                # 先判断是否为头结点                if cur == self.__head:                    # 头结点（需要找到尾节点）                    rear = self.__head                    while rear.next != self.__head:                        rear = rear.next                    self.__head = cur.next                    rear.next = self.__head                else: # 中间节点                    pre.next = cur.next                return            else:                pre = cur                cur = cur.next        # 退出循环，cur指向尾节点        if cur.elem == item:            if cur == self.__head: #代表链表只有一个节点                self.__head = None            else:                pre.next = cur.next # pre.next = self.__head    def search(self,item):        &#39;&#39;&#39;查找节点是否存在&#39;&#39;&#39;        if self.is_empty():            return False        cur = self.__head        while cur.next != self.__head:            if cur.elem == item:                return True            else:                cur = cur.next        # 退出循环，cur指向尾节点，但是尾节点还未查找        if cur.elem == item:            return True        return Falseif __name__ == &quot;__main__&quot;:    ll = SingleCycleLinkList()    print(ll.is_empty())    print(ll.length())    ll.append(1)    print(ll.is_empty())    print(ll.length())    ll.append(2)    ll.add(8)    ll.append(3)    ll.append(4)    ll.append(5)    ll.append(6)    ll.insert(-1,9)    ll.insert(3,100)    ll.insert(10,200)    ll.travel()    ll.remove(100)    ll.travel()    ll.remove(9)    ll.travel()    ll.remove(200)    ll.travel()</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 链表 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据的移动平均</title>
      <link href="/2019/05/25/moving-average/"/>
      <url>/2019/05/25/moving-average/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>探索numpy和TensorFlow中的移动平均函数，并手动实现.</strong><br><a id="more"></a></p></blockquote><h2 id="1-方法一"><a href="#1-方法一" class="headerlink" title="1. 方法一"></a>1. 方法一</h2><blockquote><p>$L = [1,2,3,4,5]$</p><pre><code>L = [1,2,3,4,5]    window_size = 3    filter_vec=np.ones(window_size)/window_size    # sma=np.convolve(weights,L,mode=&#39;vaild&#39;)  # (W = [W + 2P - f]/s + 1,其中[P = N - 1])    # sma=np.convolve(weights,L)[N-1:-N+1]    sma=np.convolve(filter_vec,L) # [0.5 1.5 2.5 3.5 4.5 2.5] # 在 mode=&#39;full&#39;情况下,卷积之后的大小为N(这里是weights)+M(这里是L)-1    print(sma)</code></pre><p>在上面的代码中使用<strong>numpy</strong>下的卷积函数<strong>convolve</strong>实现。由于移动平均是通过对一个数组中指定的<strong>N</strong>个数字(也就是移动窗口尺寸大小的数字)相加之后再除以<strong>N</strong>(也就是移动窗口的大小)实现的移动平均，而此方式和卷积的方式很像: 设置一个尺寸大小为<strong>N</strong>的全为<strong>1</strong>的卷积核与数组分别相乘相加(达到与长度为<strong>N</strong>的数组直接相加一样的效果)再除以<strong>N</strong>则和移动平均效果相同其中需要注意的是<strong>convolve</strong>函数中的<strong>mode</strong>参数有三种选择: <strong>full; valid; same</strong>，其中<strong>mode=”full”</strong>为参数的默认值，在此参数下数组卷积之后的大小为: <strong>N + M - 1</strong>，其中<strong>N</strong>代表<strong>filter_vec</strong>的尺寸长度，<strong>M</strong>代表原始数组<strong>L</strong>的长度，由于在<strong>full</strong>模式下，整个卷积过程实际上是从卷积核最右边的那个元素和原始数组最左边的第一开始进行卷积，直到卷积核最左边的元素与原始数组最右边的元素卷积完毕，整个过程相当于<strong>Padding = N - 1</strong>，因此在<strong>full</strong>模式下的卷积最后完毕之后得到的数据长度可以使用卷积神经网络中计算卷积之后尺寸的公式进行计算: </p><p><script type="math/tex">n_{H/W}^{[l]} =  \frac{n_{H/W}^{[l-1]} + 2P^{[l]} - f^{[l]}}{ s^{[l]} } + 1</script>，<br>其中这里的$Padding = N - 1$，因此与上面的计算卷积后的尺寸的公式实际上是一致的(只是要以卷积的方式实现移动平均的话需要以固定的<strong>Padding</strong>才能实现，也就是<strong>Padding = N - 1</strong>)。而且需要注意的是在<strong>full</strong>模式下卷积得到的数组的尺寸比原始数组要大，但是实际上滑动平均等价于卷积核与数组相应尺寸匹配的情况(也就是无<strong>Padding</strong>)的情况，则需要截取在卷积完之后的数组中的一部分，其中<strong>[ N-1 : -N + 1]</strong>中的<strong>N-1</strong>代表的其实就是卷积核最左边的元素与原始数组最左边的元素重合的时候，因为<strong>0</strong>到<strong>N-1</strong>的长度就是<strong>N</strong> , 想应的<strong>-N+1</strong>代表卷积核最后一个元素与原始数组最后一个元素重合的情况，因为倒着数数组的话，<strong>-1</strong>的位置到<strong>-N</strong>的位置长度也是有<strong>N</strong>个(<strong>-N+1</strong>在切片中取不到，因此切片右端代表取到<strong>index</strong>为<strong>-N</strong>的元素)，因此切片区域代表的都是卷积核与原始数组全部重合的地方.<br>需要注意的是使用<strong>mode = “full”</strong>加上切片的模式和使用<strong>mode = “valid”</strong>是一样的，此处<strong>valid</strong>其实就是和卷积中的<strong>valid</strong>一样，也就是不加<strong>Padding</strong>，则卷积核和整个数组进行卷积不会出现没有全部覆盖的情况，因此两种方式任选一种。</p></blockquote><h2 id="2-方法二"><a href="#2-方法二" class="headerlink" title="2. 方法二"></a>2. 方法二</h2><pre><code>def moving_average(a, n=3) :    ret = np.cumsum(a, dtype=float) #[1,3,6,10,15]    ret[n:] = ret[n:] - ret[:-n]    return ret[n-1:] / nprint(moving_average(L,3))</code></pre><h2 id="3-方法三"><a href="#3-方法三" class="headerlink" title="3. 方法三"></a>3. 方法三</h2><pre><code>def moving_average(data, window_size):    cumsum_vec = np.cumsum(np.insert(data, 0, 0))    ma_vec = (cumsum_vec[window_size:] - cumsum_vec[:-window_size]) / window_size    return ma_vecprint(moving_average(L,3))</code></pre>]]></content>
      
      
      <categories>
          
          <category> 算法实现 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 移动平均 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>XMM-Newton软件安装</title>
      <link href="/2019/05/25/XMM-NEWTON/"/>
      <url>/2019/05/25/XMM-NEWTON/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>天体物理中处理数据的软件XMM_Newton在Ubuntu上的安装过程.</strong><br><a id="more"></a></p></blockquote><h2 id="1-运行环境与必要软件"><a href="#1-运行环境与必要软件" class="headerlink" title="1. 运行环境与必要软件"></a>1. 运行环境与必要软件</h2><blockquote><p>运行环境:   <strong>Ubuntu 18.04</strong><br>必要软件：<strong>1. heasoft-6.19src</strong>、<strong>2. sas_15.0.0-Fedora20-64</strong>、<strong>3. ds9.ubuntu17.7.6</strong></p></blockquote><h2 id="2-ubuntu18-04双系统安装过程"><a href="#2-ubuntu18-04双系统安装过程" class="headerlink" title="2. ubuntu18.04双系统安装过程"></a>2. ubuntu18.04双系统安装过程</h2><blockquote><p><a href="https://blog.csdn.net/bychen623/article/details/53543465" target="_blank" rel="noopener">安装Windows和Ubuntu双系统</a>，这篇博文讲的非常详细，可以参照此进行双系统的安装.</p></blockquote><h2 id="3-HEAsoft安装过程"><a href="#3-HEAsoft安装过程" class="headerlink" title="3. HEAsoft安装过程"></a>3. HEAsoft安装过程</h2><blockquote><p>使用<strong>XMM-SAS</strong>进行数据处理之前需要注意的是要先安装<strong>HEAsoft</strong>然后再安装<strong>XMM-SAS</strong>，其中<strong>HEAsoft</strong>是<strong>NASA</strong>开发的高能天文卫星软件包，需要注意的是如果是自己编译，对于<strong>Linux、Darwin</strong>和<strong>Cygwin</strong>用户，需要保证本地安装有<strong>C</strong>语言编译器<strong>gcc、C++</strong>编译器<strong>g++、Fortran</strong>编译器<strong>g77</strong>或者<strong>gfortran</strong>。对于<strong>Solaris</strong>用户，默认的<strong>C</strong>语言编译器是<strong>cc</strong>，<strong>C++</strong>编译器是<strong>CC</strong>，<strong>Fortran</strong>编译器是<strong>f90</strong>或<strong>f95</strong>。当然选择的编译器也可以自己定义，只需修改用户目录下的<strong>.bashrc（bash、sh、ash、ksh</strong>用户<strong>）</strong>或是<strong>.cshrc（csh</strong>或<strong>tcsh</strong>用户<strong>）</strong>文件即可.<br>要安装<strong>HEAsoft</strong>，首先要保证的是必需的库已经安装完毕，包括<strong>perl、X11</strong>，如果这些库没有安装的话，在下面的安装过程中会有相应的报错提示，到时候按照报错提示安装相应需要的东西也是可以的. (参考自：<a href="http://bzhang.lamost.org/website/archives/heasoft_install/" target="_blank" rel="noopener">HEAsoft初体验之安装篇</a>)</p><ol><li>首先需要将下载好的<strong>HEAsoft</strong>文件放入解压，可以在图形界面直接提取压缩包，也可以在<strong>shell</strong>界面下使用<strong>tar -zxvf  heasoft-6.19src.tar.gz</strong>进行解压，解压出来之后会出现下面的图.  <strong>注</strong>：<a href="https://blog.csdn.net/songbinxu/article/details/80435665" target="_blank" rel="noopener">Ubuntu 常用解压与压缩命令</a>，这篇博文详述了<strong>Ubuntu</strong>下解压与压缩的命令，可以参考.<img src= "/img/loading.gif" data-src="/2019/05/25/XMM-NEWTON/a.png" alt></li><li>在<strong>shell</strong>使用<strong>cat /etc/shells</strong>查看自己的<strong>shell</strong>版本，然后进入解压目录下的<strong>BUILD_DIR</strong>文件夹，然后在<strong>shell</strong>处于当前这个路径(<strong>BUILD_DIR</strong>所处的路径)下依次执行下面的命令：<br><strong>For bash:</strong><br><code>./configure</code><br><code>make</code><br><code>make install</code><br><strong>这里有几点需要注意： </strong><br><strong>a</strong>. 在执行<code>./configure</code>的时候如果报出一堆错误，则说明你的电脑还有一些必要的安装所需的依赖库没有安装，按照它报的错一个一个的安装，然后执行<code>./configure</code>这句命令，直到出现<strong>finished</strong>的时候才说明这句命令运行成功了.<br><strong>b</strong>. 之前我在服务器上安装的时候，依次运行上面的语句都很顺畅，但是后面在自己的电脑上安装的时候，在<code>make</code>以及<code>make install</code>的时候报出了一大堆的错误，上网查了很久资料才发现，这两句命令在自己电脑上需要与一点改动，分别改为<code>make -i</code>以及<code>make install -i</code>这样才能够顺序执行，因此上面的两个命令报错的时候请执行这里所写的两个语句，参考自：<a href="https://blog.csdn.net/zhanzheng520/article/details/21165023" target="_blank" rel="noopener">如何忽略makefile执行过程中的某些命令的错误而得以继续运行</a>.<br><strong>c</strong>. 需要注意的是上面的三个步骤需要及其漫长的时间，整体结束完毕大体需要<strong>1</strong>个小时的时间.</li><li><strong>修改.bashrc文件：</strong> <strong>.bashrc</strong>文件的修改能够让你以后在任意的目录下以任意指定的名字都能够实现<strong>HEAsoft</strong>的初始化，需要注意的是<strong>.bashrc</strong>在根目录下，而且<code>ls</code>命令是看不到的，需要使用<code>ll</code>命令才能查看，在根目录下使用<code>gedit .bashrc</code>命令打开<strong>.bashrc</strong>文件，然后在最后的地方找个空的位置加入下面的语句命令：<br><code>HEADAS=/heasoft-6.5/PLATFORM</code><br><code>export HEADAS</code><br><code>alias heainit=&#39;. $HEADAS/headas-init.sh&#39;</code><br>其中<strong>PLATFORM</strong>文件夹为名称与操作系统有关的文件夹，在我的电脑上为<strong>x86_64-unknown-linux-gnu-libc2.27-3</strong>这个名字的文件夹，而<strong>heainit</strong>其实就是以后使用这个软件处理数据之前，在<strong>shell</strong>界面初始化<strong>HEAsoft</strong>的语句，这个名字可以随意修改，主要看自己喜好。写入上面语句之后保存<strong>.bashrc</strong>文件，然后在根目录下执行<code>source .bashrc</code>语句，相当于刷新一下刚刚写进去的内容，这样就可以在任意目录输入<code>heainit</code>以初始化启动<strong>HEAsoft</strong>了，执行这句话如果没有报错什么的那么就说明<strong>HEAsoft</strong>安装成功了. <img src= "/img/loading.gif" data-src="/2019/05/25/XMM-NEWTON/b.png" alt></li></ol></blockquote><h2 id="4-XMM-SAS安装过程"><a href="#4-XMM-SAS安装过程" class="headerlink" title="4. XMM-SAS安装过程"></a>4. XMM-SAS安装过程</h2><blockquote><p>在安装完了<strong>HAEsoft</strong>之后就可以安装<strong>SAS</strong>了，整个过程比较轻松，主要是首先解压完了压缩包之后，进入解压文件夹中，然后在当前目录下执行<code>./install.sh</code>，执行完毕之后，和<strong>HEAsoft</strong>一样，要想在任意界面下初始化启动<strong>SAS</strong>的话，依旧在根目录下<code>gedit .bashrc</code>,然后在空白处写入下面语句：<br><code>HEADAS2=/home/stoner/Heasoft_and_SAS/xmm-SAS/sas_15.0.0-Fedora20-64/xmmsas_20160201_1833</code><br><code>export HEADAS2</code><br><code>alias sas=&quot;. $HEADAS2/setsas.sh&quot;</code><br>然后刷新以下<strong>.bashrc</strong>，就可以执行<strong>SAS</strong>了，需要注意的有以下几点：</p><ol><li>每次关闭了<strong>shell</strong>之后，下次再打开一个新的终端的时候需要顺次执行：<br><code>heainit</code><br><code>sas</code><br>才能够使用<strong>XMM-SAS</strong>处理数据.</li><li>需要注意的是<strong>HEAD2</strong>是为了区分<strong>HEAsoft</strong>的<strong>HEAD</strong>变量，而且必须要注意的是，<strong>.bashrc</strong>中加入的<strong>HEAsoft</strong>的命令要在<strong>XMM-SAS</strong>之前，否则会启动程序失败，无法处理数据，如下：<img src= "/img/loading.gif" data-src="https://img2018.cnblogs.com/blog/1397221/201812/1397221-20181201164318367-1439800135.png" alt></li></ol></blockquote><h2 id="5-SAOimageDS9安装过程"><a href="#5-SAOimageDS9安装过程" class="headerlink" title="5. SAOimageDS9安装过程"></a>5. SAOimageDS9安装过程</h2><blockquote><p><strong>DS9</strong>的安装很简单，只需要解压完压缩包之后，得到的解压缩文件执行下面的语句即可：<br><code>sudo mv ds9 /usr/local/bin</code><br><code>sudo chmod +x /usr/local/bin/ds9</code><br>然后就可以在任意地方输入<code>ds9</code>即可执行，需要注意的注意的是<strong>ds9</strong>显示图片需要依赖<strong>xmmgrace</strong>，你可以在终端下载这个包，也可以直接在<strong>Ubuntu 软件商店</strong>下载<strong>Grace</strong>，这样就能使用了.  <a href="https://blog.csdn.net/ShiZhixin/article/details/7469172" target="_blank" rel="noopener">IRAF 安装 for Ubuntu 10.04</a>.</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 天体物理学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> XMM_Newton </tag>
            
            <tag> 软件安装 </tag>
            
            <tag> 天体物理学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tensorboard以及Summary类总结</title>
      <link href="/2019/05/25/tensorboard-summary/"/>
      <url>/2019/05/25/tensorboard-summary/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>TensorBoard中Summary类相关信息的总结.</strong><br><a id="more"></a></p></blockquote><p><img src= "/img/loading.gif" data-src="/2019/05/25/tensorboard-summary/1558795639611.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/tensorboard-summary/1558795646326.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/tensorboard-summary/1558795651355.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/tensorboard-summary/1558795656505.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/tensorboard-summary/1558795661914.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/tensorboard-summary/1558795666368.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/tensorboard-summary/1558795671169.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/tensorboard-summary/1558795675688.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/tensorboard-summary/1558795681014.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/tensorboard-summary/1558795685491.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/tensorboard-summary/1558795690177.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/25/tensorboard-summary/1558795694809.png" alt="Alt text"></p>]]></content>
      
      
      <categories>
          
          <category> TensorFlow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tensorboard </tag>
            
            <tag> summary </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习对超新星高红移的分类</title>
      <link href="/2019/05/25/machine-Z/"/>
      <url>/2019/05/25/machine-Z/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>在中科院紫金山天文台时做的一个报告分享.</strong><br><a id="more"></a></p></blockquote><p><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795828055.png" alt="Alt text"></p><h2 id="1-ABSTRACT"><a href="#1-ABSTRACT" class="headerlink" title="1. ABSTRACT"></a>1. ABSTRACT</h2><ol><li>分类算法：<strong>High-Z</strong></li><li>回归算法：<strong>Machine-Z</strong></li><li>样本：<br><strong>Our method relies exclusively on canonical data commonly available within the first few hours after the GRB trigger. Using a sample of 284 bursts with measured redshifts.</strong></li><li>使用的机器学习算法：<strong>Random Forest</strong></li><li><strong>Validation Performance (machine-z): </strong><br><strong>the correlation coefficient between machine-z predictions and the true redshift is nearly 0.6</strong></li><li><strong>High-Z：</strong><blockquote><p><strong>20 % FPR(False Positive Rate假阳率)</strong>  ===&gt;  <strong>80 % Recall(召回率)</strong><br><strong>40 % FPR(False Positive Rate假阳率)</strong> ===&gt; <strong>100 % Recall(召回率)</strong></p></blockquote></li></ol><h2 id="2-INTRODUCTION"><a href="#2-INTRODUCTION" class="headerlink" title="2. INTRODUCTION"></a>2. INTRODUCTION</h2><ol><li>研究原因：<br>1.1 <strong>GRB的重要程度…</strong><br>1.2 <strong>由于其独特的特性, 高红移的GRB与类星体相比具有许多显着优势。(high-z GRBs have a number of significant advantages over quasars due to their unique characteristics. )</strong></li><li>目的：<br>2.1 <strong>这项工作的主要挑战是在光学发射逐步消失之前，可靠地识别适合于详细的光谱追踪的高红移爆发。基于爆发后有限的信息，必须在爆发后的头几个小时甚至几分钟内决定在大型望远镜上使用宝贵的观测时间。</strong><br><strong>(The main challenge in this work is to reliably identify high redshift bursts suitable for detailed spectroscopic follow-up before the optical emission fades away. </strong><br><strong>Decisions to use precious observing time on large telescopes must be made within the first hours or even minutes after the burst based on limited information.)</strong><br><strong>Previous attempts to screen high-z GRBs using promptly available high-energy data， while showing some promise, lacked the accuracy necessary to facilitate a reliable follow-up program. As a result, they were never widely adopted by observers</strong><br>2.2 <strong>主要困难在于从易于获得的高维数据中提取许多弱相关性并有效地组合它们包含的信息。 基于机器学习的现代方法非常适用于此目的。</strong><br><strong>The main difficulty lies in extracting numerous weak correlations from readily available high-dimensional data and efficiently combining the information they contain. A modern approach based on machine learning is ideal for this purpose.</strong></li></ol><h2 id="3-METHODOLOGY"><a href="#3-METHODOLOGY" class="headerlink" title="3. METHODOLOGY"></a>3. METHODOLOGY</h2><h3 id="3-1-GRB-Sample-and-Data-Features"><a href="#3-1-GRB-Sample-and-Data-Features" class="headerlink" title="3.1 GRB Sample and Data Features"></a>3.1 GRB Sample and Data Features</h3><blockquote><ol><li><strong>我们的样本由284个Swift GRB组成，带有光谱红移测量. 样本包括2005年至2014年底发现的GRB. 图1显示了样品中所有爆的红移分布。 最低红移值为0.033，最高值为8.26。 我们采用z = 4作为低红移和高红移的阈值。 根据该定义，284个GRB中的25个样本或大约9％是高红移. </strong><br><strong>(Our sample consists of 284 Swift GRBs with spectroscopic redshift measurements. The sample includes GRBs discovered between 2005 and the end of 2014. Fig. 1 shows the redshfit distribution of all bursts in the sample. The lowest redshift value is 0.033 and the highest is 8.26. We adopt z = 4 as the threshold between low-redshift and high-redshift bursts. Out of 284 GRBs in the sample 25 or ∼ 9% are high-redshift according to this definition.)</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795839753.png" alt="Alt text"></li></ol><p><a href="http://swift.gsfc.nasa.gov/archive/grb%20table/" target="_blank" rel="noopener">The measurements are taken from the Swift online catalog at https.</a></p><ol><li><strong>The Swift mission payload consists of three major instruments(Swift任务有效载荷包括三个主要仪器):</strong><br>2.1 <strong>the Burst Alert Telescope (BAT):</strong><br>2.1 <strong>the X-ray Telescope (XRT)</strong><br>2.2 <strong>the UV Optical Telescope (UVOT)</strong><blockquote><p><strong>BAT is a soft gamma-ray wide field instrument sensitive to photons in the energy range 15 keV to 350 keV and it is the GRB discovery instrument.</strong><br><strong>(BAT是一种对15 keV至350 keV能量范围内的光子敏感的软伽马射线宽场仪器，它是发现GRB的仪器). </strong><br><strong>Once BAT discovered a GRB and determined its sky position, the Swift satellite slews to the location of the burst so that the narrow field instruments XRT and UVOT can quickly start observing the afterglow. In order to provide a rapid machine-z redshift and high-z classification, we limited this study to readily available measurements from all three Swift instruments.</strong><br><strong>(一旦BAT发现GRB并确定其天空位置，Swift卫星就会转向爆发位置，这样窄场仪器XRT和UVOT可以快速开始观察余辉。 为了提供快速的机器-z红移和高z分类，我们将这项研究限制在所有三种Swift仪器的现成测量中). </strong></p></blockquote></li><li><strong>These measurements were adopted as numerical features for classification and regression(BAT，XRT和UVOT的测量结果作为回归与分类的样本特征)：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795846590.png" alt="Alt text"></li></ol></blockquote><h3 id="3-2-Machine-Learning-Algorithm"><a href="#3-2-Machine-Learning-Algorithm" class="headerlink" title="3.2 Machine Learning Algorithm"></a>3.2 Machine Learning Algorithm</h3><h4 id="3-2-1-Random-Forests"><a href="#3-2-1-Random-Forests" class="headerlink" title="3.2.1 Random Forests"></a>3.2.1 Random Forests</h4><blockquote><p><strong>Over the past few years the method found several interesting applications in observational astrophysics including selection of explosive transients in imaging data, classification of X-ray sources , and redshift prediction. RF has the ability to select useful features, relatively immune to data over-fitting, can handle nonlinear relationships, and provide probabilistic outputs.(在过去几年中，该方法在观测天体物理学中发现了几个有趣的应用，包括选择成像数据中的爆炸瞬态，X射线源的分类和红移预测. RF能够选择有用的特征，相对地不受数据过拟合影响，可以处理非线性关系，并提供概率输出).</strong> </p></blockquote><h4 id="3-3-2-Missing-Features-☆"><a href="#3-3-2-Missing-Features-☆" class="headerlink" title="3.3.2 Missing Features(☆)"></a>3.3.2 Missing Features(☆)</h4><blockquote><p><strong>Missing features are common in real world data and our GRB sample is no exception. A popular approach to handle missing input values is by imputation i.e. assigning values estimated from the distribution of all remaining instances(特征缺失在现实世界数据中很常见，我们的GRB样本也不例外。 处理缺失输入值的通用方法是通过估算，即分配的值来自剩余实例的分布估计).</strong><br><strong>In order to preserve all available information about the redshift we assigned all missing features to −1000. The effect on performance is negligible as long as the plug-in value is well outside the normal range for all features(为了保留有关红移的所有可用信息，我们给所有缺失的特征分配为 -1000。 只要插件值远远超出所有特征的正常范围，对性能的影响就可以忽略不计). </strong></p></blockquote><h4 id="3-3-3-Data-Imbalance-☆"><a href="#3-3-3-Data-Imbalance-☆" class="headerlink" title="3.3.3 Data Imbalance(☆)"></a>3.3.3 Data Imbalance(☆)</h4><blockquote><p><strong>The input catalog for our study is quite unbalanced with fewer than 10% of GRBs at z &gt; 4. A low fraction of high-redshift bursts in the training sample will typically result in a tendency to classify all bursts as low-redshift as the algorithm attempts to minimize the overall error rate. This imbalance will result in poor performance of the classifier on new data. One possible solution is to assign higher weights to high-z bursts during training. However, the price is often additional complexity and a tendency for overfitting.( 输入数据是非常不平衡的，在z &gt; 4时GRB的比例不到10％。训练样本中很小一部分的高红移通常会导致算法在试图最小化整体错误率的时候，将样本的类别更倾向于判别为低红移的类别。这种(数据的)不平衡将导致分类器在新数据上的性能不佳。 一种可能的解决方案是在训练期间为高红移的爆发样本分配更高的权重。 然而，代价往往是额外的复杂性和过度拟合的趋势). </strong></p><hr><ol><li><strong>数据不平衡带来的坏处：</strong><br><strong>从训练模型的角度来说，如果某类的样本数量很少，那么这个类别所提供的“信息”就太少。使用经验风险（模型在训练集上的平均损失）最小化作为模型的学习准则。设损失函数为0-1 loss（这是一种典型的均等代价的损失函数），那么优化目标就等价于错误率最小化（也就是accuracy最大化）。考虑极端情况：1000个训练样本中，正类样本999个，负类样本1个。训练过程中在某次迭代结束后，模型把所有的样本都分为正类，虽然分错了这个负类，但是所带来的损失实在微不足道，accuracy已经是99.9%，于是满足停机条件或者达到最大迭代次数之后自然没必要再优化下去，ok，到此为止，训练结束！但是这个模型没有学习到如何去判别出少数类.</strong></li><li><strong>不平衡数据下模型的评估指标.</strong></li><li><strong>不平衡数据处理方法.</strong></li></ol></blockquote><h2 id="4-HIGH-Z-CLASSIFICATION"><a href="#4-HIGH-Z-CLASSIFICATION" class="headerlink" title="4. HIGH-Z CLASSIFICATION"></a>4. HIGH-Z CLASSIFICATION</h2><h3 id="4-1-ROC-amp-AUC"><a href="#4-1-ROC-amp-AUC" class="headerlink" title="4.1 ROC &amp; AUC"></a>4.1 ROC &amp; AUC</h3><blockquote><ol><li><strong>ROC: Receiver Operating Characteristic Curve, 即受试者工作特征曲线,是反映真正率(TPR,把正例预测为正例的概率)和假正率(把负例错分为正例的概率)续变量的综合指标.</strong><br>1.1 <strong>ROC主要作用：</strong><br><strong>a. ROC曲线能很容易的查出任意阈值对学习器的泛化性能影响。</strong><br><strong>b. 有助于选择最佳的阈值。ROC曲线越靠近左上角，模型的查全率就越高。最靠近左上角的ROC曲线上的点是分类错误最少的最好阈值，其假正例和假负例总数最少。</strong><br><strong>c.可以对不同的学习器比较性能。将各个学习器的ROC曲线绘制到同一坐标中，直观地鉴别优劣，靠近左上角的ROC曲所代表的学习器准确性最高。</strong></li><li><strong>AUC: Area Under ROC Curve， AUC就是ROC曲线下的面积，衡量学习器优劣的一种性能指标.是衡量二分类模型优劣的一种评价指标,在样本不平衡的情况下，依然能够对分类器做出合理的评价, AUC对样本类别是否均衡并不敏感，这也是不均衡样本通常用AUC评价学习器性能的一个原因。</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795865411.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795870797.png" alt="Alt text"></li></ol><hr><p><strong>We compute this curve using randomized 10-fold cross validation (train on 90% of the sample and test on 10%).(我们使用10折交叉验证计算该曲线（对90％的样品进行训练，对10％进行测试)</strong></p><hr><p><strong>k-折交叉验证: k 折交叉验证通过对 k 个不同分组训练的结果进行平均来减少方差，因此模型的性能对数据的划分就不那么敏感。</strong></p><ol><li><strong>将全部样本划分为划分为k个大小相等的样本子集.</strong></li><li><strong>每一次挑选其中 1 份作为测试集，剩余 k-1 份作为训练集用于模型训练.</strong></li><li><strong>重复第二步 k 次，这样每个子集都有一次机会作为测试集，其余机会作为训练集.</strong><br>3.1 <strong>在每个训练集上训练后得到一个模型.</strong><br>3.2 <strong>用这个模型在相应的测试集上测试，计算并保存模型的评估指标.</strong></li><li><strong>计算 k 组测试结果的平均值作为模型精度的估计，并作为当前 k 折交叉验证下模型的性能指标.</strong></li><li><strong>5折交叉验证的例子：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795882024.png" alt="Alt text"></li></ol><hr><p><strong>机器学习中的数据划分:</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795888447.png" alt="Alt text"></p><hr><p><strong>数据维数过多与样本过少情况下的龙格现象:</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795901546.png" alt="Alt text"><br><strong>过拟合与欠拟合:</strong><br><strong>回归：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795908955.png" alt="Alt text"><br><strong>分类：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795915475.png" alt="Alt text"></p></blockquote><h3 id="4-2-Tuning-the-Classifier"><a href="#4-2-Tuning-the-Classifier" class="headerlink" title="4.2 Tuning the Classifier"></a>4.2 Tuning the Classifier</h3><blockquote><p><strong>We start with a pool of available features that initially contains all features in Table 1. We start with a pool of available features that initially contains all features in Table 1. The first most informative feature is selected to maximize classification performance (area under ROC curve) using only one feature at a time from the pool of N available features.(我们从表1包含的全部25个特征开始。选择第一个最具信息性的特征以最大化分类性能（ROC曲线下的面积），一次仅使用N个可用特征池中的一个特征。)</strong><br><strong>The next best feature is selected after looping over N − 1 features remaining in the pool and maximizing classification performance using two features.(在循环特征池中剩余的N-1个特征后选择下一个最佳特征，此时使用两个特征最大化分类性能)</strong><br><strong>The process continues until the pool of available features is empty. We use parameter values from Section 3.2, i.e. ntrees = 300 and nodesize = 12，The relative importance of all 25 classification features is shown in Figure 2. As more features are included in training, the area under the ROC curve increases rapidly with a maximum value of 0.89 around 8-th feature followed by a gradual decrease.(整个过程持续到特征池中所有可用特征为空为止, 所使用的参数是$n_{tree}$ = 300, node = 12. 所有25个分类特征的相对重要性如图2所示。随着训练中包含的更多特征，ROC曲线下面积迅速增加，最大值为0.89，大约为第8个特征，然后逐渐减小.)</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795924941.png" alt="Alt text"><br><strong>It is interesting to note that the 8 best features selected in this way include information from all three Swift instruments.  The absence of the total burst duration (BAT T90) on this list is somewhat surprising and may be attributed to a large intrinsic spread of burst durations that dominates the influence of time dilation on this time scale.(值得注意的是，以这种方式选择的8个最佳特征包括来自所有三个Swift仪器的信息。在该列表上没有总爆发持续时间（BAT T90）有点令人惊讶，并且可能归因于爆发持续时间的大的内在扩展，其主导了时间扩张对该时间尺度的影响。)</strong><br><strong>The ROC curve of the final high-z classifier trained using the 8 best features is shown on Fig. 3. The curve shows a steep rise and reaches 100% recall at about 40% false posive rate. We can reduce the false positive rate by half by changing the probability threshold and accepting 80% recall.(使用8个最佳特征训练的最终高z分类器的ROC曲线如图3所示。该曲线显示了陡峭的上升并且在约40％的假阳性率下达到100％的召回率(真正率)。 我们可以通过改变概率阈值和接受80％的召回率将假正率降低一半).</strong></p></blockquote><h3 id="4-3-Machine-Learned-Scoring"><a href="#4-3-Machine-Learned-Scoring" class="headerlink" title="4.3 Machine Learned Scoring"></a>4.3 Machine Learned Scoring</h3><h2 id="5-MACHINE-Z-REDSHIFT-ESTIMATOR"><a href="#5-MACHINE-Z-REDSHIFT-ESTIMATOR" class="headerlink" title="5. MACHINE-Z REDSHIFT ESTIMATOR"></a>5. MACHINE-Z REDSHIFT ESTIMATOR</h2><blockquote><p><strong>In this section,we adapt the methods from section 3 to solve a regression problem and develop an RF based redshift estimator that we call machine-z.(High-z用于分类样本是否高红移，machine-z基于RF用于预测样本实际的红移值)</strong></p></blockquote><h3 id="5-1-Tuning-the-Regressor"><a href="#5-1-Tuning-the-Regressor" class="headerlink" title="5.1 Tuning the Regressor"></a>5.1 Tuning the Regressor</h3><blockquote><ol><li><strong>Since the performance of a regressor is evaluated differently from a classifier, we performed an independent parameter search to approximately optimize input parameters of the RF regressor. For this purpose we used the “leave-one-out” cross-validation method that for N bursts consists of N runs with N − 1 instances used for training and one for testing.(由于回归与分类的评估方式不同，在此使用&lt;留一法&gt;进行交叉验证.)</strong><blockquote><p><strong>留一法交叉验证：假设样本数据有N个，将每1个样本单独作为测试集，其余N-1个样本作为训练集，依次对这N个样本进行遍历，得到N次验证，再将评估指标求平均得到最终的评估指标。留一法主要是用于样本量较小的情况时使用的交叉验证方法；在样本数目较多的情况下留一法的时间开销及其大. K折交叉验证在k=N的时候即为留一法.</strong></p></blockquote></li><li><strong>The quality of prediction is measured using the Pearson correlation coefficient between machine-z output and true redshift. Table 2 defines the search grid for approximate parameter optimization. In this case we found that a forrest of 100 fully developed trees (with as little as one burst per leaf node) and m = 5 random features per split provides the best results.The resulting correlation coefficient is 0.52.(machine-z回归器输出结果和真正的红移之间通过使用Pearson相关系数来衡量预测质量。表2定义了用于近似参数优化的搜索网格。 在这种情况下，我们发现100棵树木（每个叶节点只有一个爆）和每个分裂节点的随机特征数m=5的情况下的RF提供了最好的结果。得到的相关系数是0.52)</strong></li></ol></blockquote><h3 id="5-2-Regression-Feature-Importance"><a href="#5-2-Regression-Feature-Importance" class="headerlink" title="5.2 Regression Feature Importance"></a>5.2 Regression Feature Importance</h3><blockquote><p><strong>The area under the ROC curve is now replaced by the redshift correlation coefficient.(使用相关系数来取代ROC曲线)</strong><br><strong>The correlation coefficient starts from a sub-optimal value for the first feature, then increases, eventually flattens after the 11-th feature, and then slowly decreases beyond 16-th feature. We selected the first 11 features in this plot as input features for the machine-z estimator. Adding features beyond 11 does not improve predictions and increases the risk of overfitting or diluting the signal with noisy features.(相关系数从第一特征的次优值开始，然后增加，最终在第11个特征之后变平，然后在超过第16个特征后开始慢慢减小。 我们选择了该图中的前11个特征作为machine-z估计器的输入特征. 添加超过11个特征不会显著改善预测结果，并可能伴随过拟合的风险).</strong><br><strong>Relative importance of machine-z regression features. The Pearson correlation coefficient is shown as a function of the next best feature starting from the single best feature at the bottom of the plot. Features selected for the final machine-z estimation are shown in red.(机器z回归特征的相对重要性. Pearson从图的底部开始相关系数作为从单个最佳特征开始得到下一个最佳特征的函数。 为最终machine-z估计选择的特征以红色显示.)</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795939595.png" alt="Alt text"></p></blockquote><h3 id="5-3-Correction-for-Noise-and-Imbalance"><a href="#5-3-Correction-for-Noise-and-Imbalance" class="headerlink" title="5.3 Correction for Noise and Imbalance"></a>5.3 Correction for Noise and Imbalance</h3><blockquote><ol><li><strong>A comparison between machine-z predictions and true redshift for GRBs in the training set is presented in Fig. 6. While there is a good correlation between the predicted and the actual redshift, the range of the output values is squeezed relative to the input. This appears to be a consequence of the interaction between noisy features and the fact that high-redshift bursts are strongly underrepresented in training data (see Fig. 1). (图6显示了machine-z的预测与训练集中GRB的真正红移之间的比较. 虽然预测红移和实际红移之间存在良好的相关性，但输出值的范围相对于输入被挤压.这似乎是噪声特征之间相互作用的结果，而事实上高红移爆在训练数据集中的数目不足(underrepresented adj. 未被充分代表的，代表名额不足的))</strong><br>1.1 <img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795946324.png" alt="Alt text"></li></ol><p>1.2 <img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558795972633.png" alt="Alt text"></p><ol><li><strong>When high-redshift bursts are given higher weights (e.g. by including multiple copies of the same burst in training data), the bias observed in Fig. 6 changes. (当高红移突发被赋予更高权重时（例如，通过在训练数据中包括相同突发的多个副本），图6中观察到的偏差改变). </strong><br><strong>The final corrected redshift predictions are computed using a straight line fit to data in Fig. 6 and taking into account the cross-validation uncertainty in machine-z output:(使用直线拟合图6中的数据并考虑机器-z输出中的交叉验证不确定性来计算最终校正的红移预测：)</strong> <img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558796045177.png" alt="Alt text"></li></ol><p><strong>The final corrected machine-z predictions as a function of the true redshift are shown in Fig. 7. The range of the output is now similar to that of the input and the correlation coefficient is the same as in Figure 6.(最终校正的machine-z预测作为真正红移的函数如图7所示。输出的范围现在与输入的范围相似，相关系数与图6中的相同.)</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558796051882.png" alt="Alt text"></p><hr><p><strong>图7中有一些有趣的地方: </strong></p><ol><li><strong>First, the lower right area of the plot is not populated. This means that in most cases machine-z does not fail to recognize a high-redshift burst.(首先图7右下角是没有东西的，说明在绝大多数情况下machine-z对高红移的爆的识别并未失败.)</strong></li><li><p><strong>Second, the density of bursts peaks roughly along the dashed line, so for a significant fraction of bursts the redshift estimate is close to the true value. This can be seen more clearly in Fig. 8 showing the distribution of the relative differences between machine-z estimates and actual redshifts. (其次，爆的密度大致沿着虚线峰值，因此对于大部分的爆来说，红移估计值接近真实值。 这在图8中可以更清楚地看出，显示了machine-Z估计值与实际红移之间的相对差异的分布)</strong><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558796059879.png" alt="Alt text"></p></li><li><p><strong>Third, the algorithm does occasionally predict a high redshift for a low-z burst as shown by the upper left portion of the plot. Even though following up these false positives will tend to waste some telescope time, machine-z will rarely miss the all important high-z bursts.(第三，该算法偶尔会预测低红移爆为高红移，如图的左上部分所示。 即使跟踪这些错误的预测会浪费一些望远镜时间，但算法很少会错过所有重要的高红移爆发。)</strong></p></li><li><strong>An inconvenient side effect of our simple correction for the redshift bias is that for a few GRBs the predicted redshift is negative. This is not a problem as long as the tool is used to select high-redshift GRBs, as the negative predictions only occurr at low redshift.(我们对红移偏差的简单校正的一个不方便的副作用是，对于少数GRB，预测的红移是负的。 不过由于负值的预测仅在低红移时发生，因此对于挑选高红移GRB的这个工具来说，这都不是问题).</strong></li></ol></blockquote><h2 id="6-DISCUSSION"><a href="#6-DISCUSSION" class="headerlink" title="6. DISCUSSION"></a>6. DISCUSSION</h2><h3 id="6-1-Comparison-with-Previous-Work"><a href="#6-1-Comparison-with-Previous-Work" class="headerlink" title="6.1 Comparison with Previous Work"></a>6.1 Comparison with Previous Work</h3><blockquote><ol><li><strong>Morgan et al. (2012) was the first to apply machine learned classification to screen high redshift GRBs using promptly available Swift data.</strong></li><li><strong>The ROC curve corresponding to our data set (red curve) has a slightly larger area than that for the Morgan et al. (2012) data (blue curve). Note that the red curve rises to 100% recall more rapidly than the blue curve.(对应于我们的数据集（红色曲线）的ROC曲线具有比Morgan等人稍大的面积。 （2012）数据（蓝色曲线）。 请注意，红色曲线比蓝色曲线更快地回升到100％).</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558796067704.png" alt="Alt text"></li></ol><ol><li><strong>Fig. 10 presents another performance comparison of the two data sets. </strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558796076146.png" alt="Alt text"></li></ol></blockquote><h3 id="6-2-Validation"><a href="#6-2-Validation" class="headerlink" title="6.2 Validation"></a>6.2 Validation</h3><blockquote><p><strong>The results for individual bursts in the test sample are shown in Table 3. (表3中显示了测试样品中单个爆的结果).</strong><br><strong>Two out of 22 bursts (GRB 151112A and GRB 151027B) qualify as high-redshift according to our classification in section 2.1 (z &gt; 4). Both algorithms flag them as having high redshift. (根据我们在2.1节（z&gt; 4）中的分类，22个爆发中的两个（GRB 151112A和GRB 151027B）符合高红移。 两种算法都将它们标记为具有高红移).</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-Z/1558796083108.png" alt="Alt text"></p><p><strong>In addition to these two clear cut cases, our classifier identified 8 other bursts in the validation sample as high-z. However, out of those 8 bursts only one (GRB 151111A) has a machinez estimate z &gt; 4. (除了这两个明确的案例，我们的分类器还在验证样本中将8个其他的爆划分为高红移。然而，在这8个爆中，只有一个（GRB 151111A）具有machine-z &gt; 4)(间接说明在指示是否高红移这事儿上machine-z方法要强于high-z？).</strong><br><strong>These outcomes are consistent with our performance estimates and confirm the usefulness of our tools in prioritizing follow-up observations of candidate high-redshift GRBs.We can expect that the most robust results will be obtained if both high-z classifier and machine-z estimator predict high redshift. In this case we would have selected three candidate high-z bursts shown as gray rows in Table 3,two real ones and a single false positive. Note that the false positive (GRB 151111A) is a burst with an intermediate redshift z = 3.5(这些结果与我们的表现估计一致，确认了我们的工具在优先考虑候选高红移GRB的后续观测中的有效性。如果高z分类器和机器z估计器都预测到高红移，我们可以期望获得最稳健的结果。 在这种情况下，我们将选择三个候选高z突发，在表3中显示为灰色行，两个确实为高红移的爆和一个误报。 请注意，误报（GRB 151111A）是具有中间红移z = 3.5的爆)</strong></p></blockquote><h3 id="6-3-Extensions-to-Other-Data-Sources"><a href="#6-3-Extensions-to-Other-Data-Sources" class="headerlink" title="6.3 Extensions to Other Data Sources"></a>6.3 Extensions to Other Data Sources</h3><blockquote><p><strong>The present paper addresses redshift prediction for Swift GRBs. Transfering a trained classifier from one data set to another is very important, but typically challenging. Unfortunately, in most cases the performance is strongly degraded even if differences between data sources are purely incidental (e.g. slightly different energy ranges of flux measurements or different estimators of model parameters).(本文讨论了Swift GRB的红移预测。 将训练有素的分类器从一个数据集转移到另一个数据集非常重要，但通常具有挑战性。 不幸的是，在大多数情况下，即使数据源之间的差异纯粹是偶然的（例如，通量测量的能量范围略有不同或模型参数的不同估计），性能也会大大降低.)</strong><br><strong>If the new features are qualitatively similar to the old ones, one can shift and rescale the numbers to approximately match the distribution of each new and old feature. This requires only a modest amount of new data and may be a productive approach for future missions similar to Swift including Space-based multi-band astronomical Variable Objects Monitor (SVOM; Cordier et al. (2015)). In other cases we are forced to build new training sets and that can be time consuming.(如果新特征在质量上与旧特征相似，则可以移动和重新缩放数字以大致匹配每个新旧特征的分布。这仅需要适量的新数据，并且可能是应对以后类似于Swift的任务的有效方法，包括基于空间的多波段天文变量对象监视器（SVOM; Cordier等人（2015））在其他情况下，我们被迫建立新的训练集，这可能是耗时的).</strong><br><strong>Generic intermediate level features can be obtained for example from wavelet analysis that captures the intrinsic structure of the data and then apply a high level classfier such as RF (Ukwatta and Wozniak 2016).Those “abstract” features may prove more transferable from one data set to another and may eventually facilitate early redshift prediction for GRBs detected by future missions such as SVOM. (通用中间级特征可以例如从小波分析中获得，小波分析捕获数据的内在结构，然后应用高级分类器，例如RF。这些“抽象”特征可能证明可以从一个数据集转移到另一个数据集，并最终可能促进以后的任务（如SVOM）检测到的GRB的早期红移预测)</strong></p></blockquote><h2 id="7-SUMMARY"><a href="#7-SUMMARY" class="headerlink" title="7. SUMMARY"></a>7. SUMMARY</h2><blockquote><p><strong>The algorithm utilizes numerical and categorical features from all three instruments onboard the Swift satellite that are readily available within the first few hours after a GRB discovery. ( 该算法利用Swift卫星上所有三种仪器的数值和分类特征，这些特征在GRB发现后的最初几个小时内随时可用).</strong></p></blockquote><h2 id="附-Feature-Engineering-简要"><a href="#附-Feature-Engineering-简要" class="headerlink" title="附: Feature Engineering(简要)"></a>附: Feature Engineering(简要)</h2><blockquote><p><strong>在业界广泛流传一句话：</strong><br><strong>数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。那特征工程到底是什么呢？顾名思义，其本质是一项工程活动，主要通过一系列数据预处理的方式，使其最大限度地从原始数据中提取有用的特征以供算法和模型使用，从而提高模型的预测准确率</strong></p><hr><p><strong>完整的机器学习项目流程: </strong></p><ol><li><strong>数学抽象：指的是根据数据明确任务目标，是分类、还是回归，或者是聚类或者其他等等.</strong></li><li><strong>数据获取：数据决定了机器学习结果的上限，而算法只是尽可能逼近这个上限.</strong></li><li><strong>特征工程：特征选择好了，非常简单的算法也能得出良好、稳定的结果。这需要运用特征有效性分析的相关技术，如相关系数、卡方检验、平均互信息、条件熵、后验概率、逻辑回归权重等方法. (特征工程：数据清洗、特征处理等等)</strong></li><li><strong>模型训练与调优：开始利用算法训练模型，需对算法原理有深入理解，才能知道如何调节模型的超参数，使得结果变得更加优良 (超参数：是指在开始模型学习过程之前设置值的参数，而不是通过训练得到的参数数据)</strong></li><li><strong>模型诊断：训练后的模型需要进行调优，调优后的模型需要重新进行诊断(判断是否过拟合或者欠拟合以及误差分析等)，这是一个反复迭代不断逼近的过程，需要不断地尝试， 进而达到最优状态。</strong></li><li><strong>模型融合/集成：模型融合就是综合考虑不同模型的情况，并将它们的结果融合到一起，使结果获得提升. (Ensemble Learning—集成学习；Bagging ,Boosting, Stacking；GBDT，AdaBoost，Xgboost，RF…)</strong></li><li><strong>上线运行： 这一部分内容主要跟工程实现的相关性更大。工程上是结果导向，模型在线上运行的效果直接决定模型的成败。不单纯包括其准确程度、误差等情况，还包括其运行的速度(时间复杂度)、资源消耗程度（空间复杂度）、稳定性是否可接受.</strong></li></ol><hr><p><strong>数据缺失值处理方法(简要)：</strong></p><ol><li><strong>删除</strong>：<br>1.1 <strong>简单删除法：</strong><br><strong>此方法将存在缺失值的数据条目（对象，元组，记录）进行删除。这种方法简单易行，在对象有多个属性缺失值、被删除的含缺失值的对象与信息表中的数据量相比非常小的情况下是非常有效的。</strong><br>2.2 <strong>权重法</strong>：<br><strong>当缺失值的类型为非完全随机缺失的时候，可以通过对完整的数据加权来减小偏差。把数据不完全的个案标记后，将完整的数据个案赋予不同的权重，个案的权重可以通过logistic或probit回归求得。</strong></li><li><strong>填补</strong>：<br>2.1 <strong>人工填补（filling manually）</strong><br>2.2 <strong>特殊值填充（Treating Missing Attribute values as Special values）</strong><br>2.3 <strong>均值填充（Mean/Mode Completer）</strong><br>2.4 <strong>热卡填充（Hot deck imputation，或就近补齐）</strong><br>2.5 <strong>聚类填充(clustering imputation)</strong><br>2.6 <strong>使用所有可能的值填充（Assigning All Possible values of the Attribute）</strong><br>2.7 <strong>组合完整化方法（Combinatorial Completer）</strong><br>2.8 <strong>回归（Regression）</strong><br>2.9 <strong>极大似然估计（Max Likelihood ，ML）</strong><br>2.10 <strong>多重插补（Multiple Imputation，MI）</strong></li><li><strong>不处理：直接在包含空值的数据上进行数据挖掘。这类方法包括贝叶斯网络和人工神经网络等。</strong></li><li><a href="https://www.cnblogs.com/lantingg/p/8492631.html" target="_blank" rel="noopener">缺失值处理方法综述</a>；<a href="https://blog.csdn.net/ge341204/article/details/80720369?utm_source=blogxgwz2" target="_blank" rel="noopener">机器学习中数据缺失值处理方法</a></li></ol></blockquote>]]></content>
      
      
      <categories>
          
          <category> 天体物理学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 天体物理学 </tag>
            
            <tag> 超新星高红移 </tag>
            
            <tag> 机器学习分类 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PCA手动实现及推导</title>
      <link href="/2019/05/25/PCA/"/>
      <url>/2019/05/25/PCA/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>尝试手动实现PCA算法并对其理论进行推导.</strong><br><a id="more"></a></p></blockquote><pre><code>&#39;&#39;&#39;总结一下PCA的算法步骤：  设有m条n维数据。  1）将原始数据按列组成n行m列矩阵X  2）将X的每一行（代表一个属性字段）进行零均值化，即减去这一行的均值  3）求出协方差矩阵C=1/m*(XX^T)  4）求出协方差矩阵的特征值及对应的特征向量  5）将特征向量按对应特征值大小从上到下按行排列成矩阵，取前k行组成矩阵P  6）Y=PX即为降维到k维后的数据  # http://blog.codinglabs.org/articles/pca-tutorial.html  # https://zhuanlan.zhihu.com/p/37777074&#39;&#39;&#39;import numpy as np# 1. 如果原始数据是按照行排列的：&#39;&#39;&#39;def PCA(original_X,componens_k):  # 1. 首先获得原始数据X的均值，如果数据按照行排列，特征按照列排列，则axis=0; 否则axis=1  norm_X = X - np.mean(original_X,axis=0) # 去均值之后的数据X  # 2. 计算协方差矩阵，由于散列矩阵和协方差矩阵仅相差一个系数，对特征向量的求解不影响，因此可以不加系数  scatter_matrix = np.dot(np.transpose(norm_X),norm_X) # 由于这里数据是按照列排布的，所以C = X^T·X  # 3. 计算协方差矩阵(散列矩阵)的特征值和特征向量  eig_val, eig_vec = np.linalg.eig(scatter_matrix)  # 4. 将各自的各自的特征值和特征向量绑定在一起按照从大到小的顺序排列  eig_pairs = [(np.abs(eig_val[i]), eig_vec[:, i]) for i in range(X.shape[1])]  eig_pairs.sort(reverse=True)  # 5. 按照特征值从大到小的排列顺序得到的特征向量，取前K行组合成降维矩阵P  dim_re_matrix = np.array([ele[1] for ele in eig_pairs[:componens_k]])  dim_re_data = np.dot(norm_X,np.transpose(dim_re_matrix))  return dim_re_data&#39;&#39;&#39;# 2. 如果原始数据是按照列排列的：def PCA(original_X,componens_k):  original_X = np.transpose(original_X) # 原始数据是行排列的，这里使用转置将其转化为列排列进行试验  norm_X = original_X - np.mean(original_X,axis=1,keepdims=True)  covariance_matrix = (1 / norm_X.shape[1]) * np.dot(norm_X,np.transpose(norm_X))  eig_val, eig_vec = np.linalg.eig(covariance_matrix)  eig_pairs = [(np.abs(eig_val[i]),eig_vec[:,i]) for i in range(norm_X.shape[0])]  eig_pairs.sort(reverse=True)  dim_re_matrix = np.array([ele[1] for ele in eig_pairs[:componens_k]])  dim_re_data = np.dot(dim_re_matrix,norm_X)  return dim_re_data # [[-2.12132034 -0.70710678  0.          2.12132034  0.70710678]]# 3. 使用sklearn的PCA&#39;&#39;&#39;from sklearn.decomposition import PCAimport numpy as npdef PCA_(original_X,components_k):  pca = PCA(n_components=1)  pca.fit(original_X)  return pca.transform(original_X)&#39;&#39;&#39;if __name__ == &#39;__main__&#39;:  X = np.array([[-1, -2], [-1, 0], [0, 0], [2, 1], [0, 1]])  # X = np.array([[-1, 1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])  print(PCA_(X, 1))</code></pre>]]></content>
      
      
      <categories>
          
          <category> 算法实现 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PCA降维 </tag>
            
            <tag> 手动实现算法系列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>近期参考网页(1)</title>
      <link href="/2019/05/25/Reference-of-web-page/"/>
      <url>/2019/05/25/Reference-of-web-page/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>近期做项目中参考的一些网页.</strong><br><a id="more"></a></p></blockquote><h2 id="1-卷积神经网络可视化"><a href="#1-卷积神经网络可视化" class="headerlink" title="1. 卷积神经网络可视化"></a>1. 卷积神经网络可视化</h2><blockquote><ol><li><a href="https://www.zhihu.com/question/48279880" target="_blank" rel="noopener">知乎——怎样通俗易懂地解释反卷积？</a></li><li><a href="https://zhuanlan.zhihu.com/p/24833574" target="_blank" rel="noopener">知乎专栏——Deep Visualization:可视化并理解CNN</a></li><li><a href="https://zhuanlan.zhihu.com/p/39822145" target="_blank" rel="noopener">知乎专栏——利用可视化方法直观理解CNN</a></li><li><a href="https://zhuanlan.zhihu.com/p/36348924" target="_blank" rel="noopener">知乎专栏——Visualizing and Understanding Convolutional Networks</a></li><li><a href="https://zhuanlan.zhihu.com/p/47784506" target="_blank" rel="noopener">知乎专栏——(论文阅读)Visualizing and Understanding Convolutional</a></li><li><a href="https://cloud.tencent.com/developer/article/1087075" target="_blank" rel="noopener">(深度)Deep Visualization:可视化并理解CNN</a></li><li><a href="https://www.jianshu.com/p/7ed99d5bc8e3" target="_blank" rel="noopener">简书——卷积神经网络可视化 Visualizing and Understanding Convolutional Networks</a></li><li><a href="https://www.tinymind.cn/articles/673" target="_blank" rel="noopener">详解深度学习的可解释性研究(上篇)</a></li><li><a href="https://www.jianshu.com/p/d4012045cf43" target="_blank" rel="noopener">简书——论文学习7“Visualizing and Understanding Convolutional Networks”文章学习</a></li><li><a href="https://blog.csdn.net/bea_tree/article/details/68954650" target="_blank" rel="noopener">CSDN——CNN入门必读经典：Visualizing and Understanding Convolutional Networks</a></li><li><a href="https://www.zybuluo.com/lutingting/note/459569" target="_blank" rel="noopener">CNN网络可视化·Visualizing and Understanding Convolutional Networks</a></li><li><a href="https://blog.csdn.net/stu_sun/article/details/80628173" target="_blank" rel="noopener">CSDN——【论文翻译】Visualizing and Understanding Convolutional Networks ECCV 2014</a></li><li><a href="https://www.zhihu.com/question/39022858/answer/224446917" target="_blank" rel="noopener">知乎——能否对卷积神经网络工作原理做一个直观的解释？</a></li><li><a href="http://www.cnblogs.com/zheng1076/p/10818837.html" target="_blank" rel="noopener">卷积神经网络</a></li><li><a href="https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/" target="_blank" rel="noopener">BLOGS: An Intuitive Explanation of Convolutional Neural Networks</a></li><li><a href="https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf" target="_blank" rel="noopener">原文: Visualizing and Understanding Convolutional Networks</a></li><li><a href="https://blog.csdn.net/kklots/article/details/17136059" target="_blank" rel="noopener">CSDN——“看懂”卷积神经网(Visualizing and Understanding Convolutional Networks)</a></li><li><a href="https://ai.yanxishe.com/page/TextTranslation/1530?from=zhihu" target="_blank" rel="noopener">AI研习社——一文带你读懂 DeconvNet 上采样层（语义分割）</a></li><li><a href="https://buptldy.github.io/2016/10/29/2016-10-29-deconv/" target="_blank" rel="noopener">Transposed Convolution, Fractionally Strided Convolution or Deconvolution</a></li><li><a href="https://blog.csdn.net/u014722627/article/details/60574260" target="_blank" rel="noopener">深度学习 | 反卷积/转置卷积 的理解 transposed conv/deconv</a></li><li><a href="https://zhuanlan.zhihu.com/p/48501100" target="_blank" rel="noopener">知乎专栏——反卷积(Transposed Convolution)详细推导</a></li><li><a href="https://zhuanlan.zhihu.com/p/22293817" target="_blank" rel="noopener">CNN-卷积反卷积（2）</a></li></ol></blockquote><h2 id="2-conv2d-transpose使用"><a href="#2-conv2d-transpose使用" class="headerlink" title="2. conv2d_transpose使用"></a>2. conv2d_transpose使用</h2><blockquote><ol><li><a href="https://www.cnblogs.com/zyly/p/8991412.html" target="_blank" rel="noopener">第十四节，TensorFlow中的反卷积，反池化操作以及gradients的使用</a></li><li><a href="https://blog.csdn.net/sinat_29957455/article/details/81638650" target="_blank" rel="noopener">使用tensorboard将卷积的过程可视化</a></li><li><a href="https://blog.csdn.net/Nianzu_Ethan_Zheng/article/details/79021399" target="_blank" rel="noopener">图示理解卷积运算、逆卷积运算、Tensorflow、tf.nn.conv2d_transpose、Conv2DSlowBackpropInput: Size of out_backprop doesn</a></li><li><a href="https://www.jianshu.com/p/a897ed29a8a0" target="_blank" rel="noopener">理解tf.nn.conv2d和tf.nn.conv2d_transpose</a></li><li><a href="https://blog.csdn.net/missyougoon/article/details/85645195" target="_blank" rel="noopener">Tensorflow+VGG16实现卷积神经网络特征图可视化</a></li><li><a href="https://blog.csdn.net/u012436149/article/details/55683401" target="_blank" rel="noopener">tensorflow学习笔记(三十二):conv2d_transpose (“解卷积”)</a></li><li><a href="https://blog.csdn.net/hustwayne/article/details/83989207" target="_blank" rel="noopener">Tensorflow中转置卷积的实现理解（tf.nn.conv2d_transpose）</a></li><li><a href="https://blog.csdn.net/sinat_31486301/article/details/81711160" target="_blank" rel="noopener">tf.nn.conv2d_transpose函数</a></li><li><a href="https://blog.csdn.net/gqixf/article/details/80403809" target="_blank" rel="noopener">tf.nn.conv2d实现卷积 tf.nn.conv2d_transpose是怎样实现反卷积的？</a></li><li><a href="https://www.cnblogs.com/zyly/p/8991412.html" target="_blank" rel="noopener">第十四节，TensorFlow中的反卷积，反池化操作以及gradients的使用</a></li><li><a href="https://blog.csdn.net/yyhhlancelot/article/details/82983987" target="_blank" rel="noopener">个人总结：关于tf.nn.conv2d（卷积）与tf.nn.conv2d_transpose（反卷积）的区别</a></li><li><a href="https://zhuanlan.zhihu.com/p/31988761" target="_blank" rel="noopener">知乎专栏——关于tf中的conv2d_transpose的用法</a></li><li><a href="http://www.aboutyun.com/thread-23477-1-1.html" target="_blank" rel="noopener">[原理型] 如何使用Tensorflow可视化卷积神经网络</a></li></ol></blockquote><h2 id="3-其他"><a href="#3-其他" class="headerlink" title="3. 其他"></a>3. 其他</h2><blockquote><ol><li><a href="https://zh.gluon.ai/index.html" target="_blank" rel="noopener">动手学深度学习</a></li><li><a href="https://blog.csdn.net/huangfei711/article/details/80325946" target="_blank" rel="noopener">python argparse 模块命令行参数解析</a></li><li><a href="https://www.cnblogs.com/chaosimple/p/4153167.html" target="_blank" rel="noopener">【原】关于使用sklearn进行数据预处理 —— 归一化/标准化/正则化</a></li><li><a href="https://zhuanlan.zhihu.com/p/26394806" target="_blank" rel="noopener">BEGAN的填坑之路</a></li><li><a href="http://neupy.com/2016/12/17/hyperparameter_optimization_for_neural_networks.html" target="_blank" rel="noopener">Hyperparameter optimization for Neural Networks</a></li><li><a href="https://www.jianshu.com/p/0837b7c6ce10" target="_blank" rel="noopener">scikit-learn和tensorflow的区别</a></li><li><a href="wepe/MachineLearning">wepe/MachineLearning</a></li><li><a href="https://www.zhihu.com/question/59829734" target="_blank" rel="noopener">知乎——回归(regression)问题是否比分类(classification)问题更难用神经网络模型学好？</a></li><li><a href="https://www.jiqizhixin.com/articles/nn-learning-rate" target="_blank" rel="noopener">机器学习算法如何调参？这里有一份神经网络学习速率设置指南</a></li><li><a href="https://www.zhihu.com/question/39792141" target="_blank" rel="noopener">如何用神经网络实现连续型变量的回归预测？</a></li><li><a href="https://www.bilibili.com/video/av8215364/%E3%80%81" target="_blank" rel="noopener">深度学习调参工具HyperBoard使用演示</a></li><li><a href="https://blog.csdn.net/sinat_26917383/article/details/54022715" target="_blank" rel="noopener">学习笔记︱Nvidia DIGITS网页版深度学习框架——深度学习版SPSS</a></li></ol></blockquote><h2 id="4-视频课程"><a href="#4-视频课程" class="headerlink" title="4. 视频课程"></a>4. 视频课程</h2><blockquote><ol><li><a href="https://bestofml.com/" target="_blank" rel="noopener">The best resources in Machine Learning &amp; AI</a></li><li><a href="https://www.bilibili.com/video/av49069401/" target="_blank" rel="noopener">Stanford CS230：吴恩达 深度学习 Deep Learning | Autumn 2018</a></li><li><a href="https://www.bilibili.com/video/av46137769/" target="_blank" rel="noopener">吴恩达AI for everyone中文笔记视频(每日一更)</a></li><li><a href="https://zhuanlan.zhihu.com/p/63783676" target="_blank" rel="noopener">吴恩达新课——《CS230-深度学习基础-2019年春》课程视频分享</a></li><li><a href="https://redstonewill.com/2115/" target="_blank" rel="noopener">撒花！斯坦福深度学习最新视频发布，吴恩达主讲！</a></li><li><a href="https://www.bilibili.com/video/av46561029/" target="_blank" rel="noopener">李宏毅机器学习2019(国语)</a></li><li><a href="https://www.bilibili.com/video/av24015685/" target="_blank" rel="noopener">李宏毅深度学习理论(国语)</a></li><li><a href="https://redstonewill.com/2033/" target="_blank" rel="noopener">重磅 | 李宏毅机器学习 2019 最新版上线，中文授课！</a></li><li><a href="https://oldpan.me/ai-funny-news/stanford-cs230-new-course" target="_blank" rel="noopener">斯坦福最新机器学习视频发布~</a></li></ol></blockquote>]]></content>
      
      
      <categories>
          
          <category> 知识积累 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 参考网页 </tag>
            
            <tag> 卷积网络可视化 </tag>
            
            <tag> 反向卷积 </tag>
            
            <tag> 视频课程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习项目优化策略(2)</title>
      <link href="/2019/05/25/machine-learning-stategy-2/"/>
      <url>/2019/05/25/machine-learning-stategy-2/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>机器学习项目优化策略第二部分</strong><br><a id="more"></a></p></blockquote><h3 id="2-1-进行误差分析"><a href="#2-1-进行误差分析" class="headerlink" title="2.1 进行误差分析"></a>2.1 进行误差分析</h3><blockquote><p>如果你希望你的学习算法能够胜任人类能做的任务，但是你的算法的表现还没有达到人类的表现的话，那么人工检查一下你的算法犯的错误也许能够让你了解接下来该做什么，这个过程<strong>误差分析(Error Analysis)</strong></p></blockquote><p>还是以猫分类器为例，假设你已经在<strong>开发集</strong>上取得了$90 \%$的准确率(也就相当于$10\%$的误差)。然后团队成员注意到算法将一些狗的图片分类成了猫，此时成员针对此提出建议希望针对狗的图片进行算法的优化(比如收集更多狗的图片，或者设计一些只处理狗的算法功能之类的)，以便让猫分类器在处理狗的图片上做得更好，这个项目可能需要花费几个月的时间才能让算法在狗的图片上犯更少的错。所以问题在于：<strong>你是否应该根据此建议去开启一个项目用于专门处理狗的图片？这是否值得？</strong></p><p>使用<strong>误差分析</strong>可以让你判断一些选项或者建议是否值得去做，以上面例子为例，过程如下：</p><blockquote><ol><li>首先，收集一下比如说$100$个被算法给错误标记的<strong>开发集</strong>例子；</li><li>然后手动检查，看一下你的<strong>开发集</strong>里面有多少被算法给错误标记的例子是狗的。</li></ol></blockquote><p>现在假设那$100$个被算法错误标记的样本中，狗的图片被误标记为猫有$5$张(占$100$张的$5\%$)，这意味着$100$个错误标记的样本中，你即使完全解决了误标记为狗的问题，你也只能修正这$100$个错误中的$5$个，或者换句话说如果只有$5\%$的错误是狗的图片，那么你在狗的问题上花费了很多时间也只是收效甚微的，你的<strong>开发集</strong>的误差最多也只是从$10\%$下降到$9.5\%$。这样你就可以确定这个建议这样花大量时间是不好的，或者说给这个建议花的时间要设置一个上限。</p><p>相应的如果$100$个错误标记的样本中，狗的照片有$50$张的话，那么花费比较多的时间去解决这个问题的效果可能就很好了。对于此时，如果解决了这个问题的话，那么<strong>开发集</strong>的误差则会从$10\%$下降到$5\%$了。<br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-learning-stategy-2/1558680203383.png" alt="Alt text"><br>而这样的人工的<strong>误差分析</strong>可能仅仅花费数十分钟的时间，却能帮助整个团队判断某个可能在以后花费数个月的工作是否值得去做。</p><p>另外一点需要注意的是，有时候我们可能需要并行的去评估多个建议是否需要去执行的时候，可以采用建立表格的方式去处理，以下面的图为例：<br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-learning-stategy-2/1558680471810.png" alt="Alt text"><br>图中针对猫分类器的例子列举了几个需要并行去处理的建议，这个时候建立一张表格，表格最左边的一列是需要人工过一遍的想要去分析的图像集(比如<strong>开发集</strong>中被误分类的$100$张图片)，之后的每一列则对应你需要并行处理的问题中的每一个，最后一列可以设置为备注列，然后你对于这$100$张误分类图片开始一张图片一张图片的过，如果第一张图片属于第一个想法(问题)，那就在对应列的那里打一个勾，如果需要对某些东西进行备注，那就在相应的地方进行备注即可。有时候某些图片(数据)可能符合多个问题，所以在对应图片那一行可能不止一个打出的勾。当把这些数据过一遍之后，需要统计每个问题所占的百分比。对于上面这个例子，可以将团队分成两部分去处理两个最大占比的问题，而其他问题可能暂时不是最重要的。</p><p><strong>这个分析的结果可以给出一个估计是否值得去处理每一个不同错误类型！</strong>这个方法可能帮助你对各个不同的需要处理的问题排出一个<strong>高低优先级</strong>。</p><h3 id="2-2-清楚标注错误的数据"><a href="#2-2-清楚标注错误的数据" class="headerlink" title="2.2 清楚标注错误的数据"></a>2.2 清楚标注错误的数据</h3><blockquote><p>对于一个监督学习来说，如果你观察你的数据集，并发现有些输出标签$Y$一开始就被标记错误了，那是否值得花时间去修正这些标签呢？</p></blockquote><p>还是以猫分类器为例，数据集中图片是猫的被标注为$Y=1$, 不是猫的标注为$Y=0$。以下图为例：<br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-learning-stategy-2/1558681500908.png" alt="Alt text"><br>上图中其中一张图片的标签被错误标记为了猫。</p><p>首先我们考虑一下<strong>训练集</strong>，事实证明，深度学习算法对于<strong>训练集中</strong>的<strong>随机误差</strong>是相当稳健鲁棒的(<strong>Robust</strong>)。只要你的标记错误的例子离随机误差不太远(有时候可能是做标记的人没有注意，或者不小心按错键了…)，只要误差足够随机，<strong>那么放着这些误差不管可能也是没有问题的，而不是花费太多时间去修复它们</strong>。也即有时候修正是有价值的，有时候放着不管也是没有问题的——<strong>只要总数据集足够的大</strong>。</p><p>需要注意的是深度学习对于<strong>随机误差</strong>是稳健的<strong>(Robust)</strong>，但是对于系统性的错误就没有那么鲁棒/稳健了。比如说如果做标记的人一直把白色的狗标记为猫，那就成问题了，因为你的算法学习之后会把所有白色的狗都分类为猫。</p><p>除此之外，如果<strong>开发集</strong>和<strong>测试集</strong>中有标记错误的例子呢？一般的做法是在上一节提到的表格中加上一列，代表这个问题，然后统计被算法分错的样本中实际是人为标记的标签出错的样本有多少：<br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-learning-stategy-2/1558682411594.png" alt="Alt text"><br>这里给出的建议是对于<strong>开发集</strong>和<strong>测试集</strong>：如果这些标记错误严重影响到你在<strong>开发集</strong>上评估算法的能力了，那就应该去花时间修正这个错误；但是如果它们没有严重影响到你用开发集去评估成本偏差(<strong>cost bias</strong>)的能力，那可能就不该花宝贵的时间去处理这个问题。</p><p>这里建议看$3$个数字来确定是否值得去人工修正标记出错的数据：</p><blockquote><ol><li><strong>整体的开发集误差</strong>($10\%$)</li><li><strong>标签被错误标记引起的误差</strong>($0.6\%$)</li><li><strong>其他原因导致的错误引起的误差</strong>($9.4\%$)<br>所以此时可以判断哪个更重要去处理。</li></ol></blockquote><p>在对<strong>开发集</strong>和<strong>测试集</strong>的标签进行检查并尝试修正的时候，有一些需要考虑的东西：</p><blockquote><ol><li>不管用什么修正手段，<strong>都要同时作用在开发集和测试集上</strong>，<strong>以确保它们继续来自相同的分布</strong>。</li><li>同时考虑检验算法判断正确和判断错误的例子，因为对于判断正确的例子，有时候也可能是因为算法运气好把某个东西判断对了，在这样的特例中可能会因为修正标签而使得算法从判断正确到判断错误。</li><li>对训练集的修正可能并不和开发集以及测试集的修正同时。<br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-learning-stategy-2/1558684603276.png" alt="Alt text"></li></ol></blockquote><h3 id="2-3-快速搭建你的第一个系统，并进行迭代"><a href="#2-3-快速搭建你的第一个系统，并进行迭代" class="headerlink" title="2.3 快速搭建你的第一个系统，并进行迭代"></a>2.3 快速搭建你的第一个系统，并进行迭代</h3><blockquote><p>如果你正在开发全新的机器学习应用，通常的建议是应该尽快建立第一个系统原型并快速进行迭代。</p></blockquote><p>通常几乎对于所有的机器学习项目，在初始的时候可能有很多个方向可以前进，而且每个方向都是相对合理的，但是挑战在于如何选择一个方向集中精力去处理。因此建议如下：如果你想搭建全新的机器学习项目，那就先快速搭建好第一个系统原型，然后快速迭代。然后，利用偏差方差分析和误差分析来确定下一步优化什么。</p><p><strong>建立这个初始系统的意义在于，有一个学习过的系统可以让你确定偏差方差的范围，然后就可以确定下一步应该优化什么，让你能够进行误差分析，可以观察一些错误，然后想出所有能走的方向，然后根据排出的优先级，确定最先应该做什么。</strong><br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-learning-stategy-2/1558685779082.png" alt="Alt text"><br>如果并不是经验非常丰富的人，那么一开始不要把第一个系统弄得过于复杂。</p><h3 id="2-4-在不同的划分上进行训练并测试"><a href="#2-4-在不同的划分上进行训练并测试" class="headerlink" title="2.4 在不同的划分上进行训练并测试"></a>2.4 在不同的划分上进行训练并测试</h3><blockquote><p>深度学习算法对于训练数据的量的胃口很大，当你收集到足够多带标签的数据，构成训练集的时候，效果最好。这导致很多团队用尽一切办法收集数据，让训练集的数据量达到最大，即使有些数据甚至大部分数据都来自和<strong>开发集</strong>以及<strong>测试集</strong>不同的分布。在深度学习时代，越来越多的团队都用来自和开发集以及测试集分布不同的数据来训练，这里有一些好的做法。</p></blockquote><p>假设你现在在开发一款可以通过用户上传的图片来判断图像中物体是否是猫的<strong>app</strong>，现在你有两个数据源：</p><blockquote><ol><li>一个是你真正关心的数据分布，来自应用上传的数据；</li><li>另一个数据源就是你可以使用爬虫挖掘网页，下载下来的数据(可以获取很多取景专业的，高分辨的，数据量大的数据)</li></ol></blockquote><p>假设你真正的用户量不多，大体只能获取到$10000$张左右的图片，但是通过爬虫的方式可以从互联网获取很多的数据。因此现在的问题是一个是来自用户上传的其中一个分布的数据，而你还有一个可获取的数据量大得多的数据集，来自另一个分布，而你又不想直接用那$10000$张图片，因为这样你的训练集就太小了。使用爬虫的图片似乎有帮助，但是问题是爬虫的图片并不完全来自你想要的分布，那你改怎么做？</p><p>其中一个选择是这样：</p><blockquote><ol><li>将两组数据合并在一起，然后随机的分配到训练集、开发集和测试集。那么这么设立你的数据集有一些好处以及坏处，好处在于你的训练集、开发集和测试集都来自一个分部，便于管理。但是坏处在于(坏处还不小)，开发集中很多是来自爬虫下载的图片，而那并不是你真真正正的关心的数据分布。根据图中的例子可以计算期望得到开发集中大体有$2381$张图像来自网页，大体只有$119$张来自手机上传。而开发集的目的在于花费大部分精力去优化你真正想要优化的分布，而此时都用于优化从网页下载的图片了，这其实是你不想要的。所以这一项不建议。</li><li>训练集全部来自爬虫或者网上下载的，如果有需要，还可以加上$5000$张来自手机上传的图片。然后对于开发集和测试集都是来自手机上传的图片。这样划分的好处就在于你现在瞄准的目标就是你想要的去处理的分布。只是缺点是你的训练集的分布和开发集以及测试集之间的分布是不同的。但是事实证明，这样把数据分成训练集、开发集和测试集会给你带来长期的更好的系统性能，只是需要再加入一些特殊技巧，后面讲到。<br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-learning-stategy-2/1558688401220.png" alt="Alt text"></li></ol></blockquote><p>另一个例子是语音激活后视镜的例子，假设你现在能够获取的别的一些并非来自语音激活后视镜的例子，对于你的训练集你可以讲你拥有的所有语音数据(从其他语音识别问题中收集来的数据——下面左图就是对应的其他语音识别问题的大量数据)，而是你现在实际的跟语句激活后视镜的问题相关的数据仅有$20000$，所以这些数据实际和训练集的数据分布不大一样，这些是你真正关心的数据分布，而这些少量的数据应该被设置为你的开发集和测试集(或者分一半再给训练集中混合)。<br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-learning-stategy-2/1558689289491.png" alt="Alt text"></p><h3 id="2-5-不匹配数据划分的偏差和方差"><a href="#2-5-不匹配数据划分的偏差和方差" class="headerlink" title="2.5 不匹配数据划分的偏差和方差"></a>2.5 不匹配数据划分的偏差和方差</h3><blockquote><p>当你的训练集与开发集和测试集的分布不同的时候，应该如何分析偏差和方差？</p></blockquote><p>还是猫分类器的例子，假设在这个问题上<strong>贝叶斯误差</strong>几乎为$0\%$，而在进行误差分析的时候通常是需要看训练误差、开发误差，假设这里训练误差为$1\%$，而开发误差为$10\%$，当开发集分布和训练集相同的时候，可以说模型存在很大的方差问题，模型泛化能力差。</p><p>但是当两个数据的分布不一致的时候，这个结论就不能轻易下了：</p><blockquote><ol><li>首先这个时候算法只见过训练集的数据，没见过开发集的数据;</li><li>其次，开发集数据来自不同的分布。</li></ol></blockquote><p>因为你的数据同时改变了两个事情，因此很难确定这增加的$9\%$误差有多少是因为算法没看过开发集而导致的，又有多少是因为来自不同分布的缘故。</p><p>所以为了分辨两个因素的影响，定义一组新的数据是有意义的，我们称之为<strong>训练开发集(training_dev set)</strong>，因此这是个新的数据子集，来自于训练集分布的子集(没有经过训练)。</p><p>因此我们可以对于训练集进行随机打乱，然后从分出一部分作为训练-开发集。就像开发集和测试集得是来自同一个分布一样，训练集和训练开发集也是来自同一个分布，只是训练开发集不用于训练模型。</p><p>为了做<strong>误差分析</strong>，你应该做的是看看分类器在训练集上的误差，训练误差集上的误差以及开发集上的误差，假设:</p><blockquote><ol><li>training-error： $1\%$</li><li>training-dev-error：$9\%$</li><li>dev-error：$10\%$</li></ol></blockquote><p>根据上面的例子可以得出结论，当你从训练数据变到训练-开发数据时，误差真的上升了很多，而训练数据和训练-开发数据的差异在于你的网络结构可以看到第一部分的数据并直接在上面做训练，但是模型没有在第二部分上面直接训练。</p><p>从上面的数据中就可以看出，算法存在方差(<strong>variance</strong>)问题，因为训练-开发集的数据和训练集是来自同一分布的数据中测得的，所以可以得知，尽管你的网络结构在训练集中表现良好，<strong>但是无法泛化到来自相同分布的训练-开发集中.</strong></p><p>假设现在数据变了：</p><blockquote><ol><li>training-error： $1\%$</li><li>training-dev-error：$1.5\%$</li><li>dev-error：$10\%$</li></ol></blockquote><p>从上可以看出现在你的模型的方差问题很小了，因为当你的模型在没有见过，但是来自相同分布的训练-开发集上运行时，误差仅仅上升了一点点。但是当你转到开发集的时候，误差就大大上升了，所以这是数据不匹配(<strong>data mismatched</strong>)的问题，因为模型在训练-开发集上很好，但是在开发集上做的不好。</p><p>假设现在数据又变了：</p><blockquote><ol><li>training-error： $10\%$</li><li>training-dev-error：$11\%$</li><li>dev-error：$12\%$</li></ol></blockquote><p>需要注意的是，人类水平在这列计算机视觉问题中的<strong>贝叶斯误差</strong>的估计大概是$0\%$，因此如果你现在的模型如上面的表现的话，那说明你的模型存在<strong>偏差问题(可避免误差)</strong>。</p><p>最后一个例子：</p><blockquote><ol><li>training-error： $10\%$</li><li>training-dev-error：$11\%$</li><li>dev-error：$20\%$</li></ol></blockquote><p>此时的模型存在两个问题：</p><blockquote><ol><li>偏差较大(可避免误差较大)，因为你在训练集上都没有做好；</li><li>数据不匹配问题较大。<br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-learning-stategy-2/1558704233071.png" alt="Alt text"></li></ol></blockquote><p>因此对于这$5$个指标，我们通过分析相应之间的差距可以得知我们的模型大体是出在了什么问题上，假设：</p><blockquote><ol><li><strong>Human Level：</strong> $4\%$</li><li><strong>Training-set Error：</strong> $7\%$</li><li><strong>Training-Dev-set Error：</strong> $10\%$</li><li><strong>Dev-set Error：</strong> $12\%$</li><li><strong>Test-set Error：</strong> $12\%$</li></ol><hr><ol><li>其中$1$和$2$之间得出可避免误差(偏差)有多大；</li><li>$2$和$3$之间表明了方差的大小，体现了你的模型从训练集推广到训练-开发集时效果如何？</li><li>$3$和$4$则告诉你数据不匹配的问题大体有多大？</li><li>$4$和$5$之间的差距则告诉你对开发集的过拟合程度，所以如果差距很大，则说明模型对开发集过拟合了(开发集和测试集必须得是来自同一个分布的)。<br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-learning-stategy-2/1558705020259.png" alt="Alt text"></li><li>如果出现上图最右边的情况的话，说明可能你的开发测试集的难度比训练集的难度要小。<br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-learning-stategy-2/1558705575568.png" alt="Alt text"></li></ol></blockquote><h3 id="2-6-定位数据不匹配"><a href="#2-6-定位数据不匹配" class="headerlink" title="2.6 定位数据不匹配"></a>2.6 定位数据不匹配</h3><blockquote><p>需要注意的是，当你的训练集的数据分布和开发集的数据分布不相同的时候，如果误差分析显示你的模型存在数据不匹配的问题，该怎么办? 比较遗憾的是这个问题没有完全系统的解决方案，但是我们可以做一下可能会有帮助的尝试。</p></blockquote><p>假设现在模型有比较严重的数据不匹配问题，一个具体的做法是通过误差分析尝试了解训练集和开发集的具体差异，以语音激活后视镜的例子为例：在数据不匹配的问题下，现在我们需要查看一下来自开发集的样本，尝试弄清楚开发集和训练集到底有什么不同。比方说你发现很多开发集样本噪声过多，这将得到你的开发集和训练集的差异之一。</p><p>因此了解开发测试集误差的性质时，你就有可能知道开发集跟训练集的不同之处，或者了解到开发集可能更加难以识别等。<strong>因此一个可能的办法是尝试把训练数据变得更像开发集一点，或者收集更多类似开发集和测试集的数据。</strong></p><p>比方说当你知道开发集和训练集的不同点来自于某个噪声的话，那你可以通过模拟车辆噪声的方式去让训练集更像开发集一点。而这个就是一种<strong>人工合成数据</strong>的方式。以上对于具体的问题处理方式不同，所以难以系统的进行处理，但是这种加入人工经验去解决问题的思路虽不能保证百分百有限，但是在实际中多数时候都是比较有成效的。<br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-learning-stategy-2/1558706460024.png" alt="Alt text"></p><hr><p>以建立语音识别系统为例，也许实际上你没有那么多实际在汽车背景噪声下录取的音频，但是我们可以进行<strong>合成</strong>。所以假设你录制了大量的清晰的音频，那你可以通过人工合成的方式在清晰音频中加入汽车背景噪声。<strong>通过人工合成数据，你可以快速的制造更多的训练数据，那就不需要花时间实际出去收集数据了。</strong></p><p>因此如果误差分析得出的结果是你的训练数据和开发集之间存在数据不匹配问题(比如开发集的数据存在车辆背景噪声)，那么这个时候通过人工合成的数据喂给你的算法就是合理的。</p><blockquote><p><strong>不过这里需要注意的一点是：</strong>如果你训练数据(清晰的音频)有$10000$个小时，而你录制的汽车噪声只有$1$个小时的话，那么对于合成的数据而言，人听起来可能觉得没什么问题，但是这里有个风险就是有可能你的算法最后会对这个$1$个小时的汽车噪声过拟合。<br>特别的，对于所有汽车噪声背景所在的集合中，如果你只录了一个小时汽车噪声，那么对于所有汽车噪声背景的集合，你可能只模拟了全部数据空间中的一小部分。当你从整个噪声数据空间很小的一个子集出发合成数据的时候，网络模型可能就会对你这一小时的汽车噪声过拟合。而如果你使用$10000$小时不重复的汽车噪声(不考虑是否能够做到以及怎么做到)，那么合成的数据对性能提升可能会更好。</p></blockquote><p><img src= "/img/loading.gif" data-src="/2019/05/25/machine-learning-stategy-2/1558707501631.png" alt="Alt text"></p><p>最后需要说明的是对于数据不匹配的问题来说，使用人工合成数据提升系统性能的例子很多，这证明人工合成数据是有效的，但是需要注意的是，一定要谨慎，要记住你有可能从所有可能性的空间中只选了很小一部分去模拟数据。</p><h3 id="2-7-迁移学习"><a href="#2-7-迁移学习" class="headerlink" title="2.7 迁移学习"></a>2.7 迁移学习</h3><blockquote><p>深度学习中最强大的理念之一就是有时候神经网络可以从一个任务中学习到知识，并将这些知识应用到另一个独立的任务中。比如现在你训练好了一个神经网络能够识别像猫这样的对象，然后使用这些学习到的知识去帮助你更好的阅读<strong>X射线扫描图</strong>，这就是所谓的<strong>迁移学习</strong>。</p></blockquote><p><img src= "/img/loading.gif" data-src="/2019/05/25/machine-learning-stategy-2/1558711774948.png" alt="Alt text"><br>假设你现在训练了一个神经网络，输入是一些图像，输出是一些识别对象(猫猫狗狗啥的)，那么当你准备将学习到的知识迁移到别的方面的时候，比方说放射科的X射线扫描图的时候，你可以将最后一层的神经网络输出层拿走，以及最后一层的输入权重给删掉，然后为最后一层重新赋予随机权重，然后将其放在放射诊断数据中进行训练。</p><p>具体来说，第一阶段中当你进行图像识别任务训练的时候，你可以训练神经网络的所有常用参数，所有权重以及所有层，这样你就得到了一个能够做图像识别预测的网络，在训练完这个神经网络之后，要实现迁移学习，你要做的就是将数据集换成新的$(x, y)$数据对，现在这些数据对就变成了放射科图像，你要做的就是初始化最后一层的权重，这个称之为$\omega^{[l]}, b^{[l]}$随机初始化，现在我们在这个新的数据集上重新训练网络。</p><p>要使用放射科数据集重新训练神经网络的做法有几种：</p><blockquote><ol><li>如果你的放射科数据集很小，你可能只需要重新训练最后一层的权重，并保持前面的参数不动，经验规则就是如果你的新的数据集比较小，那么就只训练输出层钱的最后一两层，而数据很多的时候，也许你可以重新训练神经网络中所有的参数；</li><li>如果放射科的数据足够多，那么你可以重新神经网络剩下的所有层；</li><li>当你新的数据足够多的时候，你重新训练神经网络中所有的参数的时候，那么在图像识别数据进行的初期训练阶段被称之为<strong>预训练(pre-training)</strong>，因为你使用图像识别数据去训练的时候，是去预先初始化神经网络的权重，然后如果你以后更新所有权重然后在放射科数据上进行训练，这个过程被称之为<strong>微调(fine-tuning)</strong>。</li></ol></blockquote><p>为何上面的迁移是有效果的呢？原因如下：</p><blockquote><p>有很多低层次特征，比如说边缘检测、曲线检测等从非常大的图像识别数据集中学习得到了这些能力，可能是比较有助于你的学习算法在放射科诊断中做的更好的，因为算法学习到了很多结构信息、图像形状信息，其中一些知识可能是很有用的。因此学会了图像识别，它可能学到了足够多的信息，可以了解不同图像的组成部分是怎样的，它学习到了点、曲线等等知识。</p></blockquote><hr><p>另一个例子是假设你现在的网络学习到了通过一段音频将听到的东西进行输出的算法，假设现在我们现在想要搭建一个<strong>唤醒词</strong>或者<strong>触发词</strong>检测系统，要做到这一点你可能需要去掉神经网络最后一层，然后加入新的输出节点(有时候加入的可能不止一个新的节点，视不同项目而定)，甚至有时候需要加入新的几层去做想要的项目，再次提醒的是，需要根据你的新数据的量的多少去决定你是只需要重新训练网络新的层，还是需要重新训练更多的层。</p><p>那么<strong>迁移学习</strong>什么时候是有意义的呢？<strong>迁移学习起作用的场合是迁移来源的问题中你有很多数据，但是迁移目标的问题中你没有那么多的数据</strong>，例如图像识别任务中你有一百万条数据，因此你有很多数据使得神经网络前面几层学习到如何识别很多有用的特征，但是对于放射科图像的问题中假设你仅有一百条数据，所以你从图像识别的训练中可以学习到很多有用的知识并将其迁移到放射科识别任务的问题中。</p><p>或者说对于语音识别，也许你已经有一万小时的数据训练过你的语言识别系统了，那么你从这一万小时的数据中可以学到很多人类声音的特征，因此在这种情况下预先学到很多人类声音的特征、人类语言的组成部分等等知识，将帮助你建立一个很好的唤醒词检测系统。</p><p>因此总结一下，什么时候迁移学习是有意义的：</p><blockquote><ol><li>当输入都是相同的类型的数据的时候，比如第一个例子中输入都是图像，第二个例子中输入都是音频；</li><li>当任务<strong>A</strong>的数据比任务<strong>B</strong>的数据多得多的时候；</li><li>当任务<strong>A</strong>的低层次特征可以帮助到任务<strong>B</strong>进行学习的时候。<br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-learning-stategy-2/1558711790357.png" alt="Alt text"></li></ol></blockquote><h3 id="2-8-多任务学习"><a href="#2-8-多任务学习" class="headerlink" title="2.8 多任务学习"></a>2.8 多任务学习</h3><blockquote><p>在多任务学习中，是通过试图让单个神经网络同时做几件事情，然后希望这里的每个任务都能帮助到其他的任务。</p></blockquote><p>假设你现在在研发无人驾驶车辆，那么你的无人驾驶车可能需要同时检验不同的物体，比如检验行人、车辆、停车标志、交通信号灯等。那么对于图中的输入就是那张照片，但是输出不在是一个单一的标签$y^{(i)}$，而是$4$个标签了，因此是一个$4 \times 1$的向量了，而此时总的标签值为：</p><script type="math/tex; mode=display">        Y =         \begin{pmatrix}        y^{(1)} & y^{(2)} & y^{(3)} & \cdots & y^{(m)} \\        \end{pmatrix}</script><script type="math/tex; mode=display">Y \in R^{4 \times m}</script><p>而在之前，$Y \in R^{1 \times m}$<br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-learning-stategy-2/1558712728720.png" alt="Alt text"><br>此时对于这个网络架构的损失函数如下：</p><script type="math/tex; mode=display">Loss = \frac{1}{m} \sum_{i=1}^{m} \sum_{j=1}^{4} \cal{L}(\hat{y}^{(i)}_{j} - y^{(i)}_{j})</script><p>其中损失函数通常为：</p><script type="math/tex; mode=display">\cal{L} = -y^{(i)}·\log{\hat{y}^{(i)}_{j}} - (1 - y^{(i)})·\log{(1 - \hat{y}^{(i)}_{j})}</script><p>需要和<strong>softmax</strong>回归相区别的是，<strong>softmax</strong>回归是将单个标签分配给单个样本(多类别单标签)，而这里的项目中则是一张图片可以有多个不同的标签。以上就是一个多任务学习的例子，因为你是使用单个神经网络观察每张图片然后解决四个问题。当然你可以训练四个不同的神经网络做四件事，但是如果神经网络的早起特征在识别不同的物体时都会用到的话，你会发现训练一个神经网络做四件事会比训练四个完全独立的神经网络分别做四件事的性能更好，这就是多任务学习的力量。</p><p>当然事实证明，多任务学习也可以处理图像只有部分物体被标记的情况，比如在给数据标签的时候，有些样本仅有部分标签的标记，其他的都是问号：</p><script type="math/tex; mode=display">        \begin{pmatrix}        1 & 1 & \vdots  & ? \\        0 & 1 & \vdots  & ? \\        ? & ? & \vdots  & 1 \\        ? & ? & \vdots  & ? \\        \end{pmatrix}</script><p>即使是这样的数据集(只有一小部分标签)，也可以在上面的网络中训练算法同时做四个任务，相应的损失函数就只对带$0$和$1$的标签的$j$值求和，对于问号项，在求和的时候忽略这一项就是了。<br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-learning-stategy-2/1558714464869.png" alt="Alt text"></p><p>那么多任务学习在什么时候是有意义的呢？</p><blockquote><ol><li>当你训练的任务可以共用低层次特征的时候，对于无人驾驶来说，交通灯，行人等物体是有相似的特征的，也许能帮你识别停车标志。</li><li>这个准则不是绝对的，所以不一定对。但是很多成功的多任务学习案例中可以看到：如果每个任务的数据量很接近。比如在迁移学习中一个任务<strong>A</strong>有很多的样本可以帮助提升样本量很少的任务<strong>B</strong>去提升性能，而假设在多任务学习中有一百个任务，每个任务的样本数大体有$1000$个，那么对于想要加强某个单任务的表现：比方说第$100$个任务，那么如果单独去完成这个任务，只有$1000$个样本去训练，但是通过其他$99$个任务的训练，这些加起来一共有$99000$个样本，这可能就会大幅度提升算法的性能，可以提供很多的知识来增强这个单个任务的性能。因此需要其他任务加起来的数据量远大于这个单个任务的数据量。</li><li>在训练一个巨大的神经网络的时候同时做好所有的工作。</li><li>根据研究发现，当神经网络不够巨大的时候，多任务的性能会比不上多个神经网络一一对应的各个任务，但是神经网络足够大的时候，多任务学习的性能就会比较好。</li></ol></blockquote><p>实践中多任务学习的使用频率没有迁移学习使用频率高。<br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-learning-stategy-2/1558715236374.png" alt="Alt text"></p><h3 id="2-9-端对端学习"><a href="#2-9-端对端学习" class="headerlink" title="2.9 端对端学习"></a>2.9 端对端学习</h3><blockquote><p>以前的一些数据处理系统或者学习系统，它们需要多个阶段的处理，而<strong>端对端学习</strong>则是忽略所有这些不同的阶段，使用单个神经网络代替它。</p></blockquote><p>以语音识别系统为例，输入$x$是一段音频，输出$y$则是这段音频的听写文本。所以传统上，语音识别系统需要很多阶段需要处理：首先你需要提取一些手工设计的音频特征(<strong>例如：MFCC，一种从音频中提取一组特定的人工设计的特征的算法</strong>)；在提取了低级特征之后，应用机器学习算法在音频片段中找到音位(<strong>音位是声音的基本单位</strong>)；然后将音位串在一起构成独立词；最后将词串起来构成音频片段的听写文本。</p><p>因此和这种有很多阶段的流水线相比，<strong>端对端学习</strong>做的是，训练一个巨大的神经网络，输入就是一段音频，而输出直接是听写文本。</p><p><strong>AI</strong>的其中一个有趣的社会学效应是，随着端对<strong>端深度学习系统</strong>(<strong>只需要把训练集拿过来，直觉学习到了x和y的函数映射，直接绕过中间很多步骤</strong>)表现得更好以后，有一些花费了大量时间，甚至是整个事业生涯设计出流水线各个步骤的研究员们(包括像什么语音识别领域，计算机视觉领域等)来说可能就比较难受了。</p><p><strong>端对端学习</strong>的一个挑战是你可能需要<strong>大量的</strong>数据才能够让系统表现良好。如果你的语言识别系统中的数据量大体在$3000$小时，那么传统的流水线性能会更好；但是如果你有比方说$10000$甚至$100000$小时的数据的时候，<strong>端对端学习</strong>性能就会有很大提升。<br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-learning-stategy-2/1558749040405.png" alt="Alt text"></p><hr><p>另一个例子是面部识别门禁系统，不过这里不是一步到位，由于存在人员出现在摄像头位置远近各处这个问题，于是将问题拆解成了两个更简单的子任务来处理：</p><blockquote><ol><li>首先运行某个软件来检测人脸，所以第一个检测器找的是人脸的位置；</li><li>检测到人脸之后，放大图像中人脸的那部分(裁切图像，使得人脸居中显示)，然后再将这部分图像喂给网络结构，让网络去学习检测来人的身份。</li></ol></blockquote><p>相较于一步到位，把这个问题分解成更简单的两个步骤更有效：第一步首先弄清楚脸的位置在哪儿；第二步是弄清楚这张脸是谁(通过输入的裁切之后的脸与所有人员的脸进行比较)。<strong>需要注意的是这个两步走的方式之所有有效的一个重要原因就是每一步的数据量都是超级多的，相较而言，一步到位的数据量就很少了(x就是门禁系统拍摄的图像，y是那个人的身份)</strong>。也就是说因为你没有足够的数据去解决这个端对端学习问题，但是你有足够多的数据来解决子问题1和子问题2，因此把这个问题拆解成两个子问题，比纯粹的端对端学习要有更好的效果。<br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-learning-stategy-2/1558750056739.png" alt="Alt text"></p><p>其他的例子：机器翻译(超级多的数据)<br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-learning-stategy-2/1558750251455.png" alt="Alt text"></p><h3 id="2-10-是否应该使用端对端学习"><a href="#2-10-是否应该使用端对端学习" class="headerlink" title="2.10 是否应该使用端对端学习"></a>2.10 是否应该使用端对端学习</h3><blockquote><p>给出相应条件，用于判断是否该使用端对端学习。</p></blockquote><p><strong>1. 端对端学习的好处：</strong></p><blockquote><p>1.1 端对端学习只是让数据说话，如果有<strong>足够多的数据</strong>，那么不管从$x$到$y$的映射函数该是什么，如果你训练一个足够大的神经网络，可能更能够根据足够多的数据去捕获数据中的任何统计信息，而不是被迫引入人类的成见。(比如早起的语音识别系统中提出的音位，很有可能就是语音学家臆想出来的一个概念而已，因此让网络自由的学习它想要学习到的内容可能比强迫它跟从人类的成见要得到的结果更好)</p><p>1.2 所需的手工设计组件更少，这样能够简化你的设计工作流程。</p></blockquote><p><strong>2. 端对端学习的坏处：</strong></p><blockquote><p>2.1 需要<strong>大量的数据</strong>(对于一些任务，可以将其通过拆解成多个子任务的方式解决，其中各个子任务的数据量有很多的时候)</p><p>2.2 排除了一些可能很有用的手工组件(对于有些问题，手工组件可能是把人类知识直接注入算法的途径，而这个总不是一件坏事，当你有成吨的数据的时候，手工设计的东西就不太重要了，但是当你数据不足的时候，手工设计的组件可能就很有用了)<br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-learning-stategy-2/1558751922303.png" alt="Alt text"></p></blockquote><p>因此，端对端学习的一个关键就在于数据量是否足够多的。<br>还有一个需要注意的是，在一个很复杂的问题中，并非直接使用端对端就是最好的方法，因为目前能收集到的数据，还有我们现在训练神经网络的能力是有限的，因此某些问题还是需要某些专门的算法才是比较好的结果。<br><img src= "/img/loading.gif" data-src="/2019/05/25/machine-learning-stategy-2/1558752442279.png" alt="Alt text"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习策略 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 优化策略 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习项目优化策略(1)</title>
      <link href="/2019/05/24/machine-learning-stategy/"/>
      <url>/2019/05/24/machine-learning-stategy/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>非常详细的机器学习和深度学习优化策略.</strong><br><a id="more"></a></p></blockquote><h2 id="1-为什么是ML策略"><a href="#1-为什么是ML策略" class="headerlink" title="1. 为什么是ML策略"></a>1. 为什么是ML策略</h2><p>假设你现在有一个识别猫的项目准确率达到了$90 \%$，此时你可能有很多的想法去<strong>改善优化</strong>你的系统，比如：<br><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558593688809.png" alt="Alt text"><br>当你在尝试优化一个深度学习项目的时候，你通常可以有很多想法可以尝试，但是问题在于如果你做了错误的选择的时候，你完全有可能浪费6个月的时候往错误的方向前进，而在6个月之后才意识到这个方法更本不管用。</p><h2 id="2-正交化-Orthogonalization"><a href="#2-正交化-Orthogonalization" class="headerlink" title="2. 正交化(Orthogonalization)"></a>2. 正交化(Orthogonalization)</h2><p>下面是两个正交化的例子：<br><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558594429173.png" alt="Alt text"></p><p>要想得到一个好的监督学习系统，你需要调节系统的参数来确保四件事：</p><blockquote><ol><li>首先确保在训练集上得到的结果不错(<strong>Fit training set well on cost function</strong>)，所以训练集的表现必须通过某种评估达到可接受的程度，这意味着对于某一些应用来说这可能需要达到人类平均水平的表现;</li><li>在训练集上达到不错的表现之后，接着就要在开发集(<strong>Dev_set</strong>)/交叉验证集希望达到好的表现(<strong>Fit dev set well on cost function</strong>);</li><li>在测试集上达到不错的表现(<strong>Fit test set well on cost function</strong>);</li><li>最后在实际的使用中达到令人满意的表现(<strong>Performs well in real world</strong>).</li></ol></blockquote><p>因此在优化你的项目过程中:</p><blockquote><ol><li>如果算法在<strong>cost function</strong>上不能够很好的拟合训练集的时候，你需要设置一组特定的旋钮来调整你的算法，来更好的拟合训练集，而这些旋钮可能是: </li></ol><ul><li><strong>①训练更大的网络</strong>；</li><li><strong>②切换更好的优化算法——Adam or other</strong>；</li><li><strong>③….</strong></li></ul><ol><li>如果在开发集上拟合效果很差的话，这时候就需要另一些独立正交(<strong>orthogonalization</strong>)的旋钮：</li></ol><ul><li><strong>①regularization</strong>；</li><li><strong>②增大训练集</strong>；</li><li><strong>③…</strong></li></ul><ol><li>如果在上面两个中都拟合的很好，但是在测试集中效果不好的话，另一组正交旋钮：</li></ol><ul><li><strong>①更大的开发集(因为如果在开发集中效果好，但是测试集中效果不好说明模型对开发集过拟合了)</strong>；</li><li><strong>②…</strong></li></ul><ol><li>如果在实际使用中表现不好那么：</li></ol><ul><li><strong>①改变开发集或者成本函数(因为根据某个成本函数，系统在测试集上表现很好，但是在实际应用中效果不好，那么意味着你的开发集的分布设置的不对，或者你的成本函数测量指标不对)</strong><br><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558595870814.png" alt="Alt text"></li></ul></blockquote><h2 id="3-单一数字评估指标"><a href="#3-单一数字评估指标" class="headerlink" title="3. 单一数字评估指标"></a>3. 单一数字评估指标</h2><p>无论是调整超参数，或者是尝试不同的学习算法，或者是在搭建机器学习系统的时候尝试其他不同的手段，如果使用单一数字评估指标，你的进展会加快很多，它可以快速的告诉你新尝试的手段是否比之前的手段要好. <strong>所以在开始一个机器学习项目的时候，一个比较好的措施是为对应的项目问题设置一个单实数评估指标.</strong><br><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558602946574.png" alt="Alt text"></p><p>如果对于项目中有多个评估指标的，比方说分类中的<strong>查准率(Precision)</strong>和<strong>查全率(Recall)</strong>，这个时候就可以将其合并在一起得到一个单一的数字评估指标——<strong>F1 Score</strong>.</p><p>对于很多机器学习团队来说，他们有一个明确的<strong>开发集(Dev_set)</strong>用来测量<strong>查准率</strong>和<strong>查全率</strong>(对于分类来说，如果是别的不同的项目则使用开发集去测量别的指标)，再加上一个<strong>单一数值评估指标(单实数评估指标)</strong>用于判断不同的模型之间谁更优，这样可以加速改进你的机器学习算法的迭代过程.</p><p><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558604227078.png" alt="Alt text"></p><h2 id="4-满足和优化指标"><a href="#4-满足和优化指标" class="headerlink" title="4. 满足和优化指标"></a>4. 满足和优化指标</h2><p>有时候要把所有估计的事情组合成单实数评估指标并不是一件容易的事情，这个时候可能就需要用到<strong>满足</strong>和<strong>优化</strong>指标很重要了.</p><p><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558604481135.png" alt="Alt text"><br>依旧以猫分类器这个机器学习项目为例，左边是多个分类器的<strong>准确率指标</strong>(也可是别的评估指标), 右边是另一个我们不得不考虑的另一个指标：<strong>分类一张图片所需的时间</strong>. 当然这里可以将<strong>准确率</strong>和<strong>运行时间</strong>组合成一个整体的评估指标，例如总体成本为: $Cost = Accuracy - 0.5·RunningTime$，但是对于这两个指标来说，这种方式可能以一种过于刻意的方式将其组合起来了. </p><p>这里可以有另一种方式：比如你可以选择一个分类器能够最大限度的提高准确率，但同时必须满足运行时间要求(假设上限为<strong>100 ms</strong>)，此时我们就说<strong>准确率</strong>是一个<strong>优化指标(Optimizing Metric)</strong>,因为你想最大化它；而运行时间就是满足指标(<strong>Satisficing Metric</strong>)，因为你只要满足小于<strong>100 ms</strong>的要求后你就可以不用在乎这个指标有多好了或者说至少没那么在乎了，因为实际在运行的时候小于<strong>100 ms</strong>，你的用户就不会在乎了，不管是<strong>80 ms</strong>还是<strong>50 ms</strong>. 所以这是一个相当相当合理的权衡方式，或者说将准确度和运行时间结合起来的方式.</p><p>更加一般的来说，如果你有<strong>N</strong>个指标需要考虑的时候，有时候选择其中一个指标作为<strong>优化指标</strong>是合理的，然后你就尽力去优化它；然后把剩下的<strong>N-1</strong>个指标作为<strong>满足指标</strong>，意思就是只要他们达到一定阈值以后，超过阈值多少之后的表现就变得没那么重要了.</p><hr><p>另一个例子：假设你正在构建一个系统来检测唤醒语，也叫触发词.<br><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558606240799.png" alt="Alt text"></p><hr><p><strong>Summy: </strong></p><blockquote><p>当你需要顾及多个指标的时候，比如有一个优化指标需要尽可能的优化，然后还有一个或者多个满足指标需要达到一定门槛的时候，上面的方式就是一个在观察多个<strong>cost</strong>的时候选择最优的那个方法.</p></blockquote><h2 id="5-训练-开发-测试集的划分"><a href="#5-训练-开发-测试集的划分" class="headerlink" title="5. 训练/开发/测试集的划分"></a>5. 训练/开发/测试集的划分</h2><blockquote><p><strong>Dev_Set = Development Set = Cross Validation Set</strong></p></blockquote><p>设置<strong>训练集/开发集/测试集</strong>的方式将会大大影响团队在建立机器学习应用方面取得进展的速度。设定完毕之后使用<strong>训练集</strong>训练多个不同的模型，然后使用<strong>开发集</strong>来评估不同的模型，选择最好的一个，然后不断迭代去改善开发集的性能直到最后得到一个令你满意的<strong>cost</strong>，最后再在测试集上进行评估.</p><p>依旧是一猫分类器作为例子，假设你在一下区域运营：<br><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558612555796.png" alt="Alt text"><br>那么你应该在以上区域中如何设置<strong>开发集</strong>以及<strong>测试集</strong>呢？其中一种做法是你随机的在其中4个区域选择做<strong>开发集</strong>，然后在另外4个区域中选择做<strong>测试集</strong>，试试证明<strong>这个想法是非常糟糕的</strong>，因为这样的话你的<strong>你的开发集和测试集是来自不同的分布的</strong>，正确的做法是要确保两个集合来自相同的分布。</p><p>设立你的<strong>开发集</strong>加上一个<strong>单实数评估指标</strong>就像定下目标，然后告诉你的团队要做的就是瞄准靶心，因为一旦建立这样<strong>开发集</strong>和<strong>指标</strong>以后，团队就可以快速迭代，尝试不同的想法，跑实验，直到选出最好的模型。但是上面的例子中设立的<strong>开发集</strong>和<strong>测试集</strong>在跑完模型之后，由于两个集合的分布差异巨大，最后发现努力了几个月的结果最后在测试集上却表现不佳。就像训练调参的时候设定的靶心在一个方向，结果在测试的时候却需要对准另一个放心的靶心一样。<br><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558613433325.png" alt="Alt text"></p><p>所以为了避免以上的问题，比较好的做法是：<strong>将所有数据进行随机洗牌，然后在进行开发集和测试集的划分，这样使得两个集合的数据来自同一个分布</strong>.</p><hr><p>另一个例子是这样的：<br>项目是包含中等收入邮政编码的贷款审批数据，当输入为贷款申请，项目要做的就是预测输出为是否有还贷能力？这套系统用于帮助银行判断是否批准贷款。所以<strong>开发集</strong>来自贷款申请，这些贷款申请来自中等收入邮政编码(<strong>Zip Code</strong>)。</p><p>当在上面数据训练几个月之后，团队突然决定要在低收入邮政编码上测试一下，当然，中等收入和低收入邮政编码的数据分布是很不一样的，虽然他们花了大量的时间针对前面那组数据对分类器进行优化，但是系统对后面那组数据的效果很差，因此这个团队浪费了几个月的时间。<br><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558613969782.png" alt="Alt text"></p><p>因此选择的<strong>开发集</strong>和<strong>测试集</strong>是要能够反映你未来能够得到好结果的数据。<br><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558614123598.png" alt="Alt text"></p><h2 id="6-开发集和测试集设置的大小"><a href="#6-开发集和测试集设置的大小" class="headerlink" title="6. 开发集和测试集设置的大小"></a>6. 开发集和测试集设置的大小</h2><blockquote><ol><li>机器学习中，以前的经验法则：<br>取得的全部数据以$70 \%$和$30 \%$的比例进行<strong>训练集</strong>和<strong>测试集</strong>的划分；或者是$60 \%$、$20 \%$和$20 \%$的比例划分为<strong>训练集</strong>、<strong>开发集</strong>和<strong>测试集</strong>。在机器学习早期的时候这样是很合理的，尤其是早期数据集比较小的时候(比如100个，1000个甚至是10000个左右的时候).</li><li>对于现在数据量超大的深度学习中：<br>划分比例按照$98 \%$、$1 \%$和$1 \%$将数据集划分为<strong>训练集</strong>、<strong>开发集</strong>以及<strong>测试集</strong>.<br><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558615230647.png" alt="Alt text"></li><li>测试集的作用是帮助系统开发完毕之后用于评估系统的性能表现的，方针就是：<strong>令你的测试集足够大，以便能够以高置信度评估系统整体性能</strong>。<br><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558615737594.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558615746966.png" alt="Alt text"></li></ol></blockquote><h2 id="7-什么时候该改变开发集-测试集以及指标"><a href="#7-什么时候该改变开发集-测试集以及指标" class="headerlink" title="7. 什么时候该改变开发集/测试集以及指标"></a>7. 什么时候该改变开发集/测试集以及指标</h2><blockquote><p>项目在进行过程中如果发现目标的位置定错了，这个情况下就需要移动你的目标了。</p></blockquote><p>还是以猫咪分类作为例子，在该项目中的目标是在很多照片中找到猫的照片然后发送给那些爱猫人士，这里使用的指标是分类误差。所以算法<strong>A</strong>和算法<strong>B</strong>的表现如下：<br><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558616499769.png" alt="Alt text"><br>似乎算法<strong>A</strong>做的更好，但是如果观察一下算法<strong>A</strong>发现它把很多色情图片误分类成了猫，因此如何部署算法<strong>A</strong>，用户将得到更多的猫的图片，因为它的误差只有$3 \%$，但是它同时会给用户推送色情图片，这是不能容忍的。相比之下算法<strong>B</strong>就好的多。</p><p>这种情况下<strong>开发集</strong>和<strong>单实数指标</strong>都倾向于算法<strong>A</strong>，因为<strong>A</strong>的误差较低，这是团队自己定下的指标评估出来的。但是实际的是用户更倾向于算法<strong>B</strong>。在这种情况下，当你的评估指标无法正确衡量模型算法之间的优劣的时候，就需要改变评估指标了或者要改变<strong>开发集</strong>或<strong>测试集</strong>了。</p><p>在这里你使用的分类误差指标可以写成：</p><script type="math/tex; mode=display">Error = \frac{1}{m_{dev}} \sum_{i = 1}^{m_{dev}} \mathbf I[y_{pred}^{(i)}  \neq y^{(i)}]</script><p>以上评估指标的问题在于它对于色情图片和非色情图片一视同仁。其中一个修改评估指标的方法是，在上面的式子中添加权重项：</p><script type="math/tex; mode=display">Error = \frac{1}{\sum_{i} \omega^{(i)}} \sum_{i = 1}^{m_{dev}} \omega^{(i)}·\mathbf I[y_{pred}^{(i)}  \neq y^{(i)}]</script><script type="math/tex; mode=display">\omega^{(i)} = \begin{cases}1, &\text{if $x^{(i)}$ is non-porn} \\10, &\text{if $x^{(i)}$ is porn}\end{cases}</script><p>这样你赋予了色情图片更大的权重，让算法在误将色情图片分类成猫的时候误差项快速变大。前面的系数更改是为了归一化，以便使得误差依旧在$[0,1]$之间。至于如何加权在此处不是重点。</p><p>实际上要使用这种加权，需要你自己过一遍<strong>开发集</strong>和<strong>测试集</strong>，以便自己讲色情图片标记出来，这样才能使用这个加权函数。因此一旦你定义的评估指标无法对多个模型进行正确的排名，那么就需要花时间定义一个新的评估指标了。<br><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558618736507.png" alt="Alt text"></p><p><strong>Summary：(正交化的两步)</strong></p><blockquote><ol><li>定义好的评估指标；</li><li>努力去命中定义的目标。<br><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558618993086.png" alt="Alt text"></li><li>如果你在指标上表现很好，在当前的<strong>开发集</strong>和<strong>测试集</strong>中表现很好，但是在实际的应用程序中，你真正关注的地方表现却不好的时候，那么就需要立即<strong>修改指标</strong>或者你的<strong>开发集</strong>以及<strong>测试集</strong>了。<br><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558619230287.png" alt="Alt text"></li></ol></blockquote><h2 id="8-为什么是人的表现"><a href="#8-为什么是人的表现" class="headerlink" title="8. 为什么是人的表现"></a>8. 为什么是人的表现</h2><blockquote><p>事实证明，当你试图让机器人做人类能够做的事情的时候，比较人类和机器的各自表现，可以有助于精心设计机器学习系统的工作流程，让工作流程效率更高。</p></blockquote><p>下图的内容如下：<br>$x$轴是你在一个机器学习项目中所花费的时间，一开始项目的表现开始往人类水平努力的时候，进展是很快的。但是过一段时间，当这个算法的表现比人类的更好时，那么进展和精确度的提升就会变得缓慢了，也即在超越人类水平之后，它的表现可以变得更好，只是性能增速、准确率上升的速度就会变得越来越平缓，我们都希望能够达到<strong>理论最佳性能水平(theoretical optimum level of performance)</strong>。随着时间的推移，当你继续训练算法的时候，可能模型越来越大，数据越来越多，但是性能无法超过某个理论上限，这就是所谓的<strong>贝叶斯最优误差(the Bayes optimal error / Bayesian)</strong>。<br><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558620703946.png" alt="Alt text"><br>所以<strong>贝叶斯最优误差一般被认为是理论上可以达到的最优误差</strong> ，也就是说没有任何办法设计出一个从$x$到$y$的函数，让它能够超过一定的准确率。</p><p>例如，对于语音识别来说，如果$x$是音频片段，有些音频就是这么嘈杂，基本上不可能知道说的是什么，所以完美的准确率可能不是$100 \%$，或者对于图像识别来说，也行有些图片非常模糊，不管是人类还是机器，就是无法判断图像中到底有没有猫，所以完美的准确率可能不是$100 \%$。<strong>贝叶斯误差代表的就是从</strong>$x$<strong>到</strong>$y$<strong>映射的理论最优函数永远不会被超越</strong>。</p><p>这里有两个可能的原因能够解释算法超过人类表现之后为何进展缓慢下来：</p><blockquote><ol><li>人类水平在很多任务中离<strong>贝叶斯最优误差</strong>已经不远了，例如在图像识别中人类能够比较轻易的分别图片中是否有猫，或者在语音识别中人类能够分辨音频的内容。因此当你的算法超越人类以后，也许没有太多的空间继续改善了；</li><li>有些工具能够在你的算法的表现比人类水平差的时候帮助你的算法提高性能，但是一旦超越人类的表现的时候，这些工具就没那么好用了，比方说：<blockquote><p>2.1 对于人类相当擅长的任务，比如看图识物，听写音频以及阅读语言，只要你的算法比人类差，你就可以通过：</p><ul><li><strong>Get labeled data from human(让人帮你标记数据).</strong></li><li><strong>Gain insight from manual error analysis: Why did a person get this right?(人工误差分析).</strong></li><li><strong>Better analysis of bias/variance(更好的分析偏差和方差).</strong></li></ul></blockquote></li></ol><p>而当你的算法性能超越人类的表现的时候，这三种策略就很难利用了。以上的策略也是体现了和人类表现进行比较的好处，尤其是在人类做的很好的任务上。<br><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558622015530.png" alt="Alt text"></p></blockquote><h2 id="9-可避免偏差"><a href="#9-可避免偏差" class="headerlink" title="9. 可避免偏差"></a>9. 可避免偏差</h2><blockquote><p>通常我们希望自己的学习算法能够在训练集上变现良好，但是实际的有时候你并不想做的太好，你的知道人类水平的表现怎么样，可以准确告诉你算法在训练集上的表现到底应该有多好或者有多不好。</p></blockquote><p>还是以猫分类器作为例子，假设人类的表现近乎完美，错误率在$1 \%$左右，而你的算法在<strong>训练集</strong>上的错误率为$8 \%$，在<strong>开发集</strong>上的误差为$10 \%$，那么你应该是想在<strong>训练集</strong>上有更好的结果。所以实际上你的算法在<strong>训练集</strong>上的表现和人类水平的表现有很大差距的话，说明你的算法对训练集的拟合并不好，所以从减少<strong>偏差</strong>和<strong>方差</strong>的工具这个角度看，在这种情况下我会把重点放在减少偏差上，你需要做的比如说：训练更大的神经网络，或者跑久一点梯度下降；</p><p>但是在不同的应用项目中，人类水平的误差不同，假设在另一个项目上，人类水平误差实际是$7.5 \%$，也许你的数据集的图像非常模糊，即使人类也无法分辨图像中是否有猫，而<strong>训练集</strong>和<strong>开发集</strong>的错误率还是和上面一样，这个情况下，你的系统在<strong>训练集</strong>上的表现也好可以，它只比人类稍微差一点点，此时需要做的就是减少算法的<strong>方差</strong>了，比如试试<strong>正则化</strong>或者收集更多的训练数据。</p><p>在这里我们就是使用人类水平误差估计或者代替<strong>贝叶斯最优误差</strong>，因为在计算机视觉这种人类很擅长的领域中，人类水平误差与<strong>贝叶斯误差</strong>接近，仅仅比其高一点。</p><p>这里把<strong>贝叶斯误差</strong>与<strong>训练集误差</strong>之间的差距称之为<strong>可避免误差(the avoidable bias)</strong>。而想要达到甚至超过<strong>贝叶斯误差</strong>除非过拟合。而<strong>训练集误差</strong>和<strong>开发集误差</strong>则是方差。因此需要衡量方差和<strong>可避免误差</strong>之间的大小以决定需要缩短哪一个误差的潜力更大。<br><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558625177980.png" alt="Alt text"></p><h2 id="10-理解人的表现"><a href="#10-理解人的表现" class="headerlink" title="10. 理解人的表现"></a>10. 理解人的表现</h2><p>对于下图，我们可以得到<strong>贝叶斯误差</strong>的估计的下限应该是小于等于$0.5 \%$<br><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558625553443.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558625832727.png" alt="Alt text"><br>以前的时候我们测量的时候<strong>训练误差</strong>和$0 \%$，现在换成了一个更加符合实际，更加微妙的——<strong>人类水平近似估计的贝叶斯误差</strong>.</p><h2 id="11-超过人的表现"><a href="#11-超过人的表现" class="headerlink" title="11. 超过人的表现"></a>11. 超过人的表现</h2><p><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558626293768.png" alt="Alt text"><br>上图的左边的例子还可以比较轻松的判断<strong>可避免偏差是多少</strong>? 而右边的例子的<strong>可避免偏差</strong>就不好判断了。例子中的<strong>训练误差</strong>实际的值是否意味着你的算法可能已经过拟合了$0.2 \%$或者说<strong>贝叶斯误差</strong>，其实比$0.5 \%$小呢？这个你是真的不知道的，但是右边的例子可以看出你是没有更多的信息来判断优化你的算法的时候应该更多的减少偏差还是方差，此时靠人的直觉去判断你的算法应该优化的方向是很难的，此时优化就没有了明确的选项和前进的方向了。</p><p>下图中的这些个例子是一些现今机器学习的表现远超单个人类表现的例子：<br><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558626761514.png" alt="Alt text"><br>而这几个例子都是从结构化的数据中学习得到的，它们并不是自然感知类型的问题(计算机视觉，自然语言处理等)，人类在这种问题中的表现会更好。</p><h2 id="12-改善模型表现"><a href="#12-改善模型表现" class="headerlink" title="12. 改善模型表现"></a>12. 改善模型表现</h2><p><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558627150253.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/05/24/machine-learning-stategy/1558627365213.png" alt="Alt text"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习策略 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 优化策略 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>剑指Offer部分题解</title>
      <link href="/2019/05/23/Sword-to-Offer/"/>
      <url>/2019/05/23/Sword-to-Offer/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>剑指Offer部分题目解析.</strong><br><a id="more"></a></p></blockquote><h2 id="1-二维数组中的查找"><a href="#1-二维数组中的查找" class="headerlink" title="1. 二维数组中的查找"></a>1. 二维数组中的查找</h2><blockquote><p><strong>题目：</strong>在一个二维数组中（每个一维数组的长度相同），每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。<br><strong>解题思路：</strong>首先题目中的二维数组在行和列上都是递增有序的，所以先想到使用的是类似二分查找的方式，所以会存在两个指针<strong>row</strong>和<strong>col</strong>，当两个指针所指的元素<strong>array[row][col] == target</strong>的时候，则<strong>return True</strong>，就下来就要考虑这个条件在大于和小于时候的判断了，这个题精巧的一点就是不是从矩阵[0][0]出发，而是从右上角出发，也就是<strong>array[0][len(array[0])-1]</strong>，这样的话，如果上述条件为小于的时候，则表明所在行的列可以不用往前了，因为往前会更小，而由于数组在列上递增，所以，需要行加一；如果条件为大于，则相应的判断，只是不是行加一，而是列加一，整体代码如下：<br><strong>代码：</strong></p><pre><code># -*- coding:utf-8 -*-class Solution:    # array 二维列表    def Find(self, target, array):        # write code here        if not array:            return None        rows,cols = len(array),len(array[0])        row,col = 0, cols-1        while True:            if row &lt; rows and col &gt;= 0 :                if array[row][col] == target:                    return True                elif array[row][col] &lt; target:                    row += 1                else:                    col -= 1            else:                return False</code></pre><h2 id="2-替换空格"><a href="#2-替换空格" class="headerlink" title="2. 替换空格"></a>2. 替换空格</h2><p><strong>题目：</strong>请实现一个函数，将一个字符串中的每个空格替换成“%20”。例如，当字符串为We Are Happy.则经过替换之后的字符串为We%20Are%20Happy。<br><strong>解题思路：</strong>这个题目有两种方式，第一种就是设置一个空串temp，然后遍历字符串S，当遍历到S中某个元素为空格的时候就让temp加上‘%20’，否则，其他元素的话，temp就一个一个依次加上就好，最后返回temp。另一种方式就是直接先使用spilt函数将字符串S以空格进行划分，然后返回字符串列表，再使用join函数以‘%20’作为字符链接列表序列中的元素，最后生成一个新的字符串，代码如下:<br><strong>代码1：</strong></p><pre><code># -*- coding:utf-8 -*-class Solution:    # s 源字符串    def replaceSpace(self, s):        temp = &#39;&#39;        for i in s:            if i == &#39; &#39;:                temp += &#39;%20&#39;            else:                temp += i        return temp</code></pre><p><strong>代码2：</strong></p><pre><code># -*- coding:utf-8 -*-class Solution:    # s 源字符串    def replaceSpace(self, s):        # write code here        return &#39;%20&#39;.join(s.split(&#39; &#39;))</code></pre></blockquote><h2 id="3-从尾到头打印链表"><a href="#3-从尾到头打印链表" class="headerlink" title="3. 从尾到头打印链表"></a>3. 从尾到头打印链表</h2><blockquote><p><strong>题目：</strong>输入一个链表，按链表值从尾到头的顺序返回一个ArrayList。<br><strong>解题思路：</strong>首先题目要求返回的是一个列表，所以本题需要使用列表，其次，如果用一个列表依次存放链表的元素的话，返回的则是一个从头到尾的链表，但是存放的时候又不能从列表的尾部往前存放，因为这是一个单链表，所以还需要一个外部的借助，就是再用一个列表，让两个列表模拟栈，一个依次存放元素到链表尾部，然后因为栈的先进后出的特点，因此依次弹出第一个栈的所有元素到另一个列表，这样就可以通过两个列表模拟栈的方式返回从尾到头的列表，代码如下：<br><strong>代码：</strong><br>```</p><h1 id="coding-utf-8"><a href="#coding-utf-8" class="headerlink" title="-- coding:utf-8 --"></a>-<em>- coding:utf-8 -</em>-</h1><h1 id="class-ListNode"><a href="#class-ListNode" class="headerlink" title="class ListNode:"></a>class ListNode:</h1><h1 id="def-init-self-x"><a href="#def-init-self-x" class="headerlink" title="def init(self, x):"></a>def <strong>init</strong>(self, x):</h1><h1 id="self-val-x"><a href="#self-val-x" class="headerlink" title="self.val = x"></a>self.val = x</h1><h1 id="self-next-None"><a href="#self-next-None" class="headerlink" title="self.next = None"></a>self.next = None</h1></blockquote><p>class Solution:</p><pre><code># 返回从尾部到头部的列表值序列，例如[1,2,3]def printListFromTailToHead(self, listNode):    # write code here    if not listNode:        return []    stack1 = []    stack2 = []    while listNode:        stack1.append(listNode.val)        listNode = listNode.next    while stack1:        stack2.append(stack1.pop())    return stack2     </code></pre><pre><code>## 4. 重建二叉树&gt;**题目：**输入某二叉树的前序遍历和中序遍历的结果，请重建出该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。例如输入前序遍历序列{1,2,4,7,3,5,6,8}和中序遍历序列{4,7,2,1,5,3,8,6}，则重建二叉树并返回。&gt;**解题思路：**首先，前序遍历为根左右，而中序遍历为左根右，因此如果使用递归的方式去解决的话，利用根元素，将中序划分为左子树和右子树，然后再去左子树和右子树以相同的方式递归整个序列就可以建立整个序列即可；而如果不使用递归的方式的话，可以使用栈的方式去替代递归，需要注意一点的时候，在中序中最先出现的第一个元素是整棵树最左边的节点，而在前序遍历中第二个元素虽未左子树，但却根据前序根左右的特点，为左子树的根节点，所以先用栈将左边的节点依次放入，知道栈当前最后一个节点和中序第一个节点相同的时候，则可以弹出了，然后再放入当前节点的右子树。&gt;**代码1：(递归的方式)**</code></pre><h1 id="Definition-for-a-binary-tree-node"><a href="#Definition-for-a-binary-tree-node" class="headerlink" title="Definition for a binary tree node."></a>Definition for a binary tree node.</h1><h1 id="class-TreeNode-object"><a href="#class-TreeNode-object" class="headerlink" title="class TreeNode(object):"></a>class TreeNode(object):</h1><h1 id="def-init-self-x-1"><a href="#def-init-self-x-1" class="headerlink" title="def init(self, x):"></a>def <strong>init</strong>(self, x):</h1><h1 id="self-val-x-1"><a href="#self-val-x-1" class="headerlink" title="self.val = x"></a>self.val = x</h1><h1 id="self-left-None"><a href="#self-left-None" class="headerlink" title="self.left = None"></a>self.left = None</h1><h1 id="self-right-None"><a href="#self-right-None" class="headerlink" title="self.right = None"></a>self.right = None</h1><p>class Solution(object):<br>    def buildTree(self, preorder, inorder):<br>        “””<br>        :type preorder: List[int]<br>        :type inorder: List[int]<br>        :rtype: TreeNode<br>        “””<br>        if inorder:<br>            index = inorder.index(preorder[0])<br>            root = TreeNode(preorder[0])<br>            root.left = self.buildTree(preorder[1:index+1],inorder[:index])<br>            root.right = self.buildTree(preorder[index+1:],inorder[index+1:])<br>            return root</p><pre><code>&gt;**代码2：(非递归方式)**</code></pre><h1 id="Definition-for-a-binary-tree-node-1"><a href="#Definition-for-a-binary-tree-node-1" class="headerlink" title="Definition for a binary tree node."></a>Definition for a binary tree node.</h1><h1 id="class-TreeNode"><a href="#class-TreeNode" class="headerlink" title="class TreeNode:"></a>class TreeNode:</h1><h1 id="def-init-self-x-2"><a href="#def-init-self-x-2" class="headerlink" title="def init(self, x):"></a>def <strong>init</strong>(self, x):</h1><h1 id="self-val-x-2"><a href="#self-val-x-2" class="headerlink" title="self.val = x"></a>self.val = x</h1><h1 id="self-left-None-1"><a href="#self-left-None-1" class="headerlink" title="self.left = None"></a>self.left = None</h1><h1 id="self-right-None-1"><a href="#self-right-None-1" class="headerlink" title="self.right = None"></a>self.right = None</h1><p>class Solution(object):<br>    def buildTree(self, preorder, inorder):<br>        “””<br>        :type preorder: List[int]<br>        :type inorder: List[int]<br>        :rtype: TreeNode<br>        “””<br>        if not preorder:<br>            return None<br>        stack=[]#利用栈后进先出的原理<br>        root=TreeNode(preorder[0])<br>        stack.append(root)<br>        index=0<br>        for i in range(1,len(preorder)):<br>            cur=stack[-1]<br>            if(stack[-1].val!=inorder[index]): #表明该中序索引在左子树<br>                cur.left=TreeNode(preorder[i])<br>                stack.append(cur.left)<br>            else:<br>                while(len(stack)!=0 and stack[-1].val==inorder[index]):<br>                    cur=stack.pop() #表明该子树一表达完毕<br>                    index+=1<br>                if(index&lt;len(inorder)):<br>                    cur.right=TreeNode(preorder[i])<br>                    stack.append(cur.right)<br>        return root</p><pre><code>&gt;需要注意的是此题和LeetCode第105题一样，是前序和中序，而LeetCode第106题则是中序和后序，那一道题同样可以使用递归的方式去做，不过中序和后序的非递归版本和前序和中序的很类似，只不过将后序逆序了一下，这样根就变成了第一个元素，再将代码中左子树和右子树的建立过程反一下就好了，LeetCode第106题的代码如下:&gt;**代码1：(递归的方式)**</code></pre><h1 id="Definition-for-a-binary-tree-node-2"><a href="#Definition-for-a-binary-tree-node-2" class="headerlink" title="Definition for a binary tree node."></a>Definition for a binary tree node.</h1><h1 id="class-TreeNode-1"><a href="#class-TreeNode-1" class="headerlink" title="class TreeNode:"></a>class TreeNode:</h1><h1 id="def-init-self-x-3"><a href="#def-init-self-x-3" class="headerlink" title="def init(self, x):"></a>def <strong>init</strong>(self, x):</h1><h1 id="self-val-x-3"><a href="#self-val-x-3" class="headerlink" title="self.val = x"></a>self.val = x</h1><h1 id="self-left-None-2"><a href="#self-left-None-2" class="headerlink" title="self.left = None"></a>self.left = None</h1><h1 id="self-right-None-2"><a href="#self-right-None-2" class="headerlink" title="self.right = None"></a>self.right = None</h1><p>class Solution:<br>    def buildTree(self, inorder, postorder):<br>        if postorder:<br>            ind = inorder.index(postorder[-1])<br>            root = TreeNode(inorder[ind])<br>            root.left = self.buildTree(inorder[0:ind],postorder[:ind])<br>            root.right = self.buildTree(inorder[ind+1:],postorder[ind:-1])<br>            return root</p><pre><code>&gt;**代码2：**</code></pre><h1 id="Definition-for-a-binary-tree-node-3"><a href="#Definition-for-a-binary-tree-node-3" class="headerlink" title="Definition for a binary tree node."></a>Definition for a binary tree node.</h1><h1 id="class-TreeNode-object-1"><a href="#class-TreeNode-object-1" class="headerlink" title="class TreeNode(object):"></a>class TreeNode(object):</h1><h1 id="def-init-self-x-4"><a href="#def-init-self-x-4" class="headerlink" title="def init(self, x):"></a>def <strong>init</strong>(self, x):</h1><h1 id="self-val-x-4"><a href="#self-val-x-4" class="headerlink" title="self.val = x"></a>self.val = x</h1><h1 id="self-left-None-3"><a href="#self-left-None-3" class="headerlink" title="self.left = None"></a>self.left = None</h1><h1 id="self-right-None-3"><a href="#self-right-None-3" class="headerlink" title="self.right = None"></a>self.right = None</h1><p>class Solution(object):<br>    def buildTree(self, inorder, postorder):<br>        “””<br>        :type inorder: List[int]<br>        :type postorder: List[int]<br>        :rtype: TreeNode<br>        “””<br>        if not postorder:<br>            return None<br>        postorder = postorder[::-1]<br>        inorder = inorder[::-1]<br>        stack=[]#利用栈后进先出的原理<br>        root=TreeNode(postorder[0])<br>        stack.append(root)<br>        index=0<br>        for i in range(1,len(postorder)):<br>            cur=stack[-1]<br>            if(stack[-1].val!=inorder[index]): #表明该中序索引在右子树<br>                cur.right=TreeNode(postorder[i])<br>                stack.append(cur.right)<br>            else:<br>                while(len(stack)!=0 and stack[-1].val==inorder[index]):<br>                    cur=stack.pop() #表明该子树一表达完毕<br>                    index+=1<br>                if(index&lt;len(inorder)):<br>                    cur.left=TreeNode(postorder[i])<br>                    stack.append(cur.left)<br>        return root</p><pre><code>## 5. 用两个栈实现一个队列&gt;**题目：**用两个栈来实现一个队列，完成队列的Push和Pop操作。 队列中的元素为int类型。&gt;**解题思路：**首先需要明确的一点是栈的特点是**FILO(先进后出)**，而队列的特点是**FIFO(先进先出)**，那么如果先用栈存放数据了之后，如果直接用那个栈弹出数据的话，由于栈只能从一段弹出，那么弹出来的顺序是反序的，这时候应该再有一个栈，把第一个栈依次弹出的元素存放在第二个栈中，这样就可以模拟队列的数据进出方式了。&gt;**代码：**</code></pre><h1 id="coding-utf-8-1"><a href="#coding-utf-8-1" class="headerlink" title="-- coding:utf-8 --"></a>-<em>- coding:utf-8 -</em>-</h1><p>class Solution:<br>    def <strong>init</strong>(self):</p><pre><code>    # 先初始化两个列表用于模拟两个栈    self.stack1 = []    self.stack2 = []def push(self, node):    # push操作的时候第一个栈就按照栈的方式存放就好，和第二个栈暂时没啥关系    self.stack1.append(node)def pop(self):    # return xx    if not self.stack2:        while self.stack1:            self.stack2.append(self.stack1.pop())    return self.stack2.pop()</code></pre><p>```</p>]]></content>
      
      
      <categories>
          
          <category> python数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
            <tag> 剑指Offer </tag>
            
            <tag> 题解 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tensorflow-GPU with Win10 Installing</title>
      <link href="/2019/05/22/tensorflow-gpu-win10-installing/"/>
      <url>/2019/05/22/tensorflow-gpu-win10-installing/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>记录在win10上TensorFlow-GPU版本的安装过程</strong><br><a id="more"></a></p></blockquote><h2 id="1-系统配置"><a href="#1-系统配置" class="headerlink" title="1. 系统配置"></a>1. 系统配置</h2><div class="table-container"><table><thead><tr><th style="text-align:left">配置</th><th style="text-align:right">对应版本</th></tr></thead><tbody><tr><td style="text-align:left">系统</td><td style="text-align:right">win10</td></tr><tr><td style="text-align:left">内存</td><td style="text-align:right">8.0G</td></tr><tr><td style="text-align:left">显卡</td><td style="text-align:right">NVIDIA GeForce GTX 1050</td></tr><tr><td style="text-align:left">python版本</td><td style="text-align:right">python 3.7.0 + python 3.6.2(Anaconda新建的一个环境)</td></tr><tr><td style="text-align:left">Anaconda版本</td><td style="text-align:right">Anaconda3-5.3.0-Windows-x86_64.exe(对应python3.7.0环境)</td></tr></tbody></table></div><h2 id="2-TensorFlow-CPU安装"><a href="#2-TensorFlow-CPU安装" class="headerlink" title="2. TensorFlow-CPU安装"></a>2. TensorFlow-CPU安装</h2><h3 id="2-1-安装过程"><a href="#2-1-安装过程" class="headerlink" title="2.1 安装过程"></a>2.1 安装过程</h3><blockquote><p>网上关于TensorFlow的安装的文章到处都是，有些讲的乱七八糟的，由于每个人的需求以及环境不尽相同，因此整个安装过程耗费了好几个晚上的时间，Anaconda库来来回回安装和卸载了好多次，在此将整个安装过程记录下来，以备自己以后安装的时候有个参考.<br>CPU版本的TensorFlow安装很方便，一般不会出现什么大的问题，步骤也很简单，主要如下：<br>2.1.1 首先需要安装python环境，这里直接使用集成了各个科学计算库的+python的Anaconda来安装python环境，<a href="https://www.anaconda.com/distribution/" target="_blank" rel="noopener">Anaconda连接在此：</a><br><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538368639.png" alt="Alt text"></p><p>2.1.2 需要注意的是，安装python的版本和Anaconda的版本是相互有对应的，这里给出这种图(<a href="https://blog.csdn.net/yuejisuo1948/article/details/81043823" target="_blank" rel="noopener">图片来源连接</a>)：<br><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538389057.png" alt="Alt text"></p><p>首先解释一下上表。 anaconda在每次发布新版本的时候都会给python3和python2都发布一个包，版本号是一样的。表格中，python版本号下方的离它最近的anaconda包就是包含它的版本。举个例子，假设你想安装python2.7.14，在表格中找到它，它下方的三个anaconda包（anaconda2-5.0.1、5.1.0、5.2.0）都包含python2.7.14；假设你想安装python3.6.5，在表格中找到它，它下方的anaconda3-5.2.0就是你需要下载的包；假设你想安装python3.7.0，在表格中找到它，它下方的anaconda3-5.3.0或5.3.1就是你需要下载的包；<br>2.1.3 安装Anaconda的过程就不在详述了，安装完成之后可以看到如下：<br><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538400662.png" alt="Alt text"></p><p>2.1.4 需要注意python的版本和TensorFlow的版本，很多时候安装失败是由于安装了最新版的python，而最新版的python对当时的TensorFlow支持度不够友好所致。<br><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538410126.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538419560.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538428675.png" alt="Alt text"></p><p>2.1.5 安装的时候可以直接在cmd下面运行：<code>pip install tensorflow</code>即可，这样安装的是cpu版本，且会安装当时最新的TensorFlow版本，但是由于上面所说的TensorFlow和python版本不匹配的问题，这样的方式安装可能会造成无法找到TensorFlow的报错问题，且由于这样的方式并未补充TensorFlow具体的版本号，所以可能造成找不到指定版本号TensorFlow的错误；还可以指定具体的TensorFlow版本号进行安装，这样可以避免大部分错误：<br><code>pip3 install --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.0-cp35-cp35m-win_amd64.whl</code><br>除了这个之外还可以在<strong>Anaconda Prompt</strong>中使用<strong>conda</strong>命令进行安装，在此不再赘述，请自行百度或者谷歌。</p></blockquote><h2 id="3-TensorFlow-GPU安装"><a href="#3-TensorFlow-GPU安装" class="headerlink" title="3. TensorFlow-GPU安装"></a>3. TensorFlow-GPU安装</h2><h3 id="3-1-搭建新的环境"><a href="#3-1-搭建新的环境" class="headerlink" title="3.1 搭建新的环境"></a>3.1 搭建新的环境</h3><blockquote><p>由于担心安装了python3.7.0版本的Anaconda之后会出现对当前版本的TensorFlow不兼容从而造成各种错误的情况，参考网上的方式在Anaconda下搭建了基于python3.6.2的环境方便搭建GPU版本，过程如下：</p><ol><li>右键管理员启动Anaconda Prompt；</li><li>创建python36的环境：<code>conda creat --name python36 python=3.6</code></li><li>进入(激活)python36环境：<code>conda activate python36</code></li><li>如果有需要回到python3.7：<code>conda deactivate</code></li><li>安装成功之后可以看到：<img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538444899.png" alt="Alt text"></li></ol></blockquote><h3 id="3-2-安装TensorFlow—GPU"><a href="#3-2-安装TensorFlow—GPU" class="headerlink" title="3.2 安装TensorFlow—GPU"></a>3.2 安装TensorFlow—GPU</h3><h4 id="3-2-1-软件需求："><a href="#3-2-1-软件需求：" class="headerlink" title="3.2.1 软件需求："></a>3.2.1 软件需求：</h4><div class="table-container"><table><thead><tr><th style="text-align:left">工具</th><th style="text-align:right">对应版本</th></tr></thead><tbody><tr><td style="text-align:left">NVIDIA® GPU drivers</td><td style="text-align:right">CUDA 9.0 requires 384.x or higher</td></tr><tr><td style="text-align:left">CUDA® Toolkit</td><td style="text-align:right">cuda_9.0.176_win10.exe</td></tr><tr><td style="text-align:left">cuDNN SDK</td><td style="text-align:right">cudnn-9.0-windows10-x64-v7.4.2.24.zip</td></tr><tr><td style="text-align:left">VC库</td><td style="text-align:right">Microsoft Visual C++ 2015 + Visual Studio 2017</td></tr></tbody></table></div><blockquote><ol><li>需要注意CUDA的版本和cuDNN的版本也是需要匹配的，否则没办法使用(版本对应见上面的图);</li><li>Visual studio 2015: 这个版本和CUDA8.0和CUDA9.0都兼容，VS2017和CUDA8.0不兼容，与CUDA9.0兼容.</li></ol></blockquote><h4 id="3-2-2-VC库安装："><a href="#3-2-2-VC库安装：" class="headerlink" title="3.2.2 VC库安装："></a>3.2.2 VC库安装：</h4><blockquote><ol><li><p>打开<a href="https://visualstudio.microsoft.com/zh-hans/vs/older-downloads/?rr=https://tensorflow.google.cn/install/source_windows" target="_blank" rel="noopener">微软网站</a>，下载并安装以下两个库：<br><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538461732.png" alt="Alt text"></p></li><li><p>再进入<a href="https://visualstudio.microsoft.com/zh-hans/downloads/" target="_blank" rel="noopener">VS网站</a>，下载并安装VS2017社区版；<br><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538469358.png" alt="Alt text"></p></li></ol></blockquote><h4 id="3-2-3-CUDA-cuDNN安装"><a href="#3-2-3-CUDA-cuDNN安装" class="headerlink" title="3.2.3 CUDA+cuDNN安装"></a>3.2.3 CUDA+cuDNN安装</h4><blockquote><p>需要注意的是CUDA和cuDNN也都是需要匹配相应版本的哈，所以请注意想要的版本，上面的图有对应的版本。</p><ol><li>登录<a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank" rel="noopener">CUDA官网</a>选择相应的版本下载。这里下载cuda_9.0.176_win10.exe，以及补丁patch2、3、4（patch1安装不上，可以不安装，<br><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538483321.png" alt="Alt text"></li></ol><p>1.1 文件解压，解压地方默认就好了：<br><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538491079.png" alt="Alt text"></p><p>1.2 系统兼容性，这个地方我的笔记本系统兼容性检测说无法识别硬件,是否要继续！”This graphics driver could not find compatible graphics hardware…“，这个地方可能是“因为笔记本厂商一般都给自己的机器采用的显卡添加了独特的硬件ID，导致CUDA没有包含这个ID，驱动认不出显卡”，但是也不用担心，可以继续往下安装：<br><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538502008.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538508346.png" alt="Alt text"></p><p>1.3 安装选择高级，勾选内容部分我是把所有已经安装的驱动的勾点掉了，只安装没有的驱动，安装路径默认了，在这个地方可以记录一下自己安装的文件路径：<br><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538518814.png" alt="Alt text"></p><p>1.4 更新CUDA、Driver（不更新的话有可能导致NVIDIA控制面板打不开）、physx：<br><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538526444.png" alt="Alt text"></p><p>1.5 安装位置不需要改变，后面过程直接下一步即可：<br><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538534652.png" alt="Alt text"></p><p>1.6 在安装的时候最好使用管理员权限进行安装，安装成功之后界面如下图：<br><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538542136.png" alt="Alt text"></p><p>检验CUDA是否安装成功：打开<code>CMD</code>，输入<code>nvcc -V</code><br><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538549478.png" alt="Alt text"></p><ol><li>登录<a href="https://developer.nvidia.com/rdp/cudnn-download" target="_blank" rel="noopener">cuDNN官方网站</a>下载对应版本的cuDNN，这里就是cudnn-9.0-windows10-x64-v7.4.2.24.zip：<br><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538592127.png" alt="Alt text"></li></ol><p>下载完毕解压会看到3个文件夹如下：<br><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538602305.png" alt="Alt text"></p><p>下载完成后解压缩。里面有bin、include、lib三个目录，将三个文件夹内容复制到安装CUDA的地方覆盖对应文件夹内容，CUDA默认文件夹在：C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0</p><ol><li>添加环境变量：检查一下环境变量 我的电脑—&gt; 属性—&gt; 高级系统设置—&gt; 环境变量—&gt;系统变量中加入CUDA 的bin所在目录环境，在用户环境变量中加入<strong>C:\ProgramData\NVIDIA GPU Computing Toolkit\v9.0\bin</strong>：<br><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538618494.png" alt="Alt text"></li></ol><p>如何cuDNN验证是否安装成功？cuDNN无法直接验证安装成功，在之后TensorFlow-GPU安装完毕后，import tensorflow as tf 若报错ImportError: Could not find ‘cudnn64_7.dll’.则证明安装失败。</p><ol><li>安装TensorFlow：<br>4.1 在windows程序中找到Anaconda Promt并打开，输入命令：<code>activate python36</code><br><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538647698.png" alt="Alt text"></li></ol><p>4.2 然后输入对应的命令：<br><code>pip install --ignore-installed --upgrade</code> <code>https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-1.12.0-cp35-cp35m-win_amd64.whl</code><br>或者直接下载：<code>pip3 install --upgrade tensorflow-gpu</code><br>经过长时间的安装等待之后如果导入TensorFlow成功则大功告成，如果想要在pycharm下使用到gpu版的TensorFlow，只需要在解释器那里选择python36环境下的python.exe就可以了：<br><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538659711.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538666047.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538673299.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538679441.png" alt="Alt text"></p></blockquote><h2 id="4-安装过程中遇到的一些问题"><a href="#4-安装过程中遇到的一些问题" class="headerlink" title="4. 安装过程中遇到的一些问题"></a>4. 安装过程中遇到的一些问题</h2><h3 id="4-1-Numpy版本不对"><a href="#4-1-Numpy版本不对" class="headerlink" title="4.1 Numpy版本不对"></a>4.1 Numpy版本不对</h3><blockquote><p>在<code>pip install tensorflow</code>之后出现如下问题：</p><blockquote><p><strong>twisted 18.7.0 requires PyHamcrest&gt;=1.9.0, which is not installed</strong>，且在系统提示install satisfied的情况下，python导入TensorFlow库报错：<img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538692903.png" alt="Alt text"></p></blockquote></blockquote><p>，查询之后升级numpy可以正常导入TensorFlow：<code>pip install -U numpy</code> ,numpy从1.15.1升级到1.16.3.</p><blockquote><p><a href="https://www.cnblogs.com/Terrypython/p/10467859.html" target="_blank" rel="noopener">https://www.cnblogs.com/Terrypython/p/10467859.html</a></p></blockquote><h3 id="4-2-CUDA9-0版本问题"><a href="#4-2-CUDA9-0版本问题" class="headerlink" title="4.2 CUDA9.0版本问题"></a>4.2 CUDA9.0版本问题</h3><blockquote><p>我在安装CUDA8.0的时候遇到了如下问题：The graphics driver could not find compatible graphics hardware。这个问题的主要原因是你本机的显卡驱动版本比CUDA8.0中自带的驱动版本高（实际上，不论CUDA装的哪个版本，只要本机驱动比CUDA自带驱动版本高，都可能出现这个问题）。<br>解决办法：<br>直接点击继续—&gt;同意并继续—&gt;自定义（高级）—&gt;只选择CUDA进行安装，最后安装成功。 在自定义界面可以看到CUDA自带驱动版本号以及目前本机驱动版本号，如果本机版本号高于CUDA自带版本号，就不要再勾选安装了。<br><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538702894.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538708280.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538713313.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538718818.png" alt="Alt text"></p><p>除此之外，如果安装CUDA9.0直接失败的话，请先将win10的更新打开并将win10更新到最新版本，然后再更新你的GPU的驱动，驱动请勿去驱动人生或者驱动之家下载，我在这两家下载之后造成GPU驱动无法安装等情况，请使用<strong>GeForce Experience</strong>进行驱动的更新下载。<br><img src= "/img/loading.gif" data-src="/2019/05/22/tensorflow-gpu-win10-installing/1558538731468.png" alt="Alt text"></p></blockquote><h3 id="4-3-其他问题："><a href="#4-3-其他问题：" class="headerlink" title="4.3 其他问题："></a>4.3 其他问题：</h3><blockquote><ol><li><a href="https://blog.csdn.net/Halsey_/article/details/88411095" target="_blank" rel="noopener">DLL load failed: 找不到指定的模块</a></li><li><a href="https://blog.csdn.net/sinat_27917465/article/details/83656494" target="_blank" rel="noopener">安装 Tensorflow-gpu 问题及解决</a></li></ol></blockquote>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> win10 </tag>
            
            <tag> tensorflow-gpu </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Weights of Predictions of Pigs</title>
      <link href="/2019/05/22/Weights-Pred-of-Pigs/"/>
      <url>/2019/05/22/Weights-Pred-of-Pigs/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>使用深度学习的方法对死猪体重进行预测.</strong><br><a id="more"></a></p></blockquote><h2 id="1-项目情况说明"><a href="#1-项目情况说明" class="headerlink" title="1. 项目情况说明"></a>1. 项目情况说明</h2><p>当前需求场景发生在一个特定的保险产品上：<strong>育肥猪保险</strong></p><blockquote><p>生猪养殖户会对育肥猪进行投保，如果发生理赔，保险公司会按照猪的体重进行赔付，所以保险公司需要对育肥猪的体重进行勘定。</p><p>如果猪可以上秤，那么保险公司就可以获得准确的体重。但在实务操作中，有很多无法上秤的场景，比如疫病猪需要快速无害化处理，没有办法等到保险公司来查勘定损，或者因为一些原因无法人为移动上秤，就只能对猪的体重进行估算。</p><p>这个时候，一些保险公司会通过查勘员估算、或无害化处理站工作人员估算等方式，也能得到粗略的结果。</p><p>猪重识别项目的价值在于：</p><ul><li>对大量的历史样本进行学习，获得猪体重的更优估计;</li><li>自动计算，减少估算过程中的人为因素;</li><li>节约查勘成本;</li><li>自动定损，更顺畅便捷的理赔过程;</li></ul></blockquote><hr><h2 id="2-项目分析"><a href="#2-项目分析" class="headerlink" title="2. 项目分析"></a>2. 项目分析</h2><h3 id="2-1-开发环境"><a href="#2-1-开发环境" class="headerlink" title="2.1 开发环境"></a>2.1 开发环境</h3><div class="table-container"><table><thead><tr><th style="text-align:left">环境</th><th style="text-align:right">对应版本</th></tr></thead><tbody><tr><td style="text-align:left">operating system</td><td style="text-align:right">win10</td></tr><tr><td style="text-align:left">GPU</td><td style="text-align:right">NVIDIA GeForce RTX 2080 Ti</td></tr><tr><td style="text-align:left">CPU</td><td style="text-align:right">Inter(R) i7-9700K</td></tr><tr><td style="text-align:left">Memory</td><td style="text-align:right">16G</td></tr><tr><td style="text-align:left">python</td><td style="text-align:right">3.6.8</td></tr><tr><td style="text-align:left">tensorflow-gpu</td><td style="text-align:right">1.12.0</td></tr><tr><td style="text-align:left">IDE</td><td style="text-align:right">pycharm-community-2019.1.1</td></tr><tr><td style="text-align:left">Anaconda</td><td style="text-align:right">Anaconda3-5.3.0-Windows-x86_64.exe</td></tr><tr><td style="text-align:left">CUDA® Toolkit</td><td style="text-align:right">cuda-9.0.176-win10.exe</td></tr><tr><td style="text-align:left">cuDNN SDK</td><td style="text-align:right">cudnn-9.0-windows10-x64-v7.4.2.24.zip</td></tr></tbody></table></div><h3 id="2-2-原始数据"><a href="#2-2-原始数据" class="headerlink" title="2.2 原始数据"></a>2.2 原始数据</h3><p>整个项目的图片总数为192张，刨除一些存在标签标准错误以及同一图片存在多头死猪的图片之后，整个数据集还剩189张图片。整个图片集中所有图片的分辨率分为两种:    $640 \times 480$ 以及 $640 \times 853$，除此之外，每一张图片都包含有图片提供方关于图片的相应信息描述的水印，而图片中的死猪身上都有一张<strong>A4</strong>大小的纸张，纸张包含该死猪的一些相应信息，具体图片样式如下：<br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/19.jpg" alt="Alt text"></p><h3 id="2-3-设计思路1"><a href="#2-3-设计思路1" class="headerlink" title="2.3 设计思路1"></a>2.3 设计思路1</h3><p>首先，原始数据除了这189张图片之外，就只有一个<strong>Excel</strong>文档，记录了相应照片的对应体重，再无其他特征，因此首先想到的就是利用卷积神经网络(<strong>Convolutional Neural Network</strong>)对于原始图片进行特征提取，利用卷积的架构让模型自动帮我们提取有用的特征；然后再在卷积后面接入全连接神经网络(<strong>Fully Connected Neural Network</strong>)，通过修改神经网络最后一层的神经元的个数来达到预测的效果。由于全连接神经网络多用于分类，而此项目的预测结果为连续值，实则为回归问题，因此第一个设计思路就是按照分类的方式，将整个体重区间进行离散化以符合分类的要求，整个体重所处范围在$[20,100)$以及$[100+, \inf]$之间，离散化了之后的区间间隔如下：<br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/分类标签分段统计.png" alt="Alt text"><br>最后，为了避免数据较少但区间划分过细造成分类类别较多以及区间划分过粗造成分类不精确的情况出现，在此选择了间隔为<strong>4</strong>的情况，并按照<strong>卷积 + 全连接</strong>的方式搭建了第一个模型。</p><h4 id="2-3-1-数据预处理"><a href="#2-3-1-数据预处理" class="headerlink" title="2.3.1 数据预处理"></a>2.3.1 数据预处理</h4><p>由于原始数据存在水印的情况，在模型1初始的版本中考虑到水印可能会影响到分类结果，因此在初始版本中采取的思路是对所有的图片进行水印去除的预处理过程，得到的图片大体如下图：<br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1.jpg" alt="Alt text"><br>可以看到图像中的水印已经去除，但是相应的，连同白色的<strong>A4</strong>纸以及背景有白色的部分都被去除了，在后续的版本中发现这样的方式是不对的，因为<strong>A4</strong>大小其实是相同的，但是猪的大小则是不同的，因此<strong>A4</strong>纸相当于是一个体型大小的参照物，是一个很好的特征，这在后面<strong>CNN可视化</strong>中会有提及，在此不再详述。</p><h4 id="2-3-2-数据增广"><a href="#2-3-2-数据增广" class="headerlink" title="2.3.2 数据增广"></a>2.3.2 数据增广</h4><blockquote><p><strong>神经网络的好坏取决于输入的数据，通过增强数据集，可以防止神经网络学习到不相关的模式，根本上提升整体性能。(<a href="https://www.leiphone.com/news/201805/avOH5g1ZX3lAbmjp.html" target="_blank" rel="noopener">数据增强：数据有限时如何使用深度学习？</a>)</strong></p></blockquote><p>当我们训练一个深度学习模型时，我们的实际工作就是调参，以便将特定的输入（一幅图像）映射到输出(标签)。我们优化的目标是使模型的损失最小化， 以正确的方式调节优化参数即可实现这一目标。成功的神经网络拥有数以百万计的参数！自然，如果有大量参数，就需要提供的深度学习模型同比例的实例，以获得优秀的性能。相应的，需要的参数数量与需要执行的任务复杂性也成比例。但是在没有大量数据的情况之下，如何获取更多的数据呢?    其实，你并不需要添加大量的图像到你的数据集，为什么？ 因为，神经网络从一开始就不是智能的，例如，缺乏训练的神经网络会认为下面这3个网球是不同的、独立的图像：<br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557743761956.png" alt="完全一样的网球，神经网络的解释却不相同"><br>所以，为了获得更多数据，我们仅需要对已有的数据集做微小的调整。比如翻转、平移或旋转。神经网络会认为这些数据是不同的：<br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557743843604.png" alt="Alt text"><br>卷积神经网络有一个称作不变性的性质，即使卷积神经网络被放在不同方向上，它也能进行对象分类。更具体的说，卷积神经网络对<strong>平移、视角、尺寸或照度（或以上组合）</strong>保持不变性。(<a href="https://zhuanlan.zhihu.com/p/27642620" target="_blank" rel="noopener">YJango的卷积神经网络——介绍</a>)<br>这就是数据增强的本质前提。在现实世界中，我们可能会有一组在有限的条件下拍摄的图像 。但是，我们的目标应用可能是在多变的环境中，例如，不同的方向、位置、比例、亮度等。我们通过使用经综合修改过的数据来训练神经网络，以应对这些情形。</p><p>那么在深度学习的什么位置进行数据增广呢？一般有两种选择：</p><blockquote><ol><li>是预先对图片进行所有必要的变换，从根本上增加数据集的规模。</li><li>另外一个是小批量执行变换，仅仅在输入机器学习模型之前。</li></ol></blockquote><p>第一项被称为离线增强。这个方法常被用于相对较小的数据集。因为你最终会通过一个与执行的转换数量相等的因子来增加数据集的大小（例如，通过翻转所有图像，数据集数量会增加2倍）。</p><p>第二个选项称为在线增强，或称为动态增强。主要应用于规模较大的数据集，因为你无法负担数据量爆炸性增长。反而，你可以通过对即将输入模型的小批量数据的执行相应的变化。很多机器学习架构已经支持在线增强，并可以利用GPU进行加速。</p><p>在本项目中使用到的数据增强技术包括如下：</p><blockquote><ol><li><strong>随机裁切：</strong><code>tf.random_crop(value, size, seed=None, name=None)参数：value：向裁剪输入张量。size：一维张量，大小等级为 value。seed：Python 整数。用于创建一个随机的种子。查看 tf.set_random_seed 的行为。name：此操作的名称（可选）</code><br><strong>在原有图像上随机的裁剪出一块，1.12版本可以使用tf.image.random_crop</strong><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557750675402.png" alt="Alt text"><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557750683978.png" alt="Alt text"></li><li><strong>随机左右翻转：</strong><code>tf.image.random_flip_left_right(image, seed=None)参数：image：形状为[height, width, channels]的三维张量。seed：一个Python整数，用于创建一个随机种子</code><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557750872286.png" alt="Alt text"><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557750884245.png" alt="Alt text"></li><li><strong>随机上下翻转：</strong><code>tf.image.random_flip_up_down(image, seed=None)参数：image：形状为[height, width, channels]的三维张量。seed：一个Python整数，用于创建一个随机种子。</code><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557750891215.png" alt="Alt text"><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557750894727.png" alt="Alt text"></li><li><strong>随机色调变换：(通过随机因子调整RGB图像的色调)</strong><code>tf.image.random_hue(image, max_delta, seed=None)参数：image：RGB图像，最后维度的大小必须为3。max_delta：浮点型，随机增量的最大值。seed：特定于操作的seed，它将与图层seed一起使用，以确定将在此操作中使用的实际seed</code><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557751001109.png" alt="Alt text"><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557751010250.png" alt="Alt text"></li><li><strong>随机对比度变换：(函数是给图像乘一个常量(区间在[lower,upper]))</strong><code>tf.image.random_contrast(image, lower, upper, seed=None)参数：image：具有3个或更多维度的图像张量。lower：浮点型，随机对比因子的下限。upper：浮点型，随机对比因子的上限。seed：一个Python整数，用于创建一个随机种子</code><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557751145195.png" alt="Alt text"><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557751152414.png" alt="Alt text"></li><li><strong>随机亮度变换：(随机亮度变换(从-0.5到+0.5[max_delta=0.5代表最大的变换范围]，亮度变换就是给图像加上一个数或者减去一个数))</strong><code>tf.image.random_brightness(image, max_delta, seed=None)参数：image： 一个图像。max_delta：float，必须是非负的。seed：一个Python整数。用于创建一个随机种子</code><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557751228048.png" alt="Alt text"><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557751235218.png" alt="Alt text"></li><li><strong>随机饱和度变换：(通过随机因子调整RGB图像的饱和度)</strong><code>tf.image.random_saturation(image, lower, upper, seed=None)参数：image：RGB图像，最后维度的大小必须为3。lower：浮点型，随机饱和因子的下界。upper：浮点型，随机饱和因子的上界。seed：特定于操作的seed，它将与图层seed一起使用，以确定将在此操作中使用的实际seed</code><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557751301716.png" alt="Alt text"><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557751310134.png" alt="Alt text"><br>对于每一个文件夹，都扩充为20张图片，最后扩充完成后图片总数为<strong>2349</strong>张图片。</li></ol><hr><p>在数据扩充的过程当中对于数据的读取使用的是<strong>tensorflow</strong>内置的一些函数，在此相关特点记录如下：</p><ol><li><code>tf.gfile.FastGFile(path,decodestyle)函数功能：实现对图片的读取，类似于python提供的文本操作open()函数，path是要打开的文件名，decodestyle是以何种方式去读写函数参数：(1)path：图片所在路径 (2)decodestyle:图片的解码方式。(&#39;r&#39;:UTF-8编码; &#39;rb&#39;:非UTF-8编码)</code></li><li><code>tf.image.decode_jpeg &amp; tf.image.encode_jpegtensorflow里面给出了一个函数用来读取图像，不过得到的结果是最原始的图像，是没有有经过解码的图像，这个函数为tf.gfile.FastGFile（&#39;path&#39;， &#39;r&#39;）.read()。如果要显示读入的图像，那就需要经过解码过程， tensorflow里面提供解码的函数有两个, tf.image.decode_jepg和tf.image.decode_png分别用于解码jpg格式和png格式的图像进行解码，得到图像的像素值，这个像素值可以用于显示图像。如果没有有解码，读取的图像是一个字符串，没法显示。 一张RGB图像可以看成一个三维的矩阵，矩阵中的每一个数表示了图像上不同位置，不同颜色的亮度。然而图像在存储时并不是直接记录这些矩阵中的数字，而是记录经过压缩编码之后的结果。所以要将一张压缩编码了的图象还原成一个三维矩阵。需要解码的过程。下面的代码示范了如何tensorflow对 JPEG 格式图片的编码/解码函数：解码：  将图像使用JPEG的格式解码从而得到图像对应的三维矩阵。Tensorflow还提供了tf.image.decode_png函数对png格式的图像进行编码。解码之后的结果(image_data)为一个张量， 在使用他的取值之前需要明确调用运行的过程。 Decode a JPEG-encoded image to a uint8 tensor 所以这里的 image_data 已经是一个tensor。image_data = tf.image.decode_jpeg(image_raw_data)编码：  将表示一张图像的三维矩阵重新按照jpeg格式编码并存入文件中。打开这张图像就可以得到和原始图像一样的图像， encoded_image = tf.image.encode_jpeg(image_data)</code><br><a href="https://blog.csdn.net/qq_43225437/article/details/88018408" target="_blank" rel="noopener">图像处理：编码解码处理(tf.image.decode_jpeg)</a></li></ol><hr><p><strong>最后补充一些数据增广的博文以作参考：</strong></p><ol><li><a href="https://www.leiphone.com/news/201805/avOH5g1ZX3lAbmjp.html" target="_blank" rel="noopener">数据增强：数据有限时如何使用深度学习 ？</a></li><li><a href="https://blog.csdn.net/m0_38100350/article/details/84559361" target="_blank" rel="noopener">使用tensorflow实现数据增强</a></li><li><a href="https://blog.csdn.net/sinat_29957455/article/details/83279741" target="_blank" rel="noopener">tensorflow实现inception Net数据增强</a></li><li><a href="https://blog.csdn.net/sinat_29957455/article/details/80629098" target="_blank" rel="noopener">tensorflow实现数据增强(随机裁剪、翻转、对比度设置、亮度设置)</a></li><li><a href="https://blog.csdn.net/jeffery0207/article/details/79897333" target="_blank" rel="noopener">tensorflow数据增强</a></li><li><a href="https://blog.csdn.net/wc781708249/article/details/80060345" target="_blank" rel="noopener">Tensorflow数据增强</a></li><li><a href="http://www.cnblogs.com/bonelee/p/9017114.html" target="_blank" rel="noopener">迁移学习——使用Tensorflow和VGG16预训模型进行预测</a></li><li><a href="https://www.jianshu.com/p/c3a9573ecb0d" target="_blank" rel="noopener">TensorFlow 可用的数据增强</a></li></ol></blockquote><h4 id="2-3-3-创建自己的训练数据集"><a href="#2-3-3-创建自己的训练数据集" class="headerlink" title="2.3.3 创建自己的训练数据集"></a>2.3.3 创建自己的训练数据集</h4><p>刚开始学习<strong>TensorFlow</strong>的时候都是跑官方的例子：比如我们熟知的：<strong>MNIST</strong>手写体数据集或者<strong>cifar-10/100</strong>数据集，这些数据集都是官方以及整理好了的，直接使用就好。但是后面实际上不可能总是官方的数据集跑一跑就能学好<strong>TensorFlow</strong>的，所以一些项目需要处理自己的数据，整理自己的数据集。做过<strong>Kaggle</strong>竞赛的应该很熟悉<strong>.csv</strong>文件了，<strong>.csv</strong>文件非常方便,但是通常读取的时候,是一次性读取到内存里面的.要是内存小的话,就要想其他的办法了,那就变得很麻烦了.</p><p>或者有时候,从硬盘上面直接读取图片啊什么的,因为图片的文件格式,存放位置各种各样等等一些因素,要是想在训练阶段直接这么使用的话,就更加麻烦了.所以,对于数据进行统一的管理是很有必要的<strong>.TFRecord</strong>就是对于输入数据做统一管理的格式.加上一些多线程的处理方式,使得在训练期间对于数据管理把控的效率和舒适度都好于暴力的方法. 小的任务什么方法差别不大,但是对于大的任务,使用统一格式管理的好处就非常显著了.因此, 有必要熟悉<strong>.TFRecord</strong>的使用方法.</p><p>在本项目中主要用于将自己的数据做成<strong>Tfrecords</strong>，以便<strong>tensorflow</strong>能够很好的进行划分<strong>batch</strong>和<strong>Tensor</strong>读取，对于数据量较小而言，可能一般选择直接将数据加载进内存，然后再分<strong>batch</strong>输入网络进行训练，如果数据量较大，这样的方法就不适用了，因为太耗内存，所以这时最好使用<strong>tensorflow</strong>提供的队列<strong>queue</strong>，也就是从文件读取数据。对于一些特定的读取，比如<strong>csv</strong>文件格式，官网有相关的描述，因此这里使用<strong>tensorflow</strong>内定标准格式——<strong>TFRecords</strong>，实现比较高效的数据读取方式。</p><p><strong>TFRecords</strong>其实是一种二进制文件，虽然它不如其他格式好理解，但是它能更好的利用内存，更方便复制和移动，并且不需要单独的标签文件。<strong>TFRecords</strong>文件包含了<strong>tf.train.Example</strong> 协议内存块(<strong>protocol buffer</strong>)(协议内存块包含了字段 <strong>Features</strong>)。我们可以写一段代码获取你的数据， 将数据填入到<strong>Example</strong>协议内存块(<strong>protocol buffer</strong>)，将协议内存块序列化为一个字符串，并且通过<strong>tf.python_io.TFRecordWriter</strong> 写入到<strong>TFRecords</strong>文件。</p><p>从<strong>TFRecords</strong>文件中读取数据， 可以使用<strong>tf.TFRecordReader</strong>的<strong>tf.parse_single_example</strong>解析器。这个操作可以将<strong>Example</strong>协议内存块(<strong>protocol buffer</strong>)解析为张量。</p><hr><p>对于数据扩充完成之后的<strong>2349</strong>张图片，按照<strong>90%</strong>训练集，<strong>0.5%</strong>交叉验证集，<strong>0.5%</strong>评估集的划分比例，最后得到的各部分数据情况如下：</p><blockquote><p><strong>NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 2048</strong><br><strong>NUM_EXAMPLES_PER_EPOCH_FOR_VAL = 227</strong><br><strong>NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 21</strong><br><strong>NUM_EXAMPLES_PER_EPOCH_FOR_hun = 53</strong><br><strong>NUM_EXAMPLES_PER_EPOCH_FOR_other = 3</strong></p></blockquote><hr><p><strong>最后补充一些有关</strong>.tfrecord<strong>文件的博文以作参考：</strong></p><blockquote><ol><li><a href="https://github.com/Blssel/Knowledge-learning/blob/master/tfrecord/readme.md" target="_blank" rel="noopener">Github：TF-learing/tfrecord/readme.md</a></li><li><a href="https://www.cnblogs.com/Stoner/p/9051030.html" target="_blank" rel="noopener">TensorFlow高效读取数据 | Ycszen-物语</a></li><li><a href="https://zhuanlan.zhihu.com/p/27238630" target="_blank" rel="noopener">十图详解tensorflow数据读取机制(附代码)</a></li><li><a href="https://blog.csdn.net/xierhacker/article/details/72357651" target="_blank" rel="noopener">TensorFlow学习（十一）：保存TFRecord文件</a></li><li><a href="https://lguduy.github.io/2017/05/20/TensorFlow%E6%95%99%E7%A8%8B-%E5%A4%84%E7%90%86%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE/#%E5%89%8D%E8%A8%80" target="_blank" rel="noopener">TensorFlow教程：利用TensorFlow处理自己的数据</a></li><li><a href="https://blog.csdn.net/shenxiaolu1984/article/details/52857437" target="_blank" rel="noopener">TensorFlow动手玩——数据导入2</a></li><li><a href="https://blog.csdn.net/wiinter_fdd/article/details/72835939" target="_blank" rel="noopener">用Tensorflow处理自己的数据：制作自己的TFRecords数据集——Cats_vs_Dogs</a></li><li><a href="https://blog.csdn.net/Best_Coder/article/details/70141075?locationNum=3&amp;fps=1" target="_blank" rel="noopener">Tensorflow 训练自己的数据集（一）（数据直接导入到内存）</a></li><li><a href="https://www.cnblogs.com/wktwj/p/7227544.html" target="_blank" rel="noopener">tensorflow训练自己的数据集实现CNN图像分类1</a></li><li><a href="https://blog.csdn.net/yimi_ac/article/details/79008555" target="_blank" rel="noopener">tensorflow实现逻辑回归，在kaggle《泰坦尼克》训练并测试准确率</a></li><li><a href="https://blog.csdn.net/briblue/article/details/80789608" target="_blank" rel="noopener">你可能无法回避的 TFRecord 文件格式详细讲解</a></li><li><a href="https://blog.csdn.net/happyhorizion/article/details/77894055" target="_blank" rel="noopener">tensorflow读取数据-tfrecord格式</a></li><li><a href="https://blog.csdn.net/weixin_42001089/article/details/81172028" target="_blank" rel="noopener">tensorflow中的tfrecord数据操作</a></li></ol></blockquote><h4 id="2-3-4-模型1效果"><a href="#2-3-4-模型1效果" class="headerlink" title="2.3.4 模型1效果"></a>2.3.4 模型1效果</h4><blockquote><p>由于采用分类的思想去建立模型的，最后的效果并不是很好，且分类的扩充的数据以及分类训练完毕的保存的模型参数已被删除，所以在此只是简要说一下最后的结果，最后的预测结果与真实结果相差在<strong>10 kg</strong>以内的数目仅为<strong>7</strong>个左右，由于采用分类的思想，使得本身的预测结果就是一个区间范围的不准确的值，而预测结果大体正确的个数又实在太少，即使调参多次，效果也不甚明显，所以<strong>模型1</strong>最后没有被采用.</p></blockquote><h3 id="2-4-设计思路2"><a href="#2-4-设计思路2" class="headerlink" title="2.4 设计思路2"></a>2.4 设计思路2</h3><blockquote><p>在第二种设计思路中，前面依旧采用的是卷积层获得数据特征，后面也是跟着几层全连接神经网络，只是最后不再是使用分类的方式对数据进行预测，而是采用了回归的方式进行数据预测，将全连接神经网络最后一层的多个分类神经元切换为只有一个回归神经元，以此得到对体重的准确预测.</p></blockquote><h4 id="2-4-1-网络结构"><a href="#2-4-1-网络结构" class="headerlink" title="2.4.1 网络结构"></a>2.4.1 网络结构</h4><p>整个网络架构如下图所示：<br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/Weights_Predict_of_Pig_Framework.jpg" alt="Alt text"><br>其中最好的结果中：<strong>卷积层有5层，池化层有3层，全连接层有3层.</strong></p><h4 id="2-4-2-损失定义"><a href="#2-4-2-损失定义" class="headerlink" title="2.4.2 损失定义"></a>2.4.2 损失定义</h4><p>由于<strong>模型2</strong>采用的是<strong>MSE均方误差损失</strong>，因此有定义如下：</p><blockquote><ol><li>TensorFlow官方提供的MSE损失：<br><strong>reg_loss = tf.losses.mean_squared_error(labels_holder, logits)</strong></li><li>自定义实现MSE损失：<br><strong>reg_loss = tf.reduce_mean(tf.square(labels_holder - logits))</strong></li><li><strong>经验风险：对训练集中的所有样本点损失函数的平均最小化.</strong><script type="math/tex; mode=display">R_{emp} = \frac{1}{N}\sum^{N}_{i=1}L(y_i, f(x_i))</script></li><li><strong>结构风险：在经验风险函数后面加一个正则化项（惩罚项）便是结构风险.</strong><script type="math/tex; mode=display">R_{srm} = \frac{1}{N}\sum^{N}_{i=1}L(y_i, f(x_i)) + \lambda J(f)</script></li><li><strong>经验风险</strong>越小，模型决策函数越复杂，其包含的参数越多，当<strong>经验风险</strong>函数小到一定程度就出现了过拟合现象。也可以理解为模型决策函数的复杂程度是过拟合的必要条件，那么我们要想防止过拟合现象的方式，就要破坏这个必要条件，即降低决策函数的复杂度。也即，让惩罚项$J(f)$最小化，现在出现两个需要最小化的函数了。我们需要同时保证<strong>经验风险函数</strong>和<strong>模型决策函数</strong>的复杂度都达到最小化，一个简单的办法把两个式子融合成一个式子得到<strong>结构风险函数</strong>然后对这个<strong>结构风险函数</strong>进行最小化。</li><li>需要注意的是相较于全连接神经网络，卷积神经网络的参数个数是比较小的，而整个模型中参数暴涨的部分来源于全连接神经网络，我们以2012年的经典之作<strong>AlexNet</strong>为例可以看出其中的端倪，下面是<strong>AlexNet</strong>的网络结构：<br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557757489219.png" alt="Alt text"></li></ol><p><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557757503753.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557757601052.png" alt="Alt text"></p><p> <img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557757837591.png" alt="Alt text"><br> 从最后一张图可以看出一个比较有意思的一点，在前面几个卷积层中，虽然计算量很大，但是参数量很小，只占用<strong>AlexNet</strong>总参数量的很小一部分，但是后面的全连接层的参数却比卷积层要大的多的多。因此，为了避免过拟合，我在全连接层的所有隐藏层中都加入了<strong>L2_Regularization</strong>.最后通过<strong>tf.add_to_collection()</strong>和<strong>tf.add_n(tf.get_collection(‘losses’), name=’total_loss’)</strong>将正则化项加入损失中.</p><p> <strong>其他：</strong><br> <strong>总体损失 = MSE损失 + 所有权重的L2损失</strong>.</p><ol><li><strong>tf.add_to_collection(‘losses’, cross_entropy_loss)</strong>代表将损失放入到计算图中关键字为<strong>losses</strong>下，这样可以方便一起获得所有损失.</li><li><strong>tf.get_collection(‘losses’)</strong>把前面所有的损失获取得到，<strong>tf.add_n</strong>则是把所有获取得到的损失加起来. 所以也就是说<strong>losses</strong>作为关键字(类似文件夹一样), <strong>add_to_collection</strong>将所有的损失放在一起，<strong>get_collection</strong>获取同样的关键字下的内容.</li><li><strong>add_to_collection</strong>以列表的形式存放，所以<strong>get_collection</strong>获取的是列表.</li><li><strong>get_collection</strong>返回的列表的顺序和<strong>add_to_collection</strong>加入的值的顺序是一致的，也就是谁先加入，谁先输出.</li></ol></blockquote><h4 id="2-4-3-优化函数"><a href="#2-4-3-优化函数" class="headerlink" title="2.4.3 优化函数"></a>2.4.3 优化函数</h4><p>在本项目中使用了三种不用的优化函数，分别是：</p><blockquote><ol><li><strong>optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)</strong></li><li><strong>optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate)</strong></li><li><strong>optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)</strong><br>其中效果最好的是<strong>AdamOptimizer</strong>.</li></ol></blockquote><h4 id="2-4-4-训练结果"><a href="#2-4-4-训练结果" class="headerlink" title="2.4.4 训练结果"></a>2.4.4 训练结果</h4><p>在每一个<strong>batch_size</strong>有<strong>64</strong>个训练样本，每个<strong>Epoch</strong>有<strong>32</strong>个<strong>batch_size</strong>，一共训练<strong>40</strong>个<strong>Epoch</strong>个情况下，训练集损失和交叉验证集损失如下：<br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/Reg_Loss_Plot.jpg" alt="Alt text"><br>其中最好结果为预测值与真实值(评估集有<strong>21</strong>个样本的情况下)相差<strong>10 kg</strong>以内的样本个数为<strong>16</strong>个，达到较好水平，详细结果如下：<br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557759001960.png" alt="Alt text"><br>其中对于体重为<strong>100+</strong>体重的猪的预测则是全部预测准确：<br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557759064536.png" alt="Alt text"><br>整体的调参结果如下图记录：<br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557759148516.png" alt="Alt text"></p><h4 id="2-4-5-卷积层可视化"><a href="#2-4-5-卷积层可视化" class="headerlink" title="2.4.5 卷积层可视化"></a>2.4.5 卷积层可视化</h4><p>对于卷积层可视化可以有效的发现卷积核是否提取到了有用的特征，因此代码中加入了相应的可视化部分用于可视化卷积层和池化层，接下来展示两张不同重量的照片的可视化结果。</p><ol><li><p>下面第一张照片真实重量为<strong>21.60 kg</strong>, 预测重量为<strong>22.07 kg</strong>，展示了原始图片以及<strong>5</strong>个卷积层和<strong>3</strong>个池化层的输出效果：</p><blockquote><p><strong>Original_Image：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1_Original_Image.jpg" alt="Alt text"></p><hr><p><strong>Conv1_Layer：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/2_Conv1.jpg" alt="Alt text"><br>卷积层<strong>1</strong>可以明显的看出在多个卷积核的作用下，原始图像的边缘轮廓(包括<strong>垂直和水平边缘</strong>)信号被放大，而且由于该图片的背景与猪的主体区分度比较明显，因此整个猪的形态较好的被检测出来了.</p><ol><li>需要注意的是卷积核(滤波器核)的尺寸数目按照已有的经验选择的都是奇数大小，这里不再详述；</li><li>卷积尺寸计算公式如下：<blockquote><p>输入数据体的尺寸为$W_1 \times H_1 \times D_1$，卷积核的<strong>4</strong>个超参数为：<strong>卷积核的数目K</strong>；<strong>卷积核的空间尺寸f</strong>；<strong>卷积步长s</strong>；<strong>Padding类型(SAME 和 VALID)</strong>.<br>输出尺寸：</p><script type="math/tex; mode=display">n = \left\lfloor\frac{n + 2p - f}{s}\right\rfloor + 1</script></blockquote></li><li>在本项目中所有卷积层都采用的<strong>SAME Padding</strong>，避免图像块尺寸缩减过快，所谓<strong>VALID Padding</strong>，其实就是卷积过程中不进行填充，每次卷积完后整个图像块的尺寸依照卷积计算公式减小；而<strong>SAME Padding</strong>则是在图像块四周进行<strong>0填充</strong>，这样对于图像四周的边角也会更好的提取信息，图像卷积完毕大小不变，有效避免的了图像丢失角落和边沿的信息.</li></ol><hr><p><strong>Pool1_Layer：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/3_Pool1.jpg" alt="Alt text"><br>在本项目中采用了使用频率最高的<strong>Max Pooling</strong>方式，对前一层卷积过后的特征图进行缩减，逐渐降低图像块体的空间尺寸，有效减少网络中的参数数量，使得计算资源耗费变少，有效控制过拟合，而最大池化还可以保留主要特征，筛选掉次要的特征.</p><hr><p><strong>Conv2_Layer：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/4_Conv2.jpg" alt="Alt text"><br>在第一层卷积层中，主要的是提取一些简单的边缘特征，越往后的卷积层提取的特征就越高级，在本层中有一个非常明显的特征被卷积核提取到，那就是放在猪身上的<strong>A4</strong>纸，图中明显可以看到<strong>A4</strong>的边缘轮廓被提取出来，这样印证了<strong>A4</strong>这一特征的重要性: 作为和猪的体型做参照对比的重要特征，可以很好的侧面反应出猪的体重大小，因此在<strong>模型1</strong>中使用了去水印的图片作为输入的想法是不正确的，而且在<strong>模型2</strong>中输入的图片并没有去掉水印，但是卷积过程并没有被这一特征给干扰，因此很有可能将水印当做噪点给处理掉了.</p><hr><p><strong>Pool2_Layer：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/5_Pool2.jpg" alt="Alt text"></p><hr><p><strong>Conv3_Layer：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/6_Conv3.jpg" alt="Alt text"></p><hr><p><strong>Conv4_Layer：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/7_Conv4.jpg" alt="Alt text"></p><hr><p><strong>Conv5_Layer：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/8_Conv5.jpg" alt="Alt text"></p><hr><p><strong>Pool5_Layer：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/9_Pool5.jpg" alt="Alt text"></p></blockquote></li><li><p>第二张照片真实重量为<strong>52.85 kg</strong>，预测重量为<strong>53.32 kg</strong>，卷积和池化过程如下：</p><blockquote><p><strong>Original_Image：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1.jpg" alt="Alt text"></p><hr><p><strong>Conv1_Layer：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/c1.jpg" alt="Alt text"></p><hr><p><strong>Pool1_Layer：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/p1.jpg" alt="Alt text"></p><hr><p><strong>Conv2_Layer：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/c2.jpg" alt="Alt text"></p><hr><p><strong>Pool2_Layer：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/p2.jpg" alt="Alt text"></p><hr><p><strong>Conv3_Layer：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/c3.jpg" alt="Alt text"></p><hr><p><strong>Conv4_Layer：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/c4.jpg" alt="Alt text"></p><hr><p><strong>Conv5_Layer：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/c5.jpg" alt="Alt text"></p><hr><p><strong>Pool5_Layer：</strong><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/c5.jpg" alt="Alt text"></p></blockquote></li></ol><p>以上是整个卷积层的可视化过程，卷积的过程通过从初始的轮廓边缘检测到后面一层一层的低级特征组合成高级特征，最后将重要的特征提取出来以供后面特定的任务使用，整个过程可以用下面两种图来总结：<br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557800289969.png" alt="Alt text"></p><p><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557800336588.png" alt="Alt text"></p><h2 id="3-TensorBoard与数据可视化"><a href="#3-TensorBoard与数据可视化" class="headerlink" title="3. TensorBoard与数据可视化"></a>3. TensorBoard与数据可视化</h2><h3 id="3-1-TensorBoard简要介绍"><a href="#3-1-TensorBoard简要介绍" class="headerlink" title="3.1 TensorBoard简要介绍"></a>3.1 TensorBoard简要介绍</h3><blockquote><p><strong>Tensorboard</strong> 是 <strong>tensorflow</strong> 内置的一个可视化工具，也是一个 <strong>web</strong> 应用套件，支持七种可视化包括 <strong>SCALARS</strong> (标量)、<strong>IMAGES</strong>(图像)、<strong>AUDIO</strong>(音频)、<strong>GRAPHS</strong>(数据流图)、<strong>DISTRIBUTIONS</strong>(训练数据分布图)、<strong>HISOGRAMS</strong>(训练过程中数据的柱状图)和<strong>EMBEDDINGS</strong>(展示词向量的投影分布)。</p><p>它通过将 <strong>tensorflow</strong> 程序输出的日志文件的信息可视化使得 <strong>tensorflow</strong> 程序的理解、调试和优化更加简单高效。<strong>Tensorboard</strong> 的可视化依赖于 <strong>tensorflow</strong> 程序运行输出的日志文件，因而 <strong>tensorboard</strong> 和 <strong>tensorflow</strong> 程序在不同的进程中运行，<strong>TensorBoard</strong> 会自动读取最新的 <strong>TensorFlow</strong> 日志文件，并呈现当前 <strong>TensorFlow</strong> 程序运行的最新状态。</p></blockquote><h3 id="3-2-本项目中的应用"><a href="#3-2-本项目中的应用" class="headerlink" title="3.2 本项目中的应用"></a>3.2 本项目中的应用</h3><p>由于 <strong>TensorBoard</strong> 的便利，因此在本项目的模型中添加相应的对张量进行汇总的节点，包含相应的 <strong>MEAN</strong>(均值)、<strong>STDDEV</strong>(标准差)、<strong>MAX</strong>(最大值)、<strong>MIN</strong>(最小值)、<strong>HISTOGRAM</strong>(参数分布直方图)、<strong>Activation_Summary</strong>(激活值汇总)、<strong>Losses_Summary</strong>(损失值汇总)以及<strong>Image_Summary</strong>(图像汇总)等，对于整体的分析十分便利，且如果不是用<strong>TensorBoard</strong>的情况下要对各个信息进行汇总会产生各个不同的图表，而使用<strong>TensorBoard</strong>进行汇总则仅仅产生一个日志文件，而这个日志文件包含各个需要分析的图表等，因此有利于对模型进行更好的分析和调参。</p><h3 id="3-2-1-TensorBoard可视化计算图"><a href="#3-2-1-TensorBoard可视化计算图" class="headerlink" title="3.2.1 TensorBoard可视化计算图"></a>3.2.1 TensorBoard可视化计算图</h3><p>在<strong>2.4.1 网络结构</strong>中列出了整个模型的框架，但是那是手动使用<strong>PPT</strong>画出的，而在<strong>TensorBoard</strong>中，直接可以可视化我们的模型结构：<br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557995617379.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557995674798.png" alt="Alt text"><br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557995708566.png" alt="Alt text"><br>整个结构和<strong>2.4.1 网络结构</strong>中的结构是一致的，只不过这里还可以打开每个节点看到每个张量流的流动方向以及经过具体什么样的操作节点。</p><h3 id="3-2-1-TensorBoard可视化卷积过程"><a href="#3-2-1-TensorBoard可视化卷积过程" class="headerlink" title="3.2.1 TensorBoard可视化卷积过程"></a>3.2.1 TensorBoard可视化卷积过程</h3><p>与手动设计卷积层可视化不同，在<strong>TensorFlow</strong>中可以使用内置的库进行可视化，只要在相应的节点处添加图像汇总节点即可在<strong>TensorBoard</strong>中查看结果，如下：</p><ol><li><p>原始图像：<br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557995968562.png" alt="Alt text"></p></li><li><p>经过两层卷积之后的结果：<br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557995941613.png" alt="Alt text"></p></li></ol><p>从<strong>TensorBoard</strong>的卷积可视化中也可以印证前面手动可视化卷积中分析的那样：卷积层有效的检测出图像中猪的边缘轮廓信息，除此之外，在卷积可视图中可以清晰的看到一个类似矩形的物体边缘轮廓，而这个物体正是放在猪身上用于起到体型大小参考作用的<strong>A4</strong>纸，因此<strong>这是一个重要的特征，而且卷积核有效的提取出了这个特征，从而影响到最终的预测结果。相较于在机器学习中需要人工的配合着相应的经验去构造一系列特征而言，深度学习能够很好完成这项任务，自动的去学习提取对任务有用的特征，而无需外部人工干涉！</strong></p><h3 id="3-2-3-TensorBoard可视化损失变化过程"><a href="#3-2-3-TensorBoard可视化损失变化过程" class="headerlink" title="3.2.3 TensorBoard可视化损失变化过程"></a>3.2.3 TensorBoard可视化损失变化过程</h3><p><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557996622008.png" alt="Alt text"><br>相较于需要每隔一定步数就要收集相应的损失，以便手动构造代码画出损失图而言，<strong>TensorBoard</strong>直接通过添加节点即可将损失的信息汇总到日志文件中。</p><h3 id="3-2-4-TensorBoard验证Batch-Norm"><a href="#3-2-4-TensorBoard验证Batch-Norm" class="headerlink" title="3.2.4 TensorBoard验证Batch_Norm"></a>3.2.4 TensorBoard验证Batch_Norm</h3><p>在<strong>第4部分</strong>中比较详细的表述了<strong>Batch_Norm</strong>的作用，在此主要是通过手动绘出的图像和<strong>TensorBoard</strong>中的可视化用以验证加入<strong>Batch_Norm</strong>的正确性。</p><ol><li><p>手动绘图：</p><blockquote><p>1.1 添加<strong>Batch_Norm</strong>：<br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557999395593.png" alt="Alt text"></p><p>1.2 关闭<strong>Batch_Norm</strong>：<br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/1557999373890.png" alt="Alt text"></p></blockquote></li><li><p><strong>tensorboard</strong>可视化：</p><blockquote><p>2.1 添加<strong>Batch_Norm</strong>：<br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/TIM截图20190516172839.png" alt="Alt text"></p><p>2.2 关闭<strong>Batch_Norm</strong>：<br><img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/0e573ef2c4b36572b6f796cfef6899b.png" alt="Alt text"><br>在图中明显可以看到对于全连接层三个隐藏层中激活值的变化，未添加<strong>Batch_Norm</strong>层的激活值很快便缩小到0附近，这样是不能提供梯度的，因此损失值一致在一个值左右震荡，无法收敛。</p></blockquote></li></ol><h2 id="4-遇到的问题"><a href="#4-遇到的问题" class="headerlink" title="4. 遇到的问题"></a>4. 遇到的问题</h2><h3 id="4-1-神经网络如何处理回归问题？"><a href="#4-1-神经网络如何处理回归问题？" class="headerlink" title="4.1 神经网络如何处理回归问题？"></a>4.1 神经网络如何处理回归问题？</h3><p>首先需要明确一点的是，神经网络多用于分类，用于连续型变量的回归预测问题(比如预测<strong>身高、体重、年龄、温度、质量得分</strong>等)很少，即使非要用神经网络处理这类问题，多数的处理方式也是连续型变量按照区间进行划分，转化为离散型的类别变量，这样也就变成了本项目中的<strong>模型1</strong>了。</p><p>对于本项目的<strong>模型2</strong>，初始的考虑方式是直接将最后的分类层转换为只有一个神经元的回归层，然后将前面的隐藏层具有非线性映射的激活函数全部改为线性映射，最后的结果是<strong>Total Loss</strong>高达上千乃至上万，整个模型的<strong>Loss</strong>完全无法降下去，<strong>40</strong>个<strong>Epoch</strong>结束之后，<strong>Loss</strong>完全是在一个值左右震荡。</p><p>后来改进的方法如下：</p><blockquote><ol><li>前面的卷积层依旧不变，主要的变化是对于后面标签值进行改变的；</li><li>对于输入的标签值，进行标准化(<strong>sklearn.preprocessing.StandardScaler</strong>);</li><li>由于使用神经网络的其中一个主要原因就是考虑到激活函数非线性映射带来的强大拟合能力，因此如果中间所有的激活函数都改为线性的了则神经网络就只是一个线性映射了，没有实际的作用了，所以隐藏层还是加上激活函数；</li><li>由于激活函数存在区间压缩的功能，所以如果激活函数使用的是<strong>sigmoid</strong>，则标签值在传入网络做训练之前需要先放缩到$[0, 1]$之间(<strong>MinMaxScaler(feature_range=(0, 1))</strong>)，相应的如果激活函数是<strong>tanh</strong>，则需要将标签放缩到$[-1, 1]$之间；</li><li>最后一层输出层我这里采用的是不适用非线性的激活函数，考虑到输出值不将其看作某一类概率的情况，我选择使用了线性映射输出，实际的结果也要比使用非线性映射输出要好；</li><li>最后需要查看真实的标签以及预测值的情况的时候，需要将放缩后的结果进行反向放缩，这一点尤为重要(<strong>mm_train_scaler.inverse_transform(labels_batch)</strong>)</li><li>修改交叉熵损失函数为<strong>MSE</strong>均方误差损失；</li><li><a href="https://www.zhihu.com/question/68388247" target="_blank" rel="noopener">如何使用卷积神经网络做数值回归任务?</a></li></ol></blockquote><h3 id="4-2-网络损失震荡，无法降下来？"><a href="#4-2-网络损失震荡，无法降下来？" class="headerlink" title="4.2 网络损失震荡，无法降下来？"></a>4.2 网络损失震荡，无法降下来？</h3><p>按照<strong>3.1</strong>的方式修改网络结构为回归结构之后，虽然损失的值变成了小数，但是依旧是在某个值上下震荡，无法将损失降下来，后来考虑可能是由于网络的层数的原因造成数据在不同层之间的分布改变了，导致每一层其实是在训练不同的数据，结果自然降不下来。</p><p>机器学习领域有个很重要的假设： <strong>IID独立同分布假设</strong>，$\underline{就是假设训练数据和测试数据是满足相同分布的，这是通过训练数据获得的模型能够在测试集获得好的效果的一个基本保障}$。那<strong>BatchNorm</strong>的作用是什么呢？$\underline{ BatchNorm就是在深度神经网络训练过程中使得每一层神经网络的输入保持相同分布的}$。</p><p><strong>BatchNorm</strong>就是用来解决 <strong>Internal Covariate Shift</strong> 问题的，在引入<strong>Internal Covariate Shift</strong>是什么之前？先引入<strong>covariate shift</strong>的概念: $\underline{如果ML系统实例集合[X,Y]中的输入值X的分布老是变，网络模型很难稳定的学规律}$，这不符合<strong>IID假设</strong>，<strong>ML</strong>系统还得去学习怎么迎合这种分布变化。</p><p>对于深度学习这种包含很多隐层的网络结构，在训练过程中，因为各层参数不停在变化，所以每个隐层都会面临<strong>covariate shift</strong>的问题，也就是在训练过程中，隐层的输入分布老是变来变去，这就是所谓的 <strong>Internal Covariate Shift</strong>，<strong>Internal</strong>指的是深层网络的隐层，是发生在网络内部的事情，而不像<strong>covariate shift</strong>问题只发生在输入层。</p><p><strong>BatchNorm</strong>的基本思想如下：<strong>对于每个隐层神经元，把逐渐向非线性函数映射后向取值区间极限饱和区靠拢的输入分布强制拉回到均值为0方差为1的比较标准的正态分布，使得非线性变换函数的输入值落入对输入比较敏感的区域，以此避免梯度消失问题。</strong></p><p>在本项目中通过添加<strong>BatchNorm</strong>取得了巨大的效果，之前完全降不下的损失也随着迭代步数的增加在逐步下降，而非震荡甚至发散了；在代码中主要是添加在了卷积层和全连接网络的隐藏层的激活值还没有通过非线性激活函数之前的位置。整个训练过程相较于没有添加之前，训练速度提升，收敛速度大大加快，而且还有类似<strong>Dropout</strong>的正则化效果.</p><hr><p><strong>最后补充一些有关</strong>Batch_Normalization<strong>的博文以作参考：</strong></p><blockquote><ol><li><a href="https://www.cnblogs.com/guoyaohua/p/8724433.html" target="_blank" rel="noopener">深入理解Batch Normalization批标准化</a></li><li><a href="https://blog.csdn.net/dongjbstrong/article/details/80447110" target="_blank" rel="noopener">CSDN——正确使用Tensorflow Batch_normalization</a></li><li><a href="https://blog.csdn.net/huitailangyz/article/details/85015611" target="_blank" rel="noopener">CSDN——tensorflow中的batch_norm以及tf.control_dependencies和tf.GraphKeys.UPDATE_OPS的探究</a></li><li><a href="https://blog.csdn.net/u014061630/article/details/85104491" target="_blank" rel="noopener">CSDN——TensorFlow 中 Batch Normalization API 的一些坑</a></li><li><a href="https://blog.csdn.net/computerme/article/details/80836060?utm_source=blogxgwz1" target="_blank" rel="noopener">CSDN——tensorflow batch_normalization的正确使用姿势</a></li></ol></blockquote><h3 id="4-3-不同MinMaxScaler对象之间不能混着用"><a href="#4-3-不同MinMaxScaler对象之间不能混着用" class="headerlink" title="4.3 不同MinMaxScaler对象之间不能混着用"></a>4.3 不同MinMaxScaler对象之间不能混着用</h3><p>训练到后期的时候，遇到过这样一个问题：在对<strong>21</strong>个体重区间小于<strong>100+</strong>的样本进行测试的时候，得到的真实值结果居然全部在<strong>100+</strong>左右，如何修改都没有效果，后来发现<strong>MinMaxScaler</strong>对象对体重<strong>100+</strong>进行放缩和对体重小于<strong>100+</strong>进行放缩的顺序不一样的时候会出现正确结果或错误结果各有出现的情况，最后发现是由于申明<strong>MinMaxScaler</strong>对象的时候只申明了一个对象，而对所有的数据都只用一个对象进行放缩和反向放缩的时候，就会出现上面的错误现象，通过查找资料发现：</p><blockquote><p>一般情况下，或者严格点说，在监督学习中，我们需要利用训练集数据对测试集数据进行预测。<br>这里隐含了一个假设，就是训练数据和测试数据实际上是同分布的（因此我们才可以使用训练数据集来预测测试数据集），来自于同一个总体。<br>在进行标准化的过程中就将训练集的均值和方差当做是总体的均值和方差，因此对测试集使用训练集的均值和方差进行预处理。</p></blockquote><p>也就是说体重<strong>100+</strong>的测试数据和体重<strong>100+</strong>以下的测试数据的分布是不相同的，所以，如果更改两者的放缩顺序，很有可能就造成上面的错误，从而<strong>100+</strong>以下的样本被反向放缩的时候，得到的结果却是<strong>100+</strong>样本反向放缩的结果，因此修改方法就是：将<strong>MinMaxScaler</strong>对象各自申请<strong>4</strong>个，对应<strong>train\val\eval\100+</strong>这<strong>4</strong>个样本集，在反向放缩的时候也是各自对应各自的<strong>MinMaxScaler</strong>对象，这样错误就解决了。</p><h3 id="4-4-Tensor-Feed-Error"><a href="#4-4-Tensor-Feed-Error" class="headerlink" title="4.4 Tensor Feed Error"></a>4.4 Tensor Feed Error</h3><p>在制作<strong>Tfrecords</strong>文件的<strong>.py</strong>文件中有一个函数叫<strong>read_and_decode</strong>，主要用于读取已经制作完成的<strong>tfrecords</strong>文件，并以多线程的方式将数据以<strong>batch</strong>大小返回，但是在训练的时候出现过直接给<strong>Session</strong>喂<strong>read_and_decode</strong>返回的数据报错的情况，后面发现原因如下：</p><blockquote><p>需要注意的是<strong>read_and_decode</strong>函数返回的<strong>images_test</strong>和<strong>labels_test</strong>仅仅是<strong>tensorflow</strong>数据流图上定义好的。实际上它并不是一个实际的数据，仅仅是一个<strong>Tensor</strong>张量，而<strong>feed_dict</strong>必须接受的是实际的数据。实际的数据需要<strong>sees.run()</strong>来获得.</p><p><strong>sees.run()</strong>返回<strong>type</strong>为<strong>np.ndarray</strong>格式的数据才是真正的数据，也就是说在<strong>sess.run()</strong>之前的都只是在数据流图中流动的<strong>tensor</strong>，只有真正需要<strong>train</strong>的时候是需要使用<strong>sees.run()</strong>获得真正的数据然后进行<strong>feed</strong>的:</p><pre><code class="lang-flow">st=&gt;start: read_and_decodee=&gt;end: feed_dict(images)op1=&gt;operation: image_batch(tensor)op2=&gt;operation: images=sess.run(image_batch)(real data)st-&gt;op1-&gt;op2-&gt;e</code></pre><p>需要注意的是，如果已经获取了<strong>np.ndarray</strong>(真实数据格式)的数据后在<strong>feed</strong>的时候需要注意<strong>images_placeholder</strong>的<strong>shape</strong>，也就是传入数据要和<strong>placeholder</strong>的<strong>shape</strong>一致，如果不一致，可以使用<strong>tf.reshape</strong>进行<strong>shape</strong>转换<strong>(tf.reshape会将数据格式转换为tensor，切记)</strong>，然后转换为<strong>np.ndarray</strong>; 要么就在<strong>sess.run()</strong>之后使用<strong>np</strong>的方式，也就是<strong>data.reshape()</strong>的方式直接转换，这样避免还需要数据格式的转换.</p></blockquote><h3 id="4-5-Batch-size与输入数据的placeholder"><a href="#4-5-Batch-size与输入数据的placeholder" class="headerlink" title="4.5 Batch_size与输入数据的placeholder"></a>4.5 Batch_size与输入数据的placeholder</h3><p>在<strong>模型1</strong>与<strong>模型2</strong>最开始的测试部分的代码中，使用的方式是一次性将多张测试图片做成<strong>.tfrecords</strong>文件，然后利用代码读取<strong>.tfrecords</strong>文件的方式进行数据预测，这样的方式存在比较大的几个问题。</p><p>首先，每一次有新的预测任务的时候，都需要手动的去执行<strong>tfrecord</strong>文件制作的函数，生成文件，然后才能读取文件进行预测，这样是无法做到自动化的；其次，有一个很大的问题是在模型所在文件中，最开始定义数据输入的<strong>placeholder</strong>的时候，<strong>shape = [batch_size, img_size, img_size, img_channel]</strong>。</p><p>对应的，在卷积完毕之后，准备传入全连接层之前，有一步将卷积块拉长成向量的操作的，其中进行<strong>reshape</strong>的时候，开始的操作是: <strong>[batch_size, -1]</strong>, 这样，可以直接根据<strong>batch_size</strong>的大小去计算向量应该的长度，而无需因为卷积层的参数变化而每次都要重新计算向量的长度，但是这里恰巧是手动转为自动的关键所在。</p><p>要想转为自动，首先，数据输入的<strong>placeholder</strong>就不能写死，这样就将<strong>shape</strong>修改为<strong>[None, img_size, img_size, img_channel]</strong>, 这样每次不管传入的数据的批次大小如何都能应对，相应的，测试的时候数据的批次大小和训练的时候数据的批次大小肯定是不相同的，之前一直是需要在测试和训练的时候根据不同的数据大小做相应的手动<strong>batch_size</strong>调整的，这是个很麻烦且无法自动化的事情，修改输入数据的<strong>placeholder</strong>的<strong>shape</strong>可以很好的解决这个问题。</p><p>除了这个地方需要修改，还有一个地方需要修改了才能起作用，之前只是单纯的修改了输入数据的<strong>placeholder</strong>的<strong>shape</strong>，但是代码运行的时候报错了，后来想了很久才发现问题所在： 主要的问题就在于上面提到的那个重点——也就是在卷积块拉长成向量那里，不能在<strong>reshape</strong>的时候还是设置参数为<strong>[batch_size, -1]</strong>，即使这个<strong>batch_size</strong>手动设置成了匹配测试数据批次大小的值，报错的根本原因就是因为将<strong>batch_size</strong>设置为测试数据批次的大小了之后，由于在测试的时候是调用训练完毕的模型的参数的，而保存好了的模型的参数中<strong>batch_size</strong>是一个保存好了的，和模型训练有关的值，而这个值是和测试时候的值是不一样的，所以存在<strong>reshape</strong>的时候大小不匹配的情况。</p><p>正确的方式是在上面<strong>[batch_size, -1]</strong>的地方改为<strong>[-1, feats_dim]</strong>,其中<strong>feats_dim = image_Pooled_size $\times$ image_Pooled_size $\times$ conv_kernel_num</strong>，其中<strong>image_Pooled_size</strong>是和整个结构中池化层的个数又直接关系的，而卷积层采用的<strong>SAME Padding</strong> ，因此跟卷积无关；图像每经过一个池化层，图像尺寸就缩小为原来的$\frac{1}{2}$，因此假设池化层有$n$个，则<strong>image_Pooled_size = original_image_size $\times$  $(\frac{1}{2})^n$</strong>，这样就可以直接在文件夹读取文件并预测了，无需再做成<strong>tfrecord</strong>文件去预测了.</p><h3 id="4-6-原始数据集问题"><a href="#4-6-原始数据集问题" class="headerlink" title="4.6 原始数据集问题"></a>4.6 原始数据集问题</h3><p>问题就不再描述了，主要希望后期的照片能达到以下要求：</p><blockquote><ol><li>照片尽量对焦，不要拍的模糊不清；</li><li>对不同的猪的拍照角度尽量为这种方向：<img src= "/img/loading.gif" data-src="/2019/05/22/Weights-Pred-of-Pigs/136.jpg" alt="Alt text"><br>当然，也可以在这基础上多拍几张，且猪的身体尽量被包含在图像中，不要有缺失；</li><li>选择的拍照背景尽量不要和猪的毛色混杂在一起，避免造成背景和主题混在一起无法分辨(就像狙击手身穿迷彩服，躲在背景的样子)</li><li>放在猪身上的纸尽量要大小一致，放的位置尽量统一，比如都放在猪肚子附近最好；</li><li>一张照片中不要拍摄超过一头猪；</li><li>体重标签在标记的时候不要出错，会影响结果精度.</li><li>体重超过<strong>100+</strong>的如果能有具体详细的值最好，如果都按照<strong>100</strong>来处理，应该是会影响到预测精度的。</li></ol></blockquote>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TensorFlow </tag>
            
            <tag> 卷积神经网络 </tag>
            
            <tag> 全连接神经网络 </tag>
            
            <tag> 回归 </tag>
            
            <tag> 标签归一化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Application of Batch Normalization in Tensorflow</title>
      <link href="/2019/05/22/Batch-Norm/"/>
      <url>/2019/05/22/Batch-Norm/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>解析TensorFlow中Batch_Normalization的使用方法.</strong><br><a id="more"></a></p></blockquote><h2 id="1-理论公式"><a href="#1-理论公式" class="headerlink" title="1. 理论公式"></a>1. 理论公式</h2><p>以神经网络中的某一层隐藏层的中间值为例: $z^{(1)}, z^{(2)}, … , z^{(m)}$: </p><script type="math/tex; mode=display">\mu = \frac{1}{m} \sum_{i} z^{(i)}</script><script type="math/tex; mode=display">{\sigma}^2 = \frac{1}{m} (z^{(i)} - \mu)^2</script><script type="math/tex; mode=display">z_{norm}^{(i)} = \frac{z^{(i)} - \mu}{\sqrt{\sigma^2 + \epsilon}}</script><script type="math/tex; mode=display">\tilde{z}^{(i)} = \gamma·z_{norm}^{(i)} + \beta</script><p>其中 $\epsilon$ 是为了保证数值稳定. $\gamma$ 和 $\beta$ 是可以跟随<strong>backpropagation</strong>进行学习更新的参数，类似神经网络的中的权重$\omega$, 更新公式如下：</p><script type="math/tex; mode=display">\omega^{[l]} := {\omega}^{[l]} - \alpha·d{\omega}^{[l]}</script><script type="math/tex; mode=display">\gamma^{[l]} := {\gamma}^{[l]} - \alpha·d{\gamma}^{[l]}</script><script type="math/tex; mode=display">\beta^{[l]} := {\beta}^{[l]} - \alpha·d{\beta}^{[l]}</script><p>需要注意的是：当 $\gamma = \sqrt{\sigma^2 + \epsilon}$ 以及 $\beta = \mu$ 的时候，相当于是恢复到了<strong>batch_norm</strong>之前的状态.</p><h2 id="2-tensorflow中的Batch-Norm"><a href="#2-tensorflow中的Batch-Norm" class="headerlink" title="2. tensorflow中的Batch_Norm"></a>2. tensorflow中的Batch_Norm</h2><p>在<strong>TensorFlow</strong>中，关于<strong>batch_norm</strong>有三种实现：</p><blockquote><ol><li><p><strong>tf.nn.batch_normalization（最底层的实现）</strong></p><blockquote><p><strong>该函数是一种最底层的实现方法，在使用时mean、variance、scale、offset等参数需要自己传递并更新，因此实际使用时还需自己对该函数进行封装，它是最基本的代码，级别最低，基本不会变，但要实现各种功能，需要自己组合别的api来实现，一般不建议使用，但是对了解batch_norm的原理很有帮助。</strong></p></blockquote></li><li><p><strong>tf.layers.batch_normalization</strong></p><blockquote><p><strong>非常推荐使用，该函数是对上面函数的封装，在深度神经网络中非常方便就可以进行添加，一般是添加在线性输出之后和激活函数之前. 它是一些已经确定了的代码，基本不会有大的改动</strong></p></blockquote></li><li><p><strong>tf.contrib.layers.batch_norm(slim)</strong></p><blockquote><p><strong>这种方法与tf.layers.batch_normalization的使用方法差不多，两者最主要的差别在参数scale和centre的默认值上，这两个参数即是我们之前介绍原理时所说明的对input进行mean和variance的归一化之后采用的线性平移中的scale和offset，可以看到offset的默认值两者都是True，但是scale的默认值前者为True后者为False，也就是说明在tf.contrib.layers.batch_norm中，默认不对处理后的input进行线性缩放，只是加一个偏移.  tf.contrib是一些尝试代码或者不稳定的代码，将来可能会被弃用或者删除</strong></p></blockquote></li></ol></blockquote><h2 id="3-正确使用方法"><a href="#3-正确使用方法" class="headerlink" title="3. 正确使用方法"></a>3. 正确使用方法</h2><ol><li><p><strong>训练阶段：</strong></p><blockquote><p>1.1  <strong>设置training = True</strong>;<br>1.2  添加下面的代码，以保存滑动平均值，测试时会使用到:</p><pre><code class="lang-python">x_norm = tf.layers.batch_normalization(x, training=training)# ...update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)with tf.control_dependencies(update_ops): #保证train_op在update_ops执行之后再执行。 train_op = optimizer.minimize(loss)</code></pre></blockquote></li><li><p><strong>保存模型阶段：</strong></p><pre><code class="lang-python">var_list = tf.trainable_variables() g_list = tf.global_variables()bn_moving_vars = [g for g in g_list if &#39;moving_mean&#39; in g.name]bn_moving_vars += [g for g in g_list if &#39;moving_variance&#39; in g.name]var_list += bn_moving_varssaver = tf.train.Saver(var_list=var_list, max_to_keep=1)</code></pre></li><li><p><strong>预测阶段：</strong></p><blockquote><p><strong>设置training=False。（当训练时的batch_size设置为1时，training=False的测试效果不一定好，可能是由于训练时的batch_size太小，导致滑动平均值不稳定，因为使用滑动平均值去测试效果不好，反而设置为training=True效果更好。可以当做一个超参数去尝试。）</strong></p><p>注意：<strong>这个人提出即使使用training=False，在测试时效果也不好，他尝试了在测试时用：</strong></p><pre><code class="lang-python">update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)with tf.control_dependencies(update_ops): logits = yourmodel.infersence(inputs_)</code></pre></blockquote></li></ol><p><a href="https://www.jianshu.com/p/789df4b3fffa" target="_blank" rel="noopener">简书——Tensorflow Batch normalization函数</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TensorFlow </tag>
            
            <tag> Batch_Normalization </tag>
            
        </tags>
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title>分类</title>
      <link href="/categories/index.html"/>
      <url>/categories/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>友情链接</title>
      <link href="/link/index.html"/>
      <url>/link/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>标签</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
  
</search>
